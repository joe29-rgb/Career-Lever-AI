This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.
The content has been processed where line numbers have been added.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
- Pay special attention to the Repository Description. These contain important context and guidelines specific to this project.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: src/lib/perplexity-intelligence.ts, src/lib/agents/job-discovery-agent.ts, src/lib/agents/orchestrator-agent.ts, src/lib/perplexity.ts, src/app/api/jobs/search/route.ts, src/app/api/resume/upload/route.ts, src/app/api/jobs/[id]/route.ts, src/lib/scrapers/advanced-scraper.ts, src/lib/scrapers/indeed-scraper.ts, src/lib/scrapers/linkedin-scraper.ts, src/lib/scrapers/jobbank-scraper.ts, src/app/job-search/page.tsx, src/components/JobSearch.tsx, src/components/JobCard.tsx, src/app/resume-builder/page.tsx, src/components/ResumeTemplateSelector.tsx, src/lib/job-validation.ts, src/lib/job-cache.ts, src/lib/job-enrichment.ts, src/lib/deduplication.ts, src/types/job.ts, src/types/perplexity.ts, .env.example, package.json, next.config.js
- Line numbers have been added to the beginning of each line
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<user_provided_header>
Career Lever AI - Perplexity & Scraping Full Pack

Includes: Perplexity Intelligence, Agents, Scrapers, Job Search APIs, Frontend Components

Generated: {{generationDate}}
</user_provided_header>

<directory_structure>
next.config.js
package.json
src/app/api/jobs/search/route.ts
src/app/api/resume/upload/route.ts
src/app/resume-builder/page.tsx
src/lib/agents/job-discovery-agent.ts
src/lib/perplexity-intelligence.ts
src/lib/scrapers/advanced-scraper.ts
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="next.config.js">
  1: /** @type {import('next').NextConfig} */
  2: const nextConfig = {
  3:     // Enable standalone output for Docker deployment
  4:     output: 'standalone',
  5:     
  6:     // Performance optimizations
  7:     compress: true, // Enable gzip compression
  8:     poweredByHeader: false, // Remove X-Powered-By header
  9:     
 10:     // Enable SWC minification (faster than Terser)
 11:     swcMinify: true,
 12:     
 13:     // Optimize production builds
 14:     productionBrowserSourceMaps: false, // Disable source maps in prod
 15:     
 16:     // React optimizations
 17:     reactStrictMode: true,
 18:     
 19:     i18n: {
 20:         locales: ['en', 'fr'],
 21:         defaultLocale: 'en',
 22:     },
 23:     env: {
 24:         MONGODB_URI: process.env.MONGODB_URI,
 25:         NEXTAUTH_SECRET: process.env.NEXTAUTH_SECRET,
 26:         NEXTAUTH_URL: process.env.NEXTAUTH_URL,
 27:         // OPENAI_API_KEY is deprecated; retaining only if legacy routes remain
 28:         // OPENAI_API_KEY: process.env.OPENAI_API_KEY,
 29:         PERPLEXITY_API_KEY: process.env.PERPLEXITY_API_KEY,
 30:         PERPLEXITY_BASE_URL: process.env.PERPLEXITY_BASE_URL || 'https://api.perplexity.ai',
 31:         PERPLEXITY_MODEL: process.env.PERPLEXITY_MODEL || 'sonar-pro',
 32:         // OpenAI assistant IDs deprecated after Perplexity migration
 33:         NEXT_PUBLIC_SENTRY_DSN: process.env.NEXT_PUBLIC_SENTRY_DSN,
 34:         NEXT_PUBLIC_ENVIRONMENT: process.env.NEXT_PUBLIC_ENVIRONMENT || process.env.RAILWAY_ENVIRONMENT_NAME || 'production',
 35:     },
 36:     async headers() {
 37:         return [{
 38:             source: '/(.*)',
 39:             headers: [
 40:                 { key: 'X-Content-Type-Options', value: 'nosniff' },
 41:                 { key: 'X-Frame-Options', value: 'SAMEORIGIN' },
 42:                 { key: 'Referrer-Policy', value: 'strict-origin-when-cross-origin' },
 43:                 { key: 'Permissions-Policy', value: 'geolocation=(), microphone=(), camera=()' },
 44:                 { key: 'Strict-Transport-Security', value: 'max-age=63072000; includeSubDomains; preload' },
 45:                 { key: 'Cross-Origin-Opener-Policy', value: 'same-origin' },
 46:                 { key: 'Cross-Origin-Resource-Policy', value: 'same-origin' },
 47:                 { key: 'X-DNS-Prefetch-Control', value: 'off' },
 48:                 {
 49:                     key: 'Content-Security-Policy',
 50:                     value: [
 51:                         "default-src 'self'",
 52:                         "script-src 'self' 'unsafe-inline' 'unsafe-eval' blob: data: https://cdnjs.cloudflare.com",
 53:                         "worker-src 'self' blob:",
 54:                         "style-src 'self' 'unsafe-inline' https:",
 55:                         "img-src 'self' data: blob:",
 56:                         "font-src 'self' data: https:",
 57:                         "connect-src 'self' https: wss:",
 58:                         "frame-src 'self' https://accounts.google.com",
 59:                         "object-src 'none'",
 60:                         "base-uri 'self'",
 61:                         "form-action 'self' https://accounts.google.com https://*.google.com https://*.googleusercontent.com"
 62:                     ].join('; ')
 63:                 }
 64:             ]
 65:         }]
 66:     },
 67:     images: {
 68:         domains: ['localhost'],
 69:         formats: ['image/avif', 'image/webp'], // Modern image formats
 70:         minimumCacheTTL: 60, // Cache images for 60 seconds
 71:         deviceSizes: [640, 750, 828, 1080, 1200, 1920, 2048, 3840],
 72:         imageSizes: [16, 32, 48, 64, 96, 128, 256, 384],
 73:     },
 74:     
 75:     // Experimental features for performance
 76:     experimental: {
 77:         // Optimize package imports (tree-shaking)
 78:         optimizePackageImports: [
 79:             '@heroicons/react', 
 80:             'lucide-react',
 81:             '@tanstack/react-query',
 82:             'react-hot-toast',
 83:             'recharts'
 84:         ],
 85:         // Disable CSS optimization to avoid critters dependency issue
 86:         // optimizeCss: true,
 87:     },
 88:     eslint: {
 89:         ignoreDuringBuilds: true,
 90:     },
 91:     typescript: {
 92:         // Allow disabling type-check during build via env to avoid OOM on small builders
 93:         ignoreBuildErrors: process.env.DISABLE_TYPECHECK === 'true',
 94:     },
 95:     webpack: (config, { isServer }) => {
 96:         // Avoid bundling optional 'canvas' dependency required by pdfjs in Node builds
 97:         config.resolve = config.resolve || {}
 98:         config.resolve.alias = config.resolve.alias || {}
 99:         config.resolve.alias['canvas'] = false
100:         if (isServer) {
101:             config.externals = config.externals || []
102:                 // Mark canvas as external in server to prevent resolution errors
103:             config.externals.push({ canvas: 'commonjs canvas' })
104:         }
105:         return config
106:     }
107: }
108: 
109: module.exports = nextConfig
</file>

<file path="src/app/resume-builder/page.tsx">
 1: import { Suspense } from 'react'
 2: import { getServerSession } from 'next-auth/next'
 3: import { redirect } from 'next/navigation'
 4: import { authOptions } from '@/lib/auth'
 5: import { ResumeBuilder } from './components/resume-builder'
 6: 
 7: export default async function ResumeBuilderPage() {
 8:   const session = await getServerSession(authOptions)
 9: 
10:   if (!session) {
11:     redirect('/auth/signin')
12:   }
13: 
14:   return (
15:     <div className="min-h-screen bg-background">
16:       <div className="mx-auto max-w-7xl px-4 py-8 sm:px-6 lg:px-8">
17:         <div className="mb-8">
18:           <h1 className="text-3xl font-bold text-foreground">Resume Builder</h1>
19:           <p className="mt-2 text-lg text-muted-foreground">
20:             Create professional, ATS-optimized resumes with AI assistance and beautiful templates
21:           </p>
22:         </div>
23: 
24:         <Suspense fallback={<ResumeBuilderSkeleton />}>
25:           <ResumeBuilder userId={session.user.id} />
26:         </Suspense>
27:       </div>
28:     </div>
29:   )
30: }
31: 
32: function ResumeBuilderSkeleton() {
33:   return (
34:     <div className="space-y-8">
35:       {/* Template Selection Skeleton */}
36:       <div className="bg-card rounded-lg p-6 shadow-sm animate-pulse">
37:         <div className="w-48 h-6 bg-gray-200 rounded mb-4"></div>
38:         <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
39:           {[...Array(3)].map((_, i) => (
40:             <div key={i} className="border rounded-lg p-4">
41:               <div className="w-full h-32 bg-gray-200 rounded mb-3"></div>
42:               <div className="w-20 h-4 bg-gray-200 rounded"></div>
43:             </div>
44:           ))}
45:         </div>
46:       </div>
47: 
48:       {/* Builder Interface Skeleton */}
49:       <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
50:         <div className="lg:col-span-2 space-y-6">
51:           {[...Array(4)].map((_, i) => (
52:             <div key={i} className="bg-card rounded-lg p-6 shadow-sm animate-pulse">
53:               <div className="w-32 h-6 bg-gray-200 rounded mb-4"></div>
54:               <div className="space-y-3">
55:                 <div className="w-full h-10 bg-gray-200 rounded"></div>
56:                 <div className="w-3/4 h-10 bg-gray-200 rounded"></div>
57:               </div>
58:             </div>
59:           ))}
60:         </div>
61: 
62:         <div className="space-y-6">
63:           <div className="bg-card rounded-lg p-6 shadow-sm animate-pulse">
64:             <div className="w-24 h-6 bg-gray-200 rounded mb-4"></div>
65:             <div className="w-full h-64 bg-gray-200 rounded"></div>
66:           </div>
67: 
68:           <div className="bg-card rounded-lg p-6 shadow-sm animate-pulse">
69:             <div className="w-20 h-6 bg-gray-200 rounded mb-4"></div>
70:             <div className="w-full h-32 bg-gray-200 rounded"></div>
71:           </div>
72:         </div>
73:       </div>
74:     </div>
75:   )
76: }
</file>

<file path="package.json">
  1: {
  2:     "name": "career-lever-ai",
  3:     "version": "1.0.0",
  4:     "description": "AI-powered job application assistant for resume customization and company research",
  5:     "main": "index.js",
  6:     "engines": {
  7:         "node": ">=20.x",
  8:         "npm": ">=10.0.0"
  9:     },
 10:     "scripts": {
 11:         "dev": "next dev",
 12:         "build": "next build",
 13:         "build:mobile": "node scripts/build-mobile.js",
 14:         "start": "next start -H 0.0.0.0 -p ${PORT:-8080}",
 15:         "lint": "next lint",
 16:         "type-check": "tsc --noEmit",
 17:         "check:env": "node scripts/check-env.js",
 18:         "prebuild": "echo '‚úÖ Environment variables will be validated at runtime'",
 19:         "test": "vitest run --reporter=verbose",
 20:         "debug:perplexity": "node debug-perplexity.js",
 21:         "test:perplexity": "PPX_DEBUG=true node -e \"require('./debug-perplexity.js')\"",
 22:         "cap:init": "npx cap init",
 23:         "cap:add:ios": "npx cap add ios",
 24:         "cap:add:android": "npx cap add android",
 25:         "cap:sync": "npx cap sync",
 26:         "cap:open:ios": "npx cap open ios",
 27:         "cap:open:android": "npx cap open android",
 28:         "mobile:build": "npm run build:mobile && npx cap sync",
 29:         "mobile:ios": "npm run mobile:build && npx cap open ios",
 30:         "mobile:android": "npm run mobile:build && npx cap open android"
 31:     },
 32:     "dependencies": {
 33:         "@auth/mongodb-adapter": "^3.10.0",
 34:         "@capacitor/android": "7.4.3",
 35:         "@capacitor/app": "7.1.0",
 36:         "@capacitor/core": "7.4.3",
 37:         "@capacitor/filesystem": "7.1.4",
 38:         "@capacitor/haptics": "7.0.2",
 39:         "@capacitor/ios": "7.4.3",
 40:         "@capacitor/keyboard": "7.0.3",
 41:         "@capacitor/network": "7.0.2",
 42:         "@capacitor/share": "7.0.2",
 43:         "@capacitor/splash-screen": "7.0.3",
 44:         "@capacitor/status-bar": "7.0.3",
 45:         "@heroicons/react": "^2.2.0",
 46:         "@hookform/resolvers": "^3.3.0",
 47:         "@next/env": "14.2.33",
 48:         "@radix-ui/react-alert-dialog": "^1.1.15",
 49:         "@radix-ui/react-avatar": "^1.1.10",
 50:         "@radix-ui/react-checkbox": "^1.3.3",
 51:         "@radix-ui/react-dialog": "^1.1.15",
 52:         "@radix-ui/react-dropdown-menu": "^2.1.16",
 53:         "@radix-ui/react-label": "^2.1.7",
 54:         "@radix-ui/react-progress": "^1.1.7",
 55:         "@radix-ui/react-select": "^2.2.6",
 56:         "@radix-ui/react-separator": "^1.1.7",
 57:         "@radix-ui/react-slot": "^1.0.0",
 58:         "@radix-ui/react-tabs": "^1.1.13",
 59:         "@radix-ui/react-toast": "^1.2.15",
 60:         "@react-pdf/renderer": "4.3.1",
 61:         "@sentry/nextjs": "^8.35.0",
 62:         "@sparticuz/chromium": "^138.0.2",
 63:         "@stripe/stripe-js": "8.1.0",
 64:         "@tanstack/react-query": "^5.90.2",
 65:         "@types/bcryptjs": "^2.4.6",
 66:         "@types/jsonwebtoken": "^9.0.0",
 67:         "@types/mongoose": "^5.11.97",
 68:         "@types/multer": "^1.4.11",
 69:         "@types/node": "^20.0.0",
 70:         "@types/pdfkit": "0.17.3",
 71:         "@types/react": "^18.2.0",
 72:         "@types/react-dom": "^18.2.0",
 73:         "ajv": "8.17.1",
 74:         "ajv-formats": "3.0.1",
 75:         "autoprefixer": "^10.4.0",
 76:         "bcryptjs": "^2.4.3",
 77:         "canvas-confetti": "1.9.3",
 78:         "chart.js": "4.5.1",
 79:         "cheerio": "1.1.2",
 80:         "class-variance-authority": "^0.7.0",
 81:         "clsx": "^2.1.1",
 82:         "date-fns": "^4.1.0",
 83:         "docx": "9.5.1",
 84:         "file-saver": "2.0.5",
 85:         "framer-motion": "10.18.0",
 86:         "ioredis": "5.8.2",
 87:         "isomorphic-dompurify": "^2.28.0",
 88:         "jsonwebtoken": "^9.0.0",
 89:         "jspdf": "^3.0.3",
 90:         "lucide-react": "^0.294.0",
 91:         "mongodb": "6.11.0",
 92:         "mongoose": "8.19.1",
 93:         "multer": "^1.4.5-lts.1",
 94:         "next": "14.2.33",
 95:         "next-auth": "^4.24.10",
 96:         "pdf-parse-debugging-disabled": "1.1.1",
 97:         "pdfjs-dist": "^4.2.0",
 98:         "pdfkit": "0.17.2",
 99:         "postcss": "^8.4.0",
100:         "puppeteer": "24.25.0",
101:         "puppeteer-core": "^24.22.0",
102:         "react": "^18.2.0",
103:         "react-chartjs-2": "5.3.0",
104:         "react-dom": "^18.2.0",
105:         "react-dropzone": "^14.2.0",
106:         "react-hook-form": "^7.48.0",
107:         "react-hot-toast": "^2.4.1",
108:         "redis": "4.6.14",
109:         "resend": "6.2.2",
110:         "stripe": "19.1.0",
111:         "tailwind-merge": "^2.6.0",
112:         "tailwindcss": "^3.3.0",
113:         "tailwindcss-animate": "^1.0.7",
114:         "zod": "^3.25.76",
115:         "zustand": "^5.0.8"
116:     },
117:     "overrides": {
118:         "next": "14.2.33",
119:         "@next/env": "14.2.33",
120:         "chromium-bidi": "0.5.10",
121:         "webdriver-bidi-protocol": "0.3.8"
122:     },
123:     "devDependencies": {
124:         "@capacitor/cli": "7.4.3",
125:         "@playwright/test": "1.56.1",
126:         "@tanstack/react-query-devtools": "^5.90.2",
127:         "@typescript-eslint/eslint-plugin": "6.21.0",
128:         "@typescript-eslint/parser": "6.21.0",
129:         "@vitest/coverage-v8": "3.2.4",
130:         "esbuild": "^0.25.10",
131:         "eslint": "8.57.1",
132:         "eslint-config-next": "^14.0.0",
133:         "mongodb-memory-server": "10.2.0",
134:         "prettier": "^3.0.0",
135:         "typescript": "5.3.3",
136:         "vitest": "^3.2.4"
137:     },
138:     "keywords": [
139:         "job-application",
140:         "resume",
141:         "ai",
142:         "career",
143:         "recruitment"
144:     ],
145:     "author": "Career Lever AI Team",
146:     "license": "MIT"
147: }
</file>

<file path="src/lib/scrapers/advanced-scraper.ts">
  1: /**
  2:  * Advanced Web Scraper with 4-Tier Fallback Strategy
  3:  * 
  4:  * Strategy 1: JSON-LD Structured Data (fastest, most reliable)
  5:  * Strategy 2: Cheerio HTML Parsing (fast, reliable for static sites)
  6:  * Strategy 3: Puppeteer Browser (for JavaScript-heavy sites)
  7:  * Strategy 4: Regex Extraction (last resort)
  8:  */
  9: 
 10: import * as cheerio from 'cheerio'
 11: import puppeteer from 'puppeteer-core'
 12: import chromium from '@sparticuz/chromium'
 13: 
 14: export interface ScrapeResult {
 15:   success: boolean
 16:   data?: {
 17:     title?: string
 18:     description?: string
 19:     requirements?: string[]
 20:     salary?: string
 21:     company?: string
 22:     location?: string
 23:     postedDate?: string
 24:   }
 25:   method?: 'structured' | 'cheerio' | 'puppeteer' | 'regex'
 26:   error?: string
 27: }
 28: 
 29: export class AdvancedScraper {
 30:   private readonly USER_AGENTS = [
 31:     'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
 32:     'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15',
 33:     'Mozilla/5.0 (X11; Linux x86_64; rv:121.0) Gecko/20100101 Firefox/121.0',
 34:     'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'
 35:   ]
 36: 
 37:   /**
 38:    * Main scraping method with 3-tier fallback
 39:    */
 40:   async scrape(url: string): Promise<ScrapeResult> {
 41:     if (process.env.PPX_DEBUG === 'true') {
 42:       console.log(`[SCRAPER] Processing: ${url}`)
 43:     }
 44: 
 45:     // Strategy 1: Structured data (JSON-LD) - fastest and most reliable
 46:     try {
 47:       const structured = await this.tryStructuredData(url)
 48:       if (structured.success && structured.data?.description && structured.data.description.length > 100) {
 49:         if (process.env.PPX_DEBUG === 'true') {
 50:           console.log('[SCRAPER] ‚úì Structured data found')
 51:         }
 52:         return { ...structured, method: 'structured' }
 53:       }
 54:     } catch (e) {
 55:       if (process.env.PPX_DEBUG === 'true') {
 56:         console.log('[SCRAPER] Structured data failed:', (e as Error).message)
 57:       }
 58:     }
 59: 
 60:     // Strategy 2: Cheerio HTML parsing - fast and reliable for static sites
 61:     try {
 62:       const cheerioResult = await this.tryCheerioScraping(url)
 63:       if (cheerioResult.success && cheerioResult.data?.description && cheerioResult.data.description.length > 100) {
 64:         if (process.env.PPX_DEBUG === 'true') {
 65:           console.log('[SCRAPER] ‚úì Cheerio parsing succeeded')
 66:         }
 67:         return { ...cheerioResult, method: 'cheerio' }
 68:       }
 69:     } catch (e) {
 70:       if (process.env.PPX_DEBUG === 'true') {
 71:         console.log('[SCRAPER] Cheerio failed:', (e as Error).message)
 72:       }
 73:     }
 74: 
 75:     // Strategy 3: Puppeteer browser - for JavaScript-heavy sites (Indeed, LinkedIn, etc.)
 76:     try {
 77:       const puppeteerResult = await this.tryPuppeteerScraping(url)
 78:       if (puppeteerResult.success && puppeteerResult.data?.description && puppeteerResult.data.description.length > 100) {
 79:         if (process.env.PPX_DEBUG === 'true') {
 80:           console.log('[SCRAPER] ‚úì Puppeteer scraping succeeded')
 81:         }
 82:         return { ...puppeteerResult, method: 'puppeteer' }
 83:       }
 84:     } catch (e) {
 85:       if (process.env.PPX_DEBUG === 'true') {
 86:         console.log('[SCRAPER] Puppeteer failed:', (e as Error).message)
 87:       }
 88:     }
 89: 
 90:     // Strategy 4: Regex extraction - last resort
 91:     try {
 92:       const regex = await this.tryRegexExtraction(url)
 93:       if (regex.success && regex.data?.description && regex.data.description.length > 100) {
 94:         if (process.env.PPX_DEBUG === 'true') {
 95:           console.log('[SCRAPER] ‚úì Regex extraction succeeded')
 96:         }
 97:         return { ...regex, method: 'regex' }
 98:       }
 99:     } catch (e) {
100:       if (process.env.PPX_DEBUG === 'true') {
101:         console.log('[SCRAPER] Regex failed:', (e as Error).message)
102:       }
103:     }
104: 
105:     return {
106:       success: false,
107:       error: 'All 4 scraping strategies failed - page may require login or CAPTCHA'
108:     }
109:   }
110: 
111:   /**
112:    * Strategy 1: Extract JSON-LD structured data
113:    * Many job boards include this for SEO
114:    */
115:   private async tryStructuredData(url: string): Promise<ScrapeResult> {
116:     const html = await this.fetchHTML(url)
117:     const jsonLdMatches = html.match(/<script type="application\/ld\+json">(.*?)<\/script>/gs)
118: 
119:     if (!jsonLdMatches) {
120:       return { success: false, error: 'No structured data found' }
121:     }
122: 
123:     for (const match of jsonLdMatches) {
124:       try {
125:         const json = JSON.parse(match.replace(/<\/?script[^>]*>/g, ''))
126: 
127:         // Check for JobPosting schema
128:         if (json['@type'] === 'JobPosting') {
129:           return {
130:             success: true,
131:             data: {
132:               title: json.title,
133:               description: json.description,
134:               company: json.hiringOrganization?.name,
135:               location: json.jobLocation?.address?.addressLocality || json.jobLocation?.address?.addressRegion,
136:               salary: this.extractSalaryFromStructured(json.baseSalary),
137:               postedDate: json.datePosted
138:             }
139:           }
140:         }
141:       } catch {
142:         continue
143:       }
144:     }
145: 
146:     return { success: false, error: 'No JobPosting structured data found' }
147:   }
148: 
149:   /**
150:    * Strategy 2: Cheerio HTML parsing
151:    * Works for most standard HTML pages
152:    */
153:   private async tryCheerioScraping(url: string): Promise<ScrapeResult> {
154:     const html = await this.fetchHTML(url)
155:     const $ = cheerio.load(html)
156: 
157:     // Remove noise elements
158:     $('script, style, nav, header, footer, aside, .advertisement, .ads').remove()
159: 
160:     // Try multiple selectors for description (ordered by specificity)
161:     const descriptionSelectors = [
162:       '.job-description',
163:       '[class*="job-description"]',
164:       '[class*="description"]',
165:       '[id*="description"]',
166:       '[class*="job-details"]',
167:       '[class*="jobDetails"]',
168:       '[data-job-description]',
169:       'article',
170:       'main',
171:       '.content'
172:     ]
173: 
174:     let description = ''
175:     for (const selector of descriptionSelectors) {
176:       const text = $(selector).text().trim()
177:       if (text.length > description.length && text.length > 100) {
178:         description = text
179:       }
180:     }
181: 
182:     // Extract title
183:     const title = 
184:       $('h1.job-title').text() ||
185:       $('[class*="job-title"]').first().text() ||
186:       $('[class*="jobTitle"]').first().text() ||
187:       $('h1').first().text() ||
188:       ''
189: 
190:     // Extract requirements
191:     const requirements: string[] = []
192:     $('.requirements li, .qualifications li, [class*="requirement"] li, [class*="qualification"] li').each((i, el) => {
193:       const req = $(el).text().trim()
194:       if (req && req.length > 10 && req.length < 500) {
195:         requirements.push(req)
196:       }
197:     })
198: 
199:     // Extract salary
200:     const salary = this.extractSalaryFromText(html)
201: 
202:     // Extract company
203:     const company = 
204:       $('[class*="company-name"]').first().text() ||
205:       $('[class*="companyName"]').first().text() ||
206:       $('[data-company]').text() ||
207:       ''
208: 
209:     // Extract location
210:     const location = 
211:       $('[class*="location"]').first().text() ||
212:       $('[class*="job-location"]').first().text() ||
213:       ''
214: 
215:     return {
216:       success: description.length > 100,
217:       data: {
218:         title: this.cleanText(title),
219:         description: this.cleanText(description),
220:         requirements,
221:         salary: this.cleanText(salary),
222:         company: this.cleanText(company),
223:         location: this.cleanText(location)
224:       }
225:     }
226:   }
227: 
228:   /**
229:    * Strategy 3: Puppeteer browser scraping (for JavaScript-heavy sites)
230:    * Handles Indeed, LinkedIn, Glassdoor, and other dynamic job boards
231:    */
232:   private async tryPuppeteerScraping(url: string): Promise<ScrapeResult> {
233:     let browser: Awaited<ReturnType<typeof puppeteer.launch>> | null = null
234:     try {
235:       // Launch headless browser with optimized settings
236:       const args = [
237:         ...chromium.args,
238:         '--no-sandbox',
239:         '--disable-setuid-sandbox',
240:         '--disable-dev-shm-usage',
241:         '--disable-gpu',
242:         '--no-first-run',
243:         '--no-zygote',
244:         '--single-process',
245:         '--disable-blink-features=AutomationControlled'
246:       ]
247: 
248:       const executablePath = process.env.CHROMIUM_PATH || await chromium.executablePath()
249: 
250:       browser = await puppeteer.launch({
251:         args,
252:         executablePath,
253:         headless: true,
254:         timeout: 30000
255:       })
256: 
257:       const page = await browser.newPage()
258: 
259:       // Set realistic user agent and viewport
260:       const userAgent = this.USER_AGENTS[Math.floor(Math.random() * this.USER_AGENTS.length)]
261:       await page.setUserAgent(userAgent)
262:       await page.setViewport({ width: 1920, height: 1080 })
263: 
264:       // Navigate to page and wait for content
265:       await page.goto(url, {
266:         waitUntil: 'networkidle2',
267:         timeout: 30000
268:       })
269: 
270:       // Wait for job description to load (common selectors)
271:       await page.waitForSelector('body', { timeout: 5000 }).catch(() => {})
272: 
273:       // Extract job data using page.evaluate
274:       const data = await page.evaluate(() => {
275:         // Helper to clean text
276:         const cleanText = (text: string) => text.replace(/\s+/g, ' ').trim()
277: 
278:         // Extract title
279:         const titleSelectors = [
280:           'h1[class*="title"]',
281:           'h1[class*="jobTitle"]',
282:           'h1[class*="job-title"]',
283:           '[data-testid="jobTitle"]',
284:           '.job-title',
285:           'h1'
286:         ]
287:         let title = ''
288:         for (const sel of titleSelectors) {
289:           const el = document.querySelector(sel)
290:           if (el?.textContent) {
291:             title = cleanText(el.textContent)
292:             break
293:           }
294:         }
295: 
296:         // Extract description
297:         const descSelectors = [
298:           '[class*="jobDescriptionText"]',
299:           '[class*="job-description"]',
300:           '[id*="jobDescriptionText"]',
301:           '[data-testid="jobDescription"]',
302:           '.description',
303:           'article',
304:           'main'
305:         ]
306:         let description = ''
307:         for (const sel of descSelectors) {
308:           const el = document.querySelector(sel)
309:           if (el?.textContent && el.textContent.length > description.length) {
310:             description = cleanText(el.textContent)
311:           }
312:         }
313: 
314:         // Extract company
315:         const companySelectors = [
316:           '[class*="companyName"]',
317:           '[data-testid="companyName"]',
318:           '[class*="company-name"]',
319:           '.company'
320:         ]
321:         let company = ''
322:         for (const sel of companySelectors) {
323:           const el = document.querySelector(sel)
324:           if (el?.textContent) {
325:             company = cleanText(el.textContent)
326:             break
327:           }
328:         }
329: 
330:         // Extract location
331:         const locationSelectors = [
332:           '[class*="location"]',
333:           '[data-testid="location"]',
334:           '[class*="job-location"]'
335:         ]
336:         let location = ''
337:         for (const sel of locationSelectors) {
338:           const el = document.querySelector(sel)
339:           if (el?.textContent) {
340:             location = cleanText(el.textContent)
341:             break
342:           }
343:         }
344: 
345:         // Extract salary
346:         const salarySelectors = [
347:           '[class*="salary"]',
348:           '[data-testid="salary"]',
349:           '[class*="compensation"]'
350:         ]
351:         let salary = ''
352:         for (const sel of salarySelectors) {
353:           const el = document.querySelector(sel)
354:           if (el?.textContent) {
355:             salary = cleanText(el.textContent)
356:             break
357:           }
358:         }
359: 
360:         return { title, description, company, location, salary }
361:       })
362: 
363:       await browser.close()
364: 
365:       return {
366:         success: data.description.length > 100,
367:         data: {
368:           title: data.title,
369:           description: data.description,
370:           company: data.company,
371:           location: data.location,
372:           salary: data.salary || undefined
373:         }
374:       }
375:     } catch (error) {
376:       if (browser) {
377:         try { await browser.close() } catch {}
378:       }
379:       throw error
380:     }
381:   }
382: 
383:   /**
384:    * Strategy 4: Regex extraction (last resort)
385:    * Works when HTML structure is non-standard
386:    */
387:   private async tryRegexExtraction(url: string): Promise<ScrapeResult> {
388:     const html = await this.fetchHTML(url)
389: 
390:     // Extract description between common patterns
391:     const descPatterns = [
392:       /<div[^>]*class="[^"]*description[^"]*"[^>]*>(.*?)<\/div>/is,
393:       /<section[^>]*class="[^"]*job[^"]*"[^>]*>(.*?)<\/section>/is,
394:       /<article[^>]*>(.*?)<\/article>/is,
395:       /<main[^>]*>(.*?)<\/main>/is
396:     ]
397: 
398:     let description = ''
399:     for (const pattern of descPatterns) {
400:       const match = html.match(pattern)
401:       if (match && match[1].length > description.length) {
402:         description = match[1]
403:       }
404:     }
405: 
406:     // Extract title
407:     const titleMatch = html.match(/<h1[^>]*>(.*?)<\/h1>/i)
408:     const title = titleMatch ? titleMatch[1] : ''
409: 
410:     return {
411:       success: description.length > 100,
412:       data: {
413:         title: this.cleanHTML(title),
414:         description: this.cleanHTML(description)
415:       }
416:     }
417:   }
418: 
419:   /**
420:    * Fetch HTML with realistic headers to avoid bot detection
421:    */
422:   private async fetchHTML(url: string): Promise<string> {
423:     const userAgent = this.USER_AGENTS[Math.floor(Math.random() * this.USER_AGENTS.length)]
424: 
425:     const response = await fetch(url, {
426:       headers: {
427:         'User-Agent': userAgent,
428:         'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
429:         'Accept-Language': 'en-US,en;q=0.9',
430:         'Accept-Encoding': 'gzip, deflate, br',
431:         'DNT': '1',
432:         'Connection': 'keep-alive',
433:         'Upgrade-Insecure-Requests': '1',
434:         'Referer': 'https://www.google.com/'
435:       },
436:       signal: AbortSignal.timeout(15000)
437:     })
438: 
439:     if (!response.ok) {
440:       throw new Error(`HTTP ${response.status}: ${response.statusText}`)
441:     }
442: 
443:     // Add small delay to be respectful
444:     await new Promise(resolve => setTimeout(resolve, 500 + Math.random() * 1000))
445: 
446:     return await response.text()
447:   }
448: 
449:   /**
450:    * Helper: Extract salary from structured data
451:    */
452:   private extractSalaryFromStructured(baseSalary: any): string {
453:     if (!baseSalary) return ''
454:     if (typeof baseSalary === 'string') return baseSalary
455:     
456:     if (baseSalary.value) {
457:       const value = baseSalary.value.value || baseSalary.value
458:       const currency = baseSalary.currency || '$'
459:       return `${currency}${value}`
460:     }
461:     
462:     if (baseSalary.minValue && baseSalary.maxValue) {
463:       const currency = baseSalary.currency || '$'
464:       return `${currency}${baseSalary.minValue} - ${currency}${baseSalary.maxValue}`
465:     }
466:     
467:     return ''
468:   }
469: 
470:   /**
471:    * Helper: Extract salary from text using patterns
472:    */
473:   private extractSalaryFromText(text: string): string {
474:     const patterns = [
475:       /\$\s*[\d,]+\s*-\s*\$\s*[\d,]+/,
476:       /\$\s*[\d,]+k?\s*-\s*\$?\s*[\d,]+k?/i,
477:       /salary:\s*\$?[\d,]+\s*-\s*\$?[\d,]+/i,
478:       /[\d,]+\s*-\s*[\d,]+\s*per\s+(?:year|hour|month)/i,
479:       /compensation:\s*\$?[\d,]+\s*-\s*\$?[\d,]+/i
480:     ]
481: 
482:     for (const pattern of patterns) {
483:       const match = text.match(pattern)
484:       if (match) return match[0]
485:     }
486: 
487:     return ''
488:   }
489: 
490:   /**
491:    * Helper: Clean HTML tags and entities
492:    */
493:   private cleanHTML(html: string): string {
494:     return html
495:       .replace(/<script[^>]*>.*?<\/script>/gis, '')
496:       .replace(/<style[^>]*>.*?<\/style>/gis, '')
497:       .replace(/<[^>]+>/g, ' ')
498:       .replace(/&nbsp;/g, ' ')
499:       .replace(/&amp;/g, '&')
500:       .replace(/&lt;/g, '<')
501:       .replace(/&gt;/g, '>')
502:       .replace(/&quot;/g, '"')
503:       .replace(/&#39;/g, "'")
504:       .replace(/\s+/g, ' ')
505:       .trim()
506:   }
507: 
508:   /**
509:    * Helper: Clean text (whitespace only)
510:    */
511:   private cleanText(text: string): string {
512:     return text
513:       .replace(/\s+/g, ' ')
514:       .replace(/\n\s*\n/g, '\n')
515:       .trim()
516:   }
517: }
</file>

<file path="src/app/api/resume/upload/route.ts">
  1: import { NextRequest, NextResponse } from 'next/server'
  2: import { getServerSession } from 'next-auth/next'
  3: import { authOptions } from '@/lib/auth'
  4: import Resume from '@/models/Resume'
  5: import { dbService } from '@/lib/database'
  6: import { isRateLimited } from '@/lib/rate-limit'
  7: import path from 'path'
  8: import { cleanPDFExtraction } from '@/lib/utils/pdf-cleaner'
  9: 
 10: function cleanExtractedText(text: string): string {
 11:   // Use comprehensive PDF cleaner first
 12:   let cleaned = cleanPDFExtraction(text)
 13:   
 14:   // Additional cleaning for resume-specific content
 15:   cleaned = cleaned
 16:     .replace(/https?:\/\/[^\s]+/gi, '') // URLs
 17:     .replace(/[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/gi, '') // Emails (during parsing)
 18:     .replace(/\s+/g, ' ') // Whitespace
 19:     .trim()
 20:   
 21:   return cleaned
 22: }
 23: 
 24: const MIN_VALID_PDF_TEXT_LENGTH = Number(process.env.RESUME_MIN_TEXT_LENGTH || 150)
 25: const ASCII_FALLBACK_CONFIDENCE = 0.3
 26: 
 27: // AI-based OCR fallback using base64 encoding
 28: async function extractTextWithAI(buffer: Buffer): Promise<string> {
 29:   try {
 30:     console.log('[PDF_PARSE] Attempting AI-based extraction')
 31:     const { PerplexityIntelligenceService } = await import('@/lib/perplexity-intelligence')
 32:     
 33:     // Convert PDF to base64
 34:     const base64 = buffer.toString('base64')
 35:     
 36:     const result = await PerplexityIntelligenceService.customQuery({
 37:       systemPrompt: 'You are a resume text extractor. Extract ALL text from the provided PDF resume. Return ONLY the extracted text, no formatting, no markdown, no explanations.',
 38:       userPrompt: `Extract all text from this PDF resume (base64 encoded, first 1000 chars): ${base64.slice(0, 1000)}...\n\nReturn the complete resume text.`,
 39:       temperature: 0.1,
 40:       maxTokens: 4000
 41:     })
 42:     
 43:     if (result.content && result.content.length > MIN_VALID_PDF_TEXT_LENGTH) {
 44:       console.log('[PDF_PARSE] ‚úÖ AI extraction SUCCESS:', result.content.length, 'chars')
 45:       return result.content
 46:     }
 47:     
 48:     throw new Error('AI extraction returned insufficient text')
 49:   } catch (error) {
 50:     console.error('[PDF_PARSE] ‚ùå AI extraction failed:', error)
 51:     throw error
 52:   }
 53: }
 54: 
 55: async function extractTextFromPDF(buffer: Buffer): Promise<{ text: string; method: string; confidence?: number }> {
 56:   console.log('[PDF_PARSE] ==========================================')
 57:   console.log('[PDF_PARSE] Starting extraction')
 58:   console.log('[PDF_PARSE] Buffer size:', buffer.length, 'bytes')
 59:   console.log('[PDF_PARSE] Buffer type:', typeof buffer)
 60:   console.log('[PDF_PARSE] Is Buffer:', Buffer.isBuffer(buffer))
 61:   console.log('[PDF_PARSE] ==========================================')
 62:   
 63:   // Try Method 1: pdf-parse-debugging-disabled (MOST RELIABLE)
 64:   try {
 65:     console.log('[PDF_PARSE] üîÑ Method 1: pdf-parse-debugging-disabled')
 66:     const pdfParse = await import('pdf-parse-debugging-disabled')
 67:     console.log('[PDF_PARSE] Module loaded:', !!pdfParse, 'default:', !!pdfParse.default)
 68:     
 69:     const data = await pdfParse.default(buffer, { 
 70:       max: 0, // Parse all pages
 71:       version: 'v2.0.550' // Specify version
 72:     })
 73:     
 74:     console.log('[PDF_PARSE] Raw result:', {
 75:       hasData: !!data,
 76:       hasText: !!data?.text,
 77:       textLength: data?.text?.length || 0,
 78:       numpages: data?.numpages,
 79:       numrender: data?.numrender,
 80:       info: data?.info,
 81:       metadata: data?.metadata
 82:     })
 83:     
 84:     if (data?.text) {
 85:       console.log('[PDF_PARSE] Raw text preview (first 500 chars):', data.text.slice(0, 500))
 86:       console.log('[PDF_PARSE] Raw text preview (last 200 chars):', data.text.slice(-200))
 87:       
 88:       const cleanedText = cleanExtractedText(data.text)
 89:       console.log('[PDF_PARSE] After cleaning:', {
 90:         rawLength: data.text.length,
 91:         cleanedLength: cleanedText.length,
 92:         preview: cleanedText.slice(0, 300)
 93:       })
 94:       
 95:       if (cleanedText.length >= 50) {
 96:         const confidence = cleanedText.length >= MIN_VALID_PDF_TEXT_LENGTH ? 0.95 : 0.6
 97:         console.log('[PDF_PARSE] ‚úÖ‚úÖ‚úÖ Method 1 SUCCESS - confidence:', confidence)
 98:         return {
 99:           text: cleanedText,
100:           method: 'pdf-parse',
101:           confidence
102:         }
103:       } else {
104:         console.log('[PDF_PARSE] ‚ö†Ô∏è Method 1 extracted text but too short:', cleanedText.length, 'chars')
105:       }
106:     } else {
107:       console.log('[PDF_PARSE] ‚ö†Ô∏è Method 1 returned no text')
108:     }
109:   } catch (error: any) {
110:     console.error('[PDF_PARSE] ‚ùå Method 1 FAILED')
111:     console.error('[PDF_PARSE] Error type:', error?.constructor?.name)
112:     console.error('[PDF_PARSE] Error message:', error?.message)
113:     console.error('[PDF_PARSE] Error stack:', error?.stack)
114:   }
115: 
116:   // Try Method 2: pdfjs-dist fallback (BETTER for complex PDFs)
117:   try {
118:     console.log('[PDF_PARSE] üîÑ Method 2: pdfjs-dist')
119:     const pdfjsLib = await import('pdfjs-dist')
120:     console.log('[PDF_PARSE] pdfjs-dist module loaded')
121:     
122:     // Load the PDF document with proper TypeScript types
123:     const loadingTask = pdfjsLib.getDocument({
124:       data: new Uint8Array(buffer),
125:       verbosity: 0,
126:       useSystemFonts: true,
127:       disableFontFace: false,
128:       standardFontDataUrl: 'https://cdn.jsdelivr.net/npm/pdfjs-dist@4.10.38/standard_fonts/'
129:     })
130:     
131:     const pdfDoc = await loadingTask.promise
132:     console.log('[PDF_PARSE] Document loaded successfully')
133:     console.log('[PDF_PARSE] Pages:', pdfDoc.numPages)
134:     console.log('[PDF_PARSE] Fingerprints:', pdfDoc.fingerprints)
135:     
136:     let fullText = ''
137:     let totalChars = 0
138:     
139:     // Extract text from each page
140:     for (let pageNum = 1; pageNum <= pdfDoc.numPages; pageNum++) {
141:       try {
142:         const page = await pdfDoc.getPage(pageNum)
143:         const textContent = await page.getTextContent()
144:         
145:         // Better text extraction with spacing
146:         const pageText = textContent.items
147:           .map((item: any) => {
148:             if ('str' in item && item.str) {
149:               return item.str
150:             }
151:             return ''
152:           })
153:           .filter(Boolean)
154:           .join(' ')
155:         
156:         fullText += pageText + '\n\n'
157:         totalChars += pageText.length
158:         console.log(`[PDF_PARSE] Page ${pageNum}/${pdfDoc.numPages}: ${pageText.length} chars (total: ${totalChars})`)
159:       } catch (pageError) {
160:         console.error(`[PDF_PARSE] Error on page ${pageNum}:`, pageError)
161:       }
162:     }
163:     
164:     console.log('[PDF_PARSE] Raw extraction complete:', fullText.length, 'chars')
165:     console.log('[PDF_PARSE] Raw text preview:', fullText.slice(0, 500))
166:     
167:     const cleanedText = cleanExtractedText(fullText.trim())
168:     console.log('[PDF_PARSE] After cleaning:', {
169:       rawLength: fullText.length,
170:       cleanedLength: cleanedText.length,
171:       preview: cleanedText.slice(0, 300)
172:     })
173:     
174:     if (cleanedText.length >= 50) {
175:       const confidence = cleanedText.length >= MIN_VALID_PDF_TEXT_LENGTH ? 0.9 : 0.6
176:       console.log('[PDF_PARSE] ‚úÖ‚úÖ‚úÖ Method 2 SUCCESS - confidence:', confidence)
177:       return {
178:         text: cleanedText,
179:         method: 'pdfjs-dist',
180:         confidence
181:       }
182:     } else {
183:       console.log('[PDF_PARSE] ‚ö†Ô∏è Method 2 extracted text but too short:', cleanedText.length, 'chars')
184:     }
185:   } catch (error: any) {
186:     console.error('[PDF_PARSE] ‚ùå Method 2 FAILED')
187:     console.error('[PDF_PARSE] Error type:', error?.constructor?.name)
188:     console.error('[PDF_PARSE] Error message:', error?.message)
189:     console.error('[PDF_PARSE] Error stack:', error?.stack)
190:   }
191: 
192:   // Try Method 3: AI-based extraction (BEST for scanned/image PDFs)
193:   try {
194:     console.log('[PDF_PARSE] Attempting Method 3: AI extraction')
195:     const aiText = await extractTextWithAI(buffer)
196:     
197:     if (aiText && aiText.length >= MIN_VALID_PDF_TEXT_LENGTH) {
198:       const cleanedText = cleanExtractedText(aiText)
199:       console.log('[PDF_PARSE] ‚úÖ Method 3 SUCCESS (AI extraction):', cleanedText.length, 'chars')
200:       
201:       return {
202:         text: cleanedText,
203:         method: 'ai-extraction',
204:         confidence: 0.8
205:       }
206:     }
207:   } catch (error) {
208:     console.error('[PDF_PARSE] ‚ùå Method 3 failed:', error)
209:   }
210: 
211:   // All methods failed
212:   console.error('[PDF_PARSE] ‚ùå‚ùå‚ùå ALL EXTRACTION METHODS FAILED')
213:   return {
214:     text: '',
215:     method: 'all-methods-failed',
216:     confidence: 0
217:   }
218: }
219: 
220: export const runtime = 'nodejs'
221: export const dynamic = 'force-dynamic'
222: 
223: export async function POST(request: NextRequest) {
224:   const startTime = Date.now()
225:   console.log('[RESUME_UPLOAD] ========== NEW UPLOAD REQUEST ==========')
226:   
227:   try {
228:     await dbService.connect()
229: 
230:     const session = await getServerSession(authOptions)
231:     if (!session?.user?.id) {
232:       console.log('[RESUME_UPLOAD] ‚ùå Unauthorized')
233:       return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
234:     }
235:     
236:     console.log('[RESUME_UPLOAD] User:', session.user.id, session.user.email)
237: 
238:     if (await isRateLimited(session.user.id, 'resume:upload')) {
239:       console.log('[RESUME_UPLOAD] ‚ùå Rate limited')
240:       return NextResponse.json({ error: 'Rate limited' }, { status: 429 })
241:     }
242: 
243:     const data = await request.formData()
244:     const file = data.get('file') as File
245:     const pastedText = data.get('pastedText') as string
246:     
247:     console.log('[RESUME_UPLOAD] Upload type:', {
248:       hasFile: !!file,
249:       fileSize: file?.size,
250:       fileName: file?.name,
251:       hasPastedText: !!pastedText,
252:       pastedTextLength: pastedText?.length
253:     })
254: 
255:     if (!file && !pastedText) {
256:       console.log('[RESUME_UPLOAD] ‚ùå No file or text provided')
257:       return NextResponse.json({ error: 'No file or text provided' }, { status: 400 })
258:     }
259: 
260:     let extractedText = ''
261:     let extractionMethod = ''
262:     let extractionError = ''
263:     let extractionConfidence = 0.95
264: 
265:     if (file && file.size > 0) {
266:       // Validate file size and type
267:       if (file.size > 10 * 1024 * 1024) {
268:         return NextResponse.json({ error: 'File too large' }, { status: 400 })
269:       }
270: 
271:       const buffer = Buffer.from(await file.arrayBuffer())
272:       const filename = file.name || 'resume.pdf'
273: 
274:       if (path.extname(filename).toLowerCase() === '.pdf') {
275:         try {
276:           const { text, method, confidence } = await extractTextFromPDF(buffer)
277:           extractedText = text
278:           extractionMethod = method
279:           extractionConfidence = confidence || 0.95
280:           
281:           // Enhanced logging
282:           console.log('üîç PDF Processing Result:', {
283:             filename,
284:             method: extractionMethod,
285:             textLength: extractedText?.length,
286:             confidence: extractionConfidence,
287:             firstWords: extractedText?.slice(0, 100)
288:           })
289:           
290:           if (!text || text.length < MIN_VALID_PDF_TEXT_LENGTH) {
291:             extractionError = 'PDF text extraction was incomplete. Please paste your resume content instead.'
292:           }
293:         } catch (pdfError) {
294:           console.error('PDF processing failed completely:', pdfError)
295:           extractionError = 'PDF processing failed. Please paste your resume text or try a different file format.'
296:           extractionMethod = 'pdf-failed'
297:         }
298:       } else {
299:         extractedText = await file.text()
300:         extractionMethod = 'direct_text'
301:         extractionConfidence = 1.0
302:       }
303:     } else if (pastedText) {
304:       extractedText = pastedText
305:       extractionMethod = 'pasted_text'
306:     }
307: 
308:     extractedText = cleanExtractedText(extractedText || '')
309: 
310:     const asciiFallbackUsed = extractionMethod === 'ascii-fallback'
311: 
312:     if (asciiFallbackUsed) {
313:       extractionError = extractionError || 'PDF could not be reliably processed (ASCII fallback). Please paste your resume text instead.'
314:       extractionConfidence = Math.min(extractionConfidence, ASCII_FALLBACK_CONFIDENCE)
315:     }
316: 
317:     if (!extractedText || extractedText.length < MIN_VALID_PDF_TEXT_LENGTH) {
318:       return NextResponse.json({ 
319:         error: 'No readable content', 
320:         details: extractionError || 'Could not extract text from the file. Please paste your resume text instead.',
321:         extractionMethod 
322:       }, { status: 400 })
323:     }
324: 
325:     if (asciiFallbackUsed) {
326:       return NextResponse.json({
327:         error: 'Resume quality too low',
328:         details: extractionError,
329:         extractionMethod,
330:         confidence: extractionConfidence
331:       }, { status: 400 })
332:     }
333: 
334:     // CRITICAL FIX: Extract location and keywords from resume text
335:     console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
336:     console.log('[PDF UPLOAD] EXTRACTING RESUME SIGNALS (Location + Keywords)')
337:     console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
338:     console.log('[PDF UPLOAD] Resume text length:', extractedText.length, 'chars')
339:     console.log('[PDF UPLOAD] First 300 chars:', extractedText.substring(0, 300))
340:     console.log('‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ')
341: 
342:     let extractedLocation: string | undefined
343:     let extractedKeywords: string[] = []
344:     let personalInfo: any = {}
345: 
346:     try {
347:       const { PerplexityIntelligenceService } = await import('@/lib/perplexity-intelligence')
348:       const signals = await PerplexityIntelligenceService.extractResumeSignals(extractedText, 50)
349:       
350:       extractedLocation = signals.location
351:       extractedKeywords = signals.keywords || []
352:       personalInfo = signals.personalInfo || {}
353: 
354:       console.log('[PDF UPLOAD] EXTRACTION RESULTS:')
355:       console.log('[PDF UPLOAD] Location extracted:', extractedLocation || 'NONE')
356:       console.log('[PDF UPLOAD] Keywords extracted:', extractedKeywords.length, 'keywords')
357:       console.log('[PDF UPLOAD] First 10 keywords:', extractedKeywords.slice(0, 10).join(', ') || 'NONE')
358:       console.log('[PDF UPLOAD] Personal info:', personalInfo)
359: 
360:       // CRITICAL: Fail if no real location found
361:       if (!extractedLocation || extractedLocation.trim().length < 2) {
362:         console.error('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
363:         console.error('[PDF UPLOAD] ‚ùå EXTRACTION FAILED - NO LOCATION')
364:         console.error('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
365:         console.error('[PDF UPLOAD] Extracted location:', extractedLocation || 'undefined')
366:         console.error('[PDF UPLOAD] Resume preview (first 500 chars):', extractedText.substring(0, 500))
367:         console.error('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
368:         
369:         return NextResponse.json({
370:           error: 'Could not extract location from resume',
371:           details: 'Please ensure your resume includes your city and state/province in the contact section at the top.',
372:           extractedLocation: extractedLocation,
373:           resumePreview: extractedText.substring(0, 300),
374:           suggestion: 'Add your location (e.g., "Seattle, WA" or "Toronto, ON") to the top of your resume and try again.'
375:         }, { status: 400 })
376:       }
377: 
378:       console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
379:       console.log('[PDF UPLOAD] ‚úÖ EXTRACTION SUCCESSFUL')
380:       console.log('[PDF UPLOAD] Location:', extractedLocation)
381:       console.log('[PDF UPLOAD] Keywords:', extractedKeywords.length, 'extracted')
382:       console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
383:     } catch (signalError) {
384:       console.error('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
385:       console.error('[PDF UPLOAD] ‚ùå SIGNAL EXTRACTION FAILED')
386:       console.error('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
387:       console.error('[PDF UPLOAD] Error:', (signalError as Error).message)
388:       console.error('[PDF UPLOAD] Stack:', (signalError as Error).stack)
389:       console.error('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
390:       
391:       return NextResponse.json({
392:         error: 'Failed to extract resume information',
393:         details: 'Could not parse location and keywords from your resume. Please ensure your resume is properly formatted with contact information at the top.',
394:         technical: (signalError as Error).message
395:       }, { status: 500 })
396:     }
397: 
398:     const resume = new Resume({
399:       userId: session.user.id,
400:       originalFileName: file?.name || 'pasted-resume.txt',
401:       filename: file?.name || 'pasted-resume.txt',
402:       extractedText,
403:       extractionMethod,
404:       extractionError: extractionError || undefined,
405:       uploadedAt: new Date(),
406:       // Store extracted signals for job matching
407:       metadata: {
408:         extractedLocation,
409:         extractedKeywords: extractedKeywords.slice(0, 20), // Store top 20
410:         personalInfo,
411:         extractionDate: new Date().toISOString()
412:       }
413:     })
414: 
415:     await resume.save()
416:     
417:     const duration = Date.now() - startTime
418:     console.log('[RESUME_UPLOAD] ‚úÖ SUCCESS:', {
419:       resumeId: resume._id.toString(),
420:       textLength: extractedText.length,
421:       method: extractionMethod,
422:       confidence: extractionConfidence,
423:       durationMs: duration
424:     })
425: 
426:     return NextResponse.json({
427:       success: true,
428:       resume: {
429:         _id: resume._id.toString(),
430:         userId: resume.userId,
431:         originalFileName: resume.originalFileName,
432:         filename: resume.filename,
433:         extractedText: resume.extractedText,
434:         extractionMethod: resume.extractionMethod,
435:         uploadedAt: resume.uploadedAt,
436:         metadata: resume.metadata
437:       },
438:       resumeId: resume._id,
439:       extractedText: extractedText.substring(0, 500) + (extractedText.length > 500 ? '...' : ''),
440:       extractionMethod,
441:       extractionError,
442:       confidence: extractionConfidence,
443:       // Include extracted signals in response for frontend
444:       extractedLocation,
445:       extractedKeywords: extractedKeywords.slice(0, 10), // Top 10 for display
446:       personalInfo
447:     })
448:   } catch (error) {
449:     console.error('Upload error:', error)
450:     const errorMessage = error instanceof Error ? error.message : 'Internal server error'
451:     
452:     // Provide helpful error messages based on error type
453:     let userMessage = 'Failed to process resume'
454:     let helpText = 'Please try again or paste your resume text directly.'
455:     
456:     if (errorMessage.includes('validation')) {
457:       userMessage = 'Invalid resume data'
458:       helpText = 'Please ensure your resume contains valid text.'
459:     } else if (errorMessage.includes('database') || errorMessage.includes('mongo')) {
460:       userMessage = 'Database connection error'
461:       helpText = 'Please try again in a moment.'
462:     } else if (errorMessage.includes('memory') || errorMessage.includes('heap')) {
463:       userMessage = 'File too complex to process'
464:       helpText = 'Try a simpler PDF or paste your text instead.'
465:     }
466:     
467:     return NextResponse.json({ 
468:       error: userMessage,
469:       details: helpText,
470:       technical: process.env.NODE_ENV === 'development' ? errorMessage : undefined
471:     }, { status: 500 })
472:   }
473: }
</file>

<file path="src/lib/agents/job-discovery-agent.ts">
  1: /**
  2:  * JOB DISCOVERY AGENT
  3:  * Autonomous job search across 15+ boards with Perplexity web_search + Cheerio fallback
  4:  */
  5: 
  6: import { BaseAgent, AgentTask, AgentResult } from './base-agent'
  7: import { COMPREHENSIVE_JOB_BOARDS, getTopJobBoards } from '../comprehensive-data-sources'
  8: import { AdvancedScraper } from '../scrapers/advanced-scraper'
  9: 
 10: export interface JobListing {
 11:   id?: string
 12:   title: string
 13:   company: string
 14:   location: string
 15:   url: string
 16:   summary: string
 17:   salary?: string | null
 18:   postedDate?: string
 19:   source: string
 20:   skills?: string[]
 21:   workType?: 'remote' | 'hybrid' | 'onsite'
 22:   skillMatchPercent?: number
 23:   description?: string
 24: }
 25: 
 26: export class JobDiscoveryAgent extends BaseAgent {
 27:   private scraper: AdvancedScraper
 28: 
 29:   constructor() {
 30:     super('Job Discovery Agent')
 31:     this.scraper = new AdvancedScraper()
 32:   }
 33: 
 34:   async execute(task: AgentTask): Promise<AgentResult<JobListing[]>> {
 35:     const { jobTitle, location, maxResults = 30 } = task.input
 36:     const started = Date.now()
 37: 
 38:     this.log(`üîç Searching for "${jobTitle}" in "${location}" across 15 job boards...`)
 39: 
 40:     // Get top 10 job boards by priority
 41:     const boards = getTopJobBoards(10)
 42:     const searchUrls = boards.map(b => ({
 43:       name: b.name,
 44:       url: b.searchUrl(jobTitle, location),
 45:       priority: b.priority
 46:     }))
 47: 
 48:     this.log(`üìä Targeting ${searchUrls.length} job boards`)
 49: 
 50:     // Try Perplexity agent first
 51:     try {
 52:       const perplexityJobs = await this.searchWithPerplexity(jobTitle, location, maxResults, searchUrls)
 53:       
 54:       if (perplexityJobs.length >= maxResults * 0.7) {
 55:         this.log(`‚úÖ Perplexity found ${perplexityJobs.length} jobs`)
 56:         return {
 57:           success: true,
 58:           data: perplexityJobs,
 59:           reasoning: 'Perplexity agent successfully searched multiple job boards using web_search',
 60:           confidence: perplexityJobs.length / maxResults,
 61:           sources: perplexityJobs.map(j => ({ title: j.title, url: j.url })),
 62:           duration: Date.now() - started,
 63:           method: 'perplexity'
 64:         }
 65:       }
 66:       
 67:       this.log(`‚ö†Ô∏è Perplexity only found ${perplexityJobs.length} jobs, trying fallback...`)
 68:     } catch (error) {
 69:       this.log(`‚ùå Perplexity failed: ${(error as Error).message}`, 'error')
 70:     }
 71: 
 72:     // Fallback: Parallel Cheerio scraping
 73:     this.log(`üîÑ Falling back to parallel Cheerio scraping...`)
 74:     const cheerioJobs = await this.searchWithCheerio(searchUrls, maxResults)
 75: 
 76:     return {
 77:       success: cheerioJobs.length > 0,
 78:       data: cheerioJobs,
 79:       reasoning: 'Perplexity failed, used parallel Cheerio scraping across multiple boards',
 80:       confidence: cheerioJobs.length / maxResults,
 81:       sources: cheerioJobs.map(j => ({ title: j.title, url: j.url })),
 82:       duration: Date.now() - started,
 83:       method: 'cheerio'
 84:     }
 85:   }
 86: 
 87:   private async searchWithPerplexity(
 88:     jobTitle: string,
 89:     location: string,
 90:     maxResults: number,
 91:     searchUrls: Array<{ name: string; url: string; priority: number }>
 92:   ): Promise<JobListing[]> {
 93:     const prompt = `üî¥ AUTONOMOUS JOB SEARCH MISSION üî¥
 94: 
 95: TASK: Find EXACTLY ${maxResults} real job listings for "${jobTitle}" in "${location}"
 96: 
 97: MANDATORY STEPS:
 98: 1. **USE web_search tool** to visit these job board URLs (search in parallel):
 99: ${searchUrls.map((s, i) => `   ${i+1}. ${s.name}: ${s.url}`).join('\n')}
100: 
101: 2. For EACH job found:
102:    - EXTRACT the job title, company, location from search results
103:    - CLICK the job URL and visit the actual posting page
104:    - SCRAPE the COMPLETE job description (minimum 300 characters)
105:    - VERIFY company name is NOT "Confidential" (skip those immediately)
106:    - EXTRACT salary if visible on the page
107:    - GET the posted date
108: 
109: 3. PRIORITIZE:
110:    - Posted within last 14 days (prefer last 7 days)
111:    - Remote or hybrid work options
112:    - Companies with clear names (not "Confidential")
113:    - Jobs with detailed descriptions
114: 
115: CRITICAL RULES:
116: ‚úÖ Return EXACTLY ${maxResults} jobs (or as many as you can find up to ${maxResults})
117: ‚úÖ Each description should be >100 characters (from actual job page content)
118: ‚úÖ REJECT any job with "Confidential" in company name
119: ‚úÖ Include actual clickable URLs to job postings
120: ‚úÖ Extract real salary data if available
121: ‚úÖ Get actual posted dates
122: 
123: OUTPUT FORMAT (strict JSON array):
124: [{
125:   "title": "Exact title from posting",
126:   "company": "Real company name (NOT Confidential)",
127:   "location": "${location}",
128:   "url": "https://actual-job-posting-url.com",
129:   "summary": "Full job description from the actual page (300+ chars)",
130:   "salary": "$XX,XXX - $YY,XXX" or null,
131:   "postedDate": "YYYY-MM-DD",
132:   "source": "indeed|linkedin|glassdoor|jobbank|etc",
133:   "skills": ["skill1", "skill2", "skill3"],
134:   "workType": "remote|hybrid|onsite",
135:   "skillMatchPercent": 75
136: }]
137: 
138: REASONING: After the JSON, explain:
139: - Which job boards you searched
140: - How many jobs you found on each board
141: - Why you selected these specific jobs
142: - Any challenges you encountered
143: 
144: üö® I WILL REJECT YOUR RESPONSE IF:
145: - Less than ${Math.floor(maxResults * 0.5)} jobs returned
146: - Any "Confidential" companies included
147: - Any dead/broken URLs
148: - Made up or fake job listings
149: 
150: START YOUR SEARCH NOW using web_search tool!`
151: 
152:     try {
153:       const response = await this.think(prompt, { maxTokens: 12000, temperature: 0.3 })
154:       
155:       // Try multiple JSON extraction methods
156:       let jobs: JobListing[] = []
157:       
158:       // Method 1: Find JSON array with proper brackets
159:       const jsonMatch = response.match(/\[\s*\{[\s\S]*?\}\s*\]/)?.[0]
160:       if (jsonMatch) {
161:         try {
162:           jobs = JSON.parse(jsonMatch)
163:           this.log(`‚úÖ Extracted JSON using method 1`)
164:         } catch (e) {
165:           this.log(`‚ö†Ô∏è Method 1 failed: ${(e as Error).message}`, 'warn')
166:         }
167:       }
168:       
169:       // Method 2: Try to find and fix common JSON errors
170:       if (jobs.length === 0) {
171:         try {
172:           // Remove markdown code blocks
173:           let cleaned = response.replace(/```json\s*/g, '').replace(/```\s*/g, '')
174:           // Find array
175:           const arrayMatch = cleaned.match(/\[\s*\{[\s\S]*?\}\s*\]/)
176:           if (arrayMatch) {
177:             // Fix common issues: trailing commas, missing commas, etc.
178:             let fixed = arrayMatch[0]
179:               .replace(/,\s*}/g, '}')  // Remove trailing commas before }
180:               .replace(/,\s*\]/g, ']')  // Remove trailing commas before ]
181:               .replace(/}\s*{/g, '},{') // Add missing commas between objects
182:             
183:             jobs = JSON.parse(fixed)
184:             this.log(`‚úÖ Extracted JSON using method 2 (with fixes)`)
185:           }
186:         } catch (e) {
187:           this.log(`‚ö†Ô∏è Method 2 failed: ${(e as Error).message}`, 'warn')
188:         }
189:       }
190:       
191:       if (jobs.length === 0) {
192:         this.log('‚ùå No valid JSON found in Perplexity response', 'error')
193:         throw new Error('No valid JSON found in agent response')
194:       }
195:       
196:       // Validate and clean jobs
197:       const validated = this.validateJobs(jobs, maxResults)
198:       
199:       this.log(`‚úÖ Validated ${validated.length}/${jobs.length} jobs from Perplexity`)
200:       
201:       return validated
202:     } catch (error) {
203:       this.log(`‚ùå Perplexity search failed: ${(error as Error).message}`, 'error')
204:       throw error
205:     }
206:   }
207: 
208:   private async searchWithCheerio(
209:     searchUrls: Array<{ name: string; url: string; priority: number }>,
210:     maxResults: number
211:   ): Promise<JobListing[]> {
212:     this.log(`üîÑ Starting parallel Cheerio scraping of ${searchUrls.length} boards...`)
213:     
214:     // Scrape all boards in parallel
215:     const scrapePromises = searchUrls.map(async ({ name, url }): Promise<JobListing | null> => {
216:       try {
217:         this.log(`üì° Scraping ${name}...`)
218:         const result = await this.scraper.scrape(url)
219:         
220:         if (result.success && result.data) {
221:           this.log(`‚úÖ ${name}: Found data`)
222:           // Convert scraper result to job listing
223:           const job: JobListing = {
224:             title: result.data.title || 'Unknown',
225:             company: result.data.company || 'Unknown',
226:             location: result.data.location || '',
227:             url: url,
228:             summary: result.data.description || '',
229:             salary: result.data.salary || null,
230:             postedDate: result.data.postedDate || new Date().toISOString().split('T')[0],
231:             source: name.toLowerCase().replace(/\s+/g, '-'),
232:             skills: result.data.requirements || [],
233:             workType: 'onsite' as const,
234:             skillMatchPercent: 0
235:           }
236:           return job
237:         }
238:         
239:         this.log(`‚ö†Ô∏è ${name}: No data found`, 'warn')
240:         return null
241:       } catch (error) {
242:         this.log(`‚ùå ${name}: ${(error as Error).message}`, 'error')
243:         return null
244:       }
245:     })
246: 
247:     const results = await Promise.all(scrapePromises)
248:     const jobs = results.filter((j): j is JobListing => j !== null)
249:     
250:     this.log(`‚úÖ Cheerio scraping complete: ${jobs.length} jobs found`)
251:     
252:     return this.validateJobs(jobs, maxResults)
253:   }
254: 
255:   private validateJobs(jobs: JobListing[], target: number): JobListing[] {
256:     const validated = jobs
257:       .filter(j => {
258:         // FIX: Only reject if completely missing critical fields
259:         if (!j.title || !j.company || !j.url) {
260:           this.log(`üö´ Rejected job missing critical fields: "${j.title || 'NO TITLE'}" at "${j.company || 'NO COMPANY'}"`)
261:           return false
262:         }
263:         
264:         // FIX: Don't reject based on description length - enrich later
265:         // Short descriptions will be enriched by URL scraping
266:         
267:         // FIX: More lenient confidential filter - only reject obvious ones
268:         const company = String(j.company).toLowerCase().trim()
269:         const isConfidential = company.includes('confidential') && company.length < 20
270:         if (isConfidential) {
271:           this.log(`üö´ Rejected confidential job: "${j.title}" at "${j.company}"`)
272:           return false
273:         }
274:         
275:         // FIX: Accept any valid HTTP URL
276:         if (!j.url.startsWith('http')) {
277:           this.log(`üö´ Rejected job with invalid URL: "${j.title}"`)
278:           return false
279:         }
280:         
281:         return true
282:       })
283:       .slice(0, target)
284:     
285:     this.log(`‚úÖ Validation complete: ${validated.length}/${jobs.length} jobs passed`)
286:     
287:     return validated
288:   }
289: }
</file>

<file path="src/app/api/jobs/search/route.ts">
  1: /**
  2:  * Unified Job Search API - Enhanced with PerplexityIntelligenceService
  3:  * 
  4:  * NOW USES: PerplexityIntelligenceService for comprehensive 25+ board coverage
  5:  * 
  6:  * Features:
  7:  * - 10 Canadian job boards (Job Bank, Jobboom, Workopolis, etc.)
  8:  * - 35+ Canadian ATS companies (Shopify, Wealthsimple, etc.)
  9:  * - Global boards (LinkedIn, Indeed, Glassdoor)
 10:  * - Resume skill matching with scoring
 11:  * - Smart Canadian prioritization
 12:  * - Built-in caching (24hr TTL)
 13:  */
 14: 
 15: import { NextRequest, NextResponse } from 'next/server'
 16: import { getServerSession } from 'next-auth/next'
 17: import { authOptions } from '@/lib/auth'
 18: import { dbService } from '@/lib/database'
 19: import { PerplexityIntelligenceService } from '@/lib/perplexity-intelligence'
 20: import { isRateLimited } from '@/lib/rate-limit'
 21: import Resume from '@/models/Resume'
 22: import { jobSearchCacheService } from '@/services/job-search-cache.service'
 23: 
 24: export const dynamic = 'force-dynamic'
 25: export const runtime = 'nodejs'
 26: export const maxDuration = 60 // Increased to handle Perplexity API calls which can take longer
 27: 
 28: interface JobSearchRequest {
 29:   keywords: string
 30:   location?: string
 31:   sources?: string[] // Specific boards to search
 32:   limit?: number
 33:   remote?: boolean
 34:   salaryMin?: number
 35:   experienceLevel?: 'entry' | 'mid' | 'senior' | 'executive'
 36:   workType?: 'remote' | 'hybrid' | 'onsite' | 'any'
 37:   useResumeMatching?: boolean // Use resume for skill matching
 38:   targetIndustry?: string // ENTERPRISE: User wants to switch industries (e.g., "Technology", "Healthcare")
 39:   disableIndustryWeighting?: boolean // ENTERPRISE: User wants equal weight across all industries
 40: }
 41: 
 42: export async function POST(request: NextRequest) {
 43:   try {
 44:     // CRITICAL FIX: Parse body and validate location BEFORE authentication
 45:     // This allows testing location validation without auth
 46:     const body: JobSearchRequest = await request.json()
 47:     let { 
 48:       keywords, 
 49:       location, 
 50:       sources, 
 51:       limit = 25, 
 52:       remote,
 53:       salaryMin,
 54:       experienceLevel,
 55:       workType,
 56:       targetIndustry,
 57:       disableIndustryWeighting
 58:     } = body
 59:     
 60:     console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
 61:     console.log('[JOB_SEARCH] NEW SEARCH REQUEST')
 62:     console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
 63:     console.log('[JOB_SEARCH] Job Title:', keywords)
 64:     console.log('[JOB_SEARCH] Location:', location || 'UNDEFINED')
 65:     console.log('[JOB_SEARCH] Max Results:', limit)
 66:     console.log('[JOB_SEARCH] Work Type:', workType || 'any')
 67:     console.log('‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ')
 68: 
 69:     // CRITICAL: Validate location BEFORE authentication check
 70:     if (!location || location.trim().length < 2) {
 71:       console.error('[JOB_SEARCH] ‚ùå MISSING LOCATION')
 72:       return NextResponse.json({
 73:         success: false,
 74:         error: 'Location is required for job search',
 75:         suggestion: 'Upload your resume to extract location, or manually enter city and state/province',
 76:         errorCode: 'LOCATION_REQUIRED'
 77:       }, { status: 400 })
 78:     }
 79: 
 80:     // Reject "Canada" or "United States" (too broad)
 81:     const normalizedLocation = location.toLowerCase().trim()
 82:     if (['canada', 'united states', 'usa', 'us'].includes(normalizedLocation)) {
 83:       console.error('[JOB_SEARCH] ‚ùå LOCATION TOO BROAD:', location)
 84:       return NextResponse.json({
 85:         success: false,
 86:         error: 'Location is too broad. Please specify a city and state/province.',
 87:         example: 'Examples: Seattle, WA or Toronto, ON or Vancouver, BC',
 88:         errorCode: 'LOCATION_TOO_BROAD'
 89:       }, { status: 400 })
 90:     }
 91: 
 92:     console.log('[JOB_SEARCH] ‚úÖ Location valid, proceeding with authentication...')
 93: 
 94:     // NOW check authentication after location validation passes
 95:     const session = await getServerSession(authOptions)
 96:     if (!session?.user?.id) {
 97:       return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
 98:     }
 99: 
100:     // Rate limiting
101:     if (await isRateLimited(session.user.id, 'job-search')) {
102:       return NextResponse.json({ 
103:         error: 'Too many searches. Please wait a moment.' 
104:       }, { status: 429 })
105:     }
106: 
107:     await dbService.connect()
108: 
109:     let useResumeMatching = body.useResumeMatching || false
110: 
111:     if (!keywords || keywords.trim().length < 2) {
112:       return NextResponse.json({ 
113:         error: 'Please provide valid search keywords' 
114:       }, { status: 400 })
115:     }
116: 
117:     console.log(`[JOB_SEARCH] User ${session.user.id} searching: "${keywords}" in ${location} (Resume matching: ${useResumeMatching})`)
118: 
119:     // CRITICAL FIX: Get cached jobs but ALWAYS search for new ones too
120:     const cachedJobs = await jobSearchCacheService.getCachedJobs({
121:       keywords,
122:       location,
123:       workType,
124:       experienceLevel,
125:       userId: session.user.id
126:     });
127: 
128:     if (cachedJobs && cachedJobs.length > 0) {
129:       console.log(`[JOB_CACHE] Found ${cachedJobs.length} cached jobs - will merge with NEW search results`);
130:     } else {
131:       console.log(`[JOB_CACHE] No cached jobs found - performing fresh search`);
132:     }
133: 
134:     let result: any
135:     let jobs: any[] = []
136:     let metadata: any = {}
137: 
138:     // Option 1: Resume-matched search with INDUSTRY WEIGHTING (most powerful)
139:     if (useResumeMatching) {
140:       try {
141:         // Get user's resume
142:         const resumeDoc = await Resume.findOne({ userId: session.user.id })
143:           .sort({ createdAt: -1 })
144:           .lean()
145:         
146:         const extractedText = (resumeDoc as any)?.extractedText
147:         
148:         if (!resumeDoc || !extractedText) {
149:           return NextResponse.json({ 
150:             error: 'Please upload a resume first to use resume matching' 
151:           }, { status: 400 })
152:         }
153: 
154:         console.log(`[JOB_SEARCH] Using resume matching with industry weighting for user ${session.user.id}`)
155: 
156:         // ENTERPRISE FEATURE: Analyze career timeline for industry weighting
157:         let careerTimeline: any = null
158:         let effectivePrimaryIndustry: any = null
159:         
160:         // Skip industry analysis if user explicitly disabled it
161:         if (!disableIndustryWeighting) {
162:           try {
163:             careerTimeline = await PerplexityIntelligenceService.extractCareerTimeline(extractedText)
164:             console.log('[JOB_SEARCH] Career timeline:', {
165:               industries: careerTimeline.industries.map((i: any) => `${i.name} (${i.percentage}%)`).join(', '),
166:               primaryIndustry: careerTimeline.industries[0]?.name,
167:               hasTransition: !!careerTimeline.careerTransition,
168:               userTargetIndustry: targetIndustry || 'none'
169:             })
170:             
171:             // ENTERPRISE: User wants to switch industries
172:             if (targetIndustry && targetIndustry.trim()) {
173:               // Find matching industry from resume, or create synthetic one
174:               const normalizedTarget = targetIndustry.toLowerCase()
175:               effectivePrimaryIndustry = careerTimeline.industries.find(
176:                 (i: any) => i?.name?.toLowerCase()?.includes(normalizedTarget)
177:               )
178: 
179:               if (effectivePrimaryIndustry) {
180:                 console.log(`[JOB_SEARCH] User targeting industry switch TO: ${effectivePrimaryIndustry.name}`)
181:               } else {
182:                 // User wants to switch to an entirely new industry not in their history
183:                 console.log(`[JOB_SEARCH] User switching to NEW industry: ${targetIndustry} (no prior experience)`)
184:                 effectivePrimaryIndustry = {
185:                   name: targetIndustry,
186:                   yearsOfExperience: 0,
187:                   keywords: keywords
188:                     .split(',')
189:                     .map((k: string) => k.trim())
190:                     .filter(Boolean),
191:                   percentage: 100 // Give full weight to target industry
192:                 }
193:               }
194:             } else {
195:               // Default: Use longest-tenure industry
196:               effectivePrimaryIndustry = careerTimeline.industries[0]
197:             }
198:           } catch (err) {
199:             console.warn('[JOB_SEARCH] Career timeline extraction failed, using standard matching:', err)
200:           }
201:         } else {
202:           console.log('[JOB_SEARCH] Industry weighting DISABLED by user preference')
203:         }
204: 
205:         // CRITICAL: If career timeline exists, weight job results by industry tenure
206:         let industryWeightedLimit = limit
207:         
208:         if (effectivePrimaryIndustry) {
209:           // Calculate industry-based search distribution
210:           const primaryPercentage = effectivePrimaryIndustry.percentage / 100
211:           
212:           // EXAMPLE: If 95% of career in Transportation, show 95% transport jobs
213:           // UNLESS user is switching industries, then show 100% of new industry
214:           industryWeightedLimit = targetIndustry ? limit : Math.ceil(limit * primaryPercentage)
215:           
216:           console.log('[JOB_SEARCH] Industry weighting:', {
217:             primaryIndustry: effectivePrimaryIndustry.name,
218:             primaryPercentage: `${effectivePrimaryIndustry.percentage}%`,
219:             adjustedLimit: industryWeightedLimit,
220:             keywords: effectivePrimaryIndustry.keywords?.join(', ') || 'none',
221:             isSwitching: !!targetIndustry
222:           })
223:           
224:           // Boost keywords from target/primary industry (if available)
225:           if (effectivePrimaryIndustry.keywords && Array.isArray(effectivePrimaryIndustry.keywords) && effectivePrimaryIndustry.keywords.length > 0) {
226:             const industryKeywords = effectivePrimaryIndustry.keywords.slice(0, 5).join(', ')
227:             keywords = `${industryKeywords}, ${keywords}`.trim()
228:           }
229:         }
230: 
231:         // Use NEW AGENT SYSTEM with Perplexity web_search + Cheerio fallback
232:         console.log('[JOB_SEARCH] ü§ñ Calling NEW AGENT SYSTEM jobListingsWithAgent with:', {
233:           jobTitle: keywords,
234:           location,
235:           workType: workType || (remote ? 'remote' : 'any'),
236:           maxResults: limit
237:         })
238:         
239:         result = await PerplexityIntelligenceService.jobListingsWithAgent(
240:           keywords,
241:           location,
242:           {
243:             maxResults: limit,
244:             workType: workType || (remote ? 'remote' : 'any')
245:           }
246:         )
247: 
248:         console.log('[JOB_SEARCH] ü§ñ Agent system result:', {
249:           success: result.success,
250:           dataType: typeof result.data,
251:           dataIsArray: Array.isArray(result.data),
252:           dataLength: Array.isArray(result.data) ? result.data.length : 0,
253:           cached: result.cached,
254:           method: result.metadata?.method,
255:           confidence: result.metadata?.confidence,
256:           error: result.metadata?.error
257:         })
258: 
259:         jobs = result.data
260:         
261:         // POST-PROCESSING: Re-rank jobs by industry tenure (respects user preferences)
262:         if (effectivePrimaryIndustry && !disableIndustryWeighting && effectivePrimaryIndustry.keywords && Array.isArray(effectivePrimaryIndustry.keywords)) {
263:           const primaryKeywords = effectivePrimaryIndustry.keywords.map((k: string) => k.toLowerCase())
264:           
265:           jobs = jobs.map((job: any) => {
266:             // Calculate industry match score
267:             const jobTitle = (job.title || '').toLowerCase()
268:             const jobDescription = (job.description || '').toLowerCase()
269:             const jobCompany = (job.company || '').toLowerCase()
270:             const fullText = `${jobTitle} ${jobDescription} ${jobCompany}`
271:             
272:             let industryMatchCount = 0
273:             primaryKeywords.forEach((keyword: string) => {
274:               if (fullText.includes(keyword)) industryMatchCount++
275:             })
276:             
277:             const industryMatchScore = industryMatchCount / primaryKeywords.length
278:             
279:             // Boost jobs from primary/target industry
280:             const originalScore = job.skillMatchScore || 0.5
281:             // If user is switching industries, give HIGHER boost (up to 75%)
282:             const boostMultiplier = targetIndustry ? 0.75 : 0.5
283:             const boostedScore = originalScore * (1 + industryMatchScore * boostMultiplier)
284:             
285:             return {
286:               ...job,
287:               skillMatchScore: Math.min(boostedScore, 1.0), // Cap at 1.0
288:               industryMatchScore,
289:               primaryIndustry: effectivePrimaryIndustry.name,
290:               isSwitchingIndustries: !!targetIndustry
291:             }
292:           }).sort((a: any, b: any) => (b.skillMatchScore || 0) - (a.skillMatchScore || 0)) // Re-sort by boosted score
293:           
294:           const matchedJobs = jobs.filter((j: any) => j.industryMatchScore > 0.3).length
295:           console.log(`[JOB_SEARCH] Applied industry weighting boost to ${jobs.length} jobs (${matchedJobs} strong matches)`)
296:         }
297:         
298:         metadata = {
299:           ...result.metadata,
300:           useResumeMatching: true,
301:           skillMatchingEnabled: true,
302:           industryWeighting: effectivePrimaryIndustry ? {
303:             primaryIndustry: effectivePrimaryIndustry.name,
304:             primaryPercentage: effectivePrimaryIndustry.percentage,
305:             careerTransition: careerTimeline?.careerTransition,
306:             userTargetIndustry: targetIndustry || null,
307:             disabledByUser: disableIndustryWeighting || false
308:           } : null
309:         }
310: 
311:         console.log(`[JOB_SEARCH] Resume matching found ${jobs.length} jobs with skill scores and industry weighting`)
312: 
313:       } catch (error) {
314:         console.error('[JOB_SEARCH] Resume matching failed, falling back to standard search:', error)
315:         // Fall back to standard search
316:         useResumeMatching = false
317:       }
318:     }
319: 
320:     // Option 2: Standard job listing search (25+ boards)
321:     if (!useResumeMatching || jobs.length === 0) {
322:       console.log(`[JOB_SEARCH] Using standard search across 25+ boards`, {
323:         keywords,
324:         location,
325:         limit,
326:         workType: workType || (remote ? 'remote' : undefined)
327:       })
328: 
329:       const jobsResult = await PerplexityIntelligenceService.jobListings(
330:         keywords,
331:         location,
332:         {
333:           limit,
334:           boards: sources
335:         }
336:       )
337: 
338:       console.log(`[JOB_SEARCH] jobListings returned:`, {
339:         type: typeof jobsResult,
340:         isArray: Array.isArray(jobsResult),
341:         length: Array.isArray(jobsResult) ? jobsResult.length : 0,
342:         sample: Array.isArray(jobsResult) && jobsResult[0] ? {
343:           title: jobsResult[0].title,
344:           company: jobsResult[0].company,
345:           hasUrl: !!jobsResult[0].url
346:         } : null
347:       })
348: 
349:       jobs = Array.isArray(jobsResult) ? jobsResult : []
350:       console.log(`[JOB_SEARCH] Standard search returned type: ${typeof jobsResult}, isArray: ${Array.isArray(jobsResult)}, length: ${jobs.length}`)
351: 
352:       metadata = {
353:         useResumeMatching: false,
354:         searchedBoards: sources?.length || 15,
355:         canadianPriority: location.toLowerCase().includes('canada')
356:       }
357: 
358:       console.log(`[JOB_SEARCH] Standard search found ${jobs.length} jobs`)
359:       if (jobs.length > 0) {
360:         console.log(`[JOB_SEARCH] First job sample:`, JSON.stringify(jobs[0]).substring(0, 200))
361:       }
362:     }
363: 
364:     // Save search history
365:     try {
366:       const { default: SearchHistory } = await import('@/models/SearchHistory')
367:       await SearchHistory.create({
368:         userId: session.user.id,
369:         keywords,
370:         location,
371:         resultsCount: jobs.length,
372:         sources: sources || ['all'],
373:         aiUsed: useResumeMatching,
374:         searchDate: new Date()
375:       })
376:     } catch (error) {
377:       console.error('[JOB_SEARCH] Failed to save search history:', error)
378:       // Non-critical, continue
379:     }
380: 
381:     // IMPROVED: Mark confidential jobs instead of filtering them out
382:     let processedJobs = jobs.map((job: any) => {
383:       const company = (job.company || '').toLowerCase().trim()
384:       const title = (job.title || '').toLowerCase().trim()
385:       
386:       // Only filter out COMPLETELY invalid jobs (empty title/company)
387:       const isCompletelyInvalid = (company === '' && title === '')
388:       
389:       // Mark confidential companies but keep them
390:       const confidentialCompanies = ['confidential', 'confidential company', 'undisclosed', 'private']
391:       const isConfidential = confidentialCompanies.includes(company)
392:       
393:       return {
394:         ...job,
395:         isConfidential,
396:         isCompletelyInvalid,
397:         note: isConfidential ? 'Company name not disclosed in posting' : undefined
398:       }
399:     }).filter((job: any) => !job.isCompletelyInvalid) // Only filter completely invalid
400: 
401:     // üö´ CRITICAL: REMOVE ALL CONFIDENTIAL JOBS - DO NOT SHOW THEM AT ALL
402:     const confidentialCount = processedJobs.filter((j: any) => j.isConfidential).length
403:     processedJobs = processedJobs.filter((j: any) => {
404:       const isConfidential = j.isConfidential || 
405:         j.title?.toLowerCase().includes('confidential') ||
406:         j.company?.toLowerCase().includes('confidential') ||
407:         j.company?.toLowerCase() === 'confidential'
408:       
409:       if (isConfidential) {
410:         console.log(`[JOB_SEARCH] üö´ REJECTED CONFIDENTIAL JOB: "${j.title}" at "${j.company}"`)
411:       }
412:       
413:       return !isConfidential
414:     })
415:     
416:     console.log(`[JOB_SEARCH] Processed ${jobs.length} jobs, REJECTED ${confidentialCount} confidential jobs, ${processedJobs.length} valid jobs kept`)
417: 
418:     // CRITICAL FIX: Merge cached jobs with new results (remove duplicates by URL)
419:     let finalJobs = [...processedJobs]
420:     if (cachedJobs && cachedJobs.length > 0) {
421:       const newJobUrls = new Set(processedJobs.map((j: any) => j.url).filter(Boolean))
422:       // Also filter confidential from cached jobs
423:       const uniqueCachedJobs = cachedJobs.filter((cj: any) => {
424:         const isConfidential = cj.isConfidential || 
425:           cj.title?.toLowerCase().includes('confidential') ||
426:           cj.company?.toLowerCase().includes('confidential') ||
427:           cj.company?.toLowerCase() === 'confidential'
428:         return !newJobUrls.has(cj.url) && !isConfidential
429:       })
430:       finalJobs = [...processedJobs, ...uniqueCachedJobs]
431:       console.log(`[JOB_CACHE] Merged ${uniqueCachedJobs.length} unique cached jobs with ${processedJobs.length} new jobs = ${finalJobs.length} total`)
432:     }
433: 
434:     // üöÄ NEW: Cache the search results for 3 weeks
435:     if (processedJobs.length > 0) {
436:       await jobSearchCacheService.cacheSearchResults(
437:         {
438:           keywords,
439:           location,
440:           workType,
441:           experienceLevel,
442:           userId: session.user.id
443:         },
444:         processedJobs
445:       );
446:       console.log(`[JOB_CACHE] ‚úÖ Cached ${processedJobs.length} jobs for future searches`);
447:     }
448: 
449:     // Get recommended boards for this location
450:     const recommendedBoards = PerplexityIntelligenceService.getRecommendedBoards(location)
451: 
452:     return NextResponse.json({
453:       success: true,
454:       query: { keywords, location, sources },
455:       totalResults: finalJobs.length,
456:       returnedResults: Math.min(finalJobs.length, limit),
457:       jobs: finalJobs.slice(0, limit),
458:       metadata: {
459:         ...metadata,
460:         searchedAt: new Date().toISOString(),
461:         cachedResults: cachedJobs ? cachedJobs.length : 0,
462:         newResults: processedJobs.length,
463:         totalMerged: finalJobs.length
464:       },
465:       recommendations: {
466:         priorityBoards: recommendedBoards.slice(0, 5),
467:         reasoning: `Recommended job boards for ${location || 'your location'}`
468:       },
469:       sources: [...new Set(finalJobs.map((j: any) => j.source || 'Unknown'))]
470:     })
471: 
472:   } catch (error: any) {
473:     console.error('‚ùå‚ùå‚ùå [JOB_SEARCH] CRITICAL ERROR ‚ùå‚ùå‚ùå')
474:     console.error('[JOB_SEARCH] Error type:', error?.constructor?.name)
475:     console.error('[JOB_SEARCH] Error message:', error?.message)
476:     console.error('[JOB_SEARCH] Error stack:', error?.stack)
477:     
478:     // Get session for error logging
479:     const session = await getServerSession(authOptions)
480:     console.error('[JOB_SEARCH] User ID:', session?.user?.id)
481:     
482:     return NextResponse.json({ 
483:       error: 'Job search failed', 
484:       details: error?.message || 'Unknown error',
485:       errorType: error?.constructor?.name,
486:       timestamp: new Date().toISOString()
487:     }, { status: 500 })
488:   }
489: }
490: 
491: /**
492:  * GET endpoint for search history and available job boards
493:  */
494: export async function GET(request: NextRequest) {
495:   try {
496:     const session = await getServerSession(authOptions)
497:     if (!session?.user?.id) {
498:       return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
499:     }
500: 
501:     await dbService.connect()
502: 
503:     const url = new URL(request.url)
504:     const action = url.searchParams.get('action')
505: 
506:     // Get available job boards
507:     if (action === 'boards') {
508:       const boards = PerplexityIntelligenceService.getAvailableJobBoards()
509:       return NextResponse.json({
510:         success: true,
511:         boards,
512:         totalBoards: boards.length
513:       })
514:     }
515: 
516:     // Get search history (default)
517:     const { default: SearchHistory } = await import('@/models/SearchHistory')
518:     const history = await SearchHistory.find({ userId: session.user.id })
519:       .sort({ searchDate: -1 })
520:       .limit(20)
521: 
522:     return NextResponse.json({
523:       success: true,
524:       history
525:     })
526: 
527:   } catch (error) {
528:     console.error('[JOB_SEARCH] Failed to fetch data:', error)
529:     return NextResponse.json({ 
530:       error: 'Failed to fetch data' 
531:     }, { status: 500 })
532:   }
533: }
</file>

<file path="src/lib/perplexity-intelligence.ts">
   1: // FIXED: Universal crypto support (browser + Node.js)
   2: let crypto: any
   3: try {
   4:   crypto = require('crypto')
   5: } catch {
   6:   // Browser environment - will use fallback
   7:   crypto = null
   8: }
   9: import { PerplexityService } from './perplexity-service'
  10: import { 
  11:   CANADIAN_JOB_BOARDS, 
  12:   MAJOR_JOB_BOARDS, 
  13:   OPEN_API_BOARDS,
  14:   ATS_PLATFORMS,
  15:   DISCOVERY_PRIORITY_ORDER
  16: } from './public-job-boards-config'
  17: import { parseAIResponse } from './utils/ai-response-parser'
  18: import { getCoverLetterTemplateById } from './cover-letter-templates'
  19: 
  20: // Environment
  21: const CACHE_TTL_MS = Number(process.env.PPX_CACHE_TTL_MS || 24 * 60 * 60 * 1000)
  22: const MAX_RETRY_ATTEMPTS = Number(process.env.PPX_MAX_RETRIES || 3)
  23: const RETRY_DELAY_MS = Number(process.env.PPX_RETRY_DELAY || 1000)
  24: 
  25: type CacheRecord = {
  26:   value: unknown
  27:   metadata: { createdAt: number; hitCount: number; lastAccessed: number }
  28:   expiresAt: number
  29: }
  30: 
  31: // Simple Map-based cache with TTL
  32: const cache = new Map<string, CacheRecord>()
  33: 
  34: // Cache cleanup interval (every hour)
  35: setInterval(() => {
  36:   const now = Date.now()
  37:   for (const [key, record] of cache.entries()) {
  38:     if (now > record.expiresAt) {
  39:       cache.delete(key)
  40:     }
  41:   }
  42: }, 60 * 60 * 1000)
  43: 
  44: function makeKey(prefix: string, payload: unknown): string {
  45:   const raw = typeof payload === 'string' ? payload : JSON.stringify(payload)
  46:   
  47:   // Use crypto if available (Node.js), otherwise simple hash (browser)
  48:   if (crypto && crypto.createHash) {
  49:     return `${prefix}:${crypto.createHash('sha256').update(raw).digest('hex')}`
  50:   }
  51:   
  52:   // Browser fallback: simple hash
  53:   let hash = 0
  54:   for (let i = 0; i < raw.length; i++) {
  55:     const char = raw.charCodeAt(i)
  56:     hash = ((hash << 5) - hash) + char
  57:     hash = hash & hash
  58:   }
  59:   return `${prefix}:${Math.abs(hash).toString(36)}`
  60: }
  61: 
  62: function getCache(key: string): unknown | undefined {
  63:   const entry = cache.get(key)
  64:   if (!entry) return undefined
  65:   
  66:   // Check if expired
  67:   if (Date.now() > entry.expiresAt) {
  68:     cache.delete(key)
  69:     return undefined
  70:   }
  71:   
  72:   entry.metadata.hitCount += 1
  73:   entry.metadata.lastAccessed = Date.now()
  74:   return entry.value
  75: }
  76: 
  77: function setCache(key: string, value: unknown) {
  78:   cache.set(key, {
  79:     value,
  80:     expiresAt: Date.now() + CACHE_TTL_MS,
  81:     metadata: {
  82:       createdAt: Date.now(),
  83:       hitCount: 0,
  84:       lastAccessed: Date.now()
  85:     }
  86:   })
  87: }
  88: 
  89: function createClient(): PerplexityService { return new PerplexityService() }
  90: 
  91: // ---------- Enhanced helpers (ids, retry, enrichment) ----------
  92: function generateRequestId(): string {
  93:   if (crypto && crypto.randomBytes) {
  94:     return crypto.randomBytes(8).toString('hex')
  95:   }
  96:   // Browser fallback
  97:   return Math.random().toString(36).substr(2, 16) + Date.now().toString(36)
  98: }
  99: 
 100: // FIXED: Add timeout protection
 101: function withTimeout<T>(promise: Promise<T>, ms: number): Promise<T> {
 102:   return Promise.race([
 103:     promise,
 104:     new Promise<T>((_, reject) => 
 105:       setTimeout(() => reject(new Error(`Request timeout after ${ms}ms`)), ms)
 106:     )
 107:   ])
 108: }
 109: 
 110: async function withRetry<T>(
 111:   operation: () => Promise<T>,
 112:   maxAttempts: number = MAX_RETRY_ATTEMPTS,
 113:   logger?: { warn?: (message: string, context?: Record<string, unknown>) => void },
 114:   timeoutMs: number = 30000 // 30 second default timeout
 115: ): Promise<T> {
 116:   let lastError: unknown
 117:   for (let attempt = 1; attempt <= maxAttempts; attempt++) {
 118:     try {
 119:       return await withTimeout(operation(), timeoutMs)
 120:     } catch (err) {
 121:       lastError = err
 122:       if (attempt === maxAttempts) break
 123:       const baseDelay = RETRY_DELAY_MS * Math.pow(2, attempt - 1)
 124:       const jitter = Math.random() * RETRY_DELAY_MS
 125:       const delay = baseDelay + jitter
 126:       logger?.warn?.('Retrying Perplexity operation', {
 127:         attempt,
 128:         delay,
 129:         error: err instanceof Error ? err.message : String(err)
 130:       })
 131:       await new Promise(resolve => setTimeout(resolve, delay))
 132:     }
 133:   }
 134:   throw (lastError instanceof Error ? lastError : new Error('Operation failed'))
 135: }
 136: 
 137: // Removed unused PerplexityError class - using standard Error instead
 138: 
 139: // CRITICAL: This generates PATTERN-BASED emails (NOT VERIFIED)
 140: // These are stored as "alternativeEmails" with emailType: 'pattern' and low confidence
 141: // NEVER present these as verified contacts - they are guesses based on common patterns
 142: function inferEmails(name: string, companyDomain: string): string[] {
 143:   if (!name || !companyDomain) return []
 144:   const parts = name.toLowerCase().split(' ').filter(Boolean)
 145:   if (parts.length < 2) return []
 146:   const first = parts[0]
 147:   const last = parts[parts.length - 1]
 148:   const patterns = [
 149:     `${first}.${last}@${companyDomain}`,
 150:     `${first}${last}@${companyDomain}`,
 151:     `${first[0]}${last}@${companyDomain}`,
 152:     `${first}@${companyDomain}`,
 153:     `${last}@${companyDomain}`,
 154:     `${first}.${last[0]}@${companyDomain}`
 155:   ]
 156:   return patterns
 157: }
 158: 
 159: function normalizeSkills(skills: string[]): string[] {
 160:   const mapping: Record<string, string> = {
 161:     javascript: 'JavaScript', js: 'JavaScript',
 162:     typescript: 'TypeScript', ts: 'TypeScript',
 163:     react: 'React', reactjs: 'React',
 164:     node: 'Node.js', nodejs: 'Node.js',
 165:     python: 'Python', py: 'Python',
 166:     sales: 'Sales', selling: 'Sales',
 167:     crm: 'CRM', 'customer relationship management': 'CRM',
 168:     ai: 'Artificial Intelligence', 'artificial intelligence': 'Artificial Intelligence',
 169:     'machine learning': 'Machine Learning', ml: 'Machine Learning'
 170:   }
 171:   return (skills || []).map(s => {
 172:     const k = s.toLowerCase().trim()
 173:     return mapping[k] || s
 174:   })
 175: }
 176: 
 177: // CRITICAL FIX: Calculate years of experience from resume text
 178: // Prevents double-counting overlapping periods and filters out education dates
 179: function calculateYearsFromResume(resumeText: string): number {
 180:   // Extract only the work experience section to avoid counting education dates
 181:   const experienceSection = extractExperienceSection(resumeText)
 182:   
 183:   // Match date ranges in various formats
 184:   const dateRegex = /(\w+\s+\d{4}|(\d{1,2}\/\d{4}))\s*[-‚Äì‚Äî]\s*(\w+\s+\d{4}|Present|Current|(\d{1,2}\/\d{4}))/gi
 185:   const matches = Array.from(experienceSection.matchAll(dateRegex))
 186:   
 187:   // Parse all date ranges into start/end pairs
 188:   const periods: Array<{ start: Date; end: Date }> = []
 189:   for (const match of matches) {
 190:     try {
 191:       const startStr = match[1]
 192:       const endStr = match[3]
 193:       
 194:       const startDate = new Date(startStr)
 195:       const endDate = endStr.match(/Present|Current/i) ? new Date() : new Date(endStr)
 196:       
 197:       // Validate dates are reasonable (not in future, not before 1970)
 198:       if (startDate.getFullYear() < 1970 || startDate.getFullYear() > new Date().getFullYear()) continue
 199:       if (endDate.getFullYear() < 1970 || endDate.getFullYear() > new Date().getFullYear() + 1) continue
 200:       if (startDate > endDate) continue // Skip invalid ranges
 201:       
 202:       const months = (endDate.getFullYear() - startDate.getFullYear()) * 12 + 
 203:                     (endDate.getMonth() - startDate.getMonth())
 204:       
 205:       // Sanity check: skip periods longer than 50 years or negative
 206:       if (months > 0 && months < 600) {
 207:         periods.push({ start: startDate, end: endDate })
 208:       }
 209:     } catch (e) {
 210:       // Skip invalid dates
 211:       continue
 212:     }
 213:   }
 214:   
 215:   // If no valid periods found, return 0
 216:   if (periods.length === 0) return 0
 217:   
 218:   // Sort periods by start date
 219:   periods.sort((a, b) => a.start.getTime() - b.start.getTime())
 220:   
 221:   // Merge overlapping periods to avoid double-counting
 222:   const merged: Array<{ start: Date; end: Date }> = []
 223:   let current = periods[0]
 224:   
 225:   for (let i = 1; i < periods.length; i++) {
 226:     const next = periods[i]
 227:     
 228:     // If periods overlap or are adjacent, merge them
 229:     if (next.start <= current.end) {
 230:       current.end = new Date(Math.max(current.end.getTime(), next.end.getTime()))
 231:     } else {
 232:       // No overlap, push current and start new period
 233:       merged.push(current)
 234:       current = next
 235:     }
 236:   }
 237:   merged.push(current)
 238:   
 239:   // Calculate total months from merged periods
 240:   let totalMonths = 0
 241:   for (const period of merged) {
 242:     const months = (period.end.getFullYear() - period.start.getFullYear()) * 12 + 
 243:                   (period.end.getMonth() - period.start.getMonth())
 244:     totalMonths += months
 245:   }
 246:   
 247:   const years = Math.round(totalMonths / 12)
 248:   
 249:   // CRITICAL FIX: Cap at realistic maximum
 250:   // Assume candidate started working at age 18, max age 65
 251:   // Most candidates are 25-45, so cap at 25 years to be safe
 252:   const maxRealisticYears = 25
 253:   const cappedYears = Math.min(years, maxRealisticYears)
 254:   
 255:   // If calculated years seem unrealistic (>15), round down to nearest 5
 256:   if (cappedYears > 15) {
 257:     return Math.floor(cappedYears / 5) * 5
 258:   }
 259:   
 260:   return cappedYears
 261: }
 262: 
 263: // Extract work experience section from resume to avoid counting education dates
 264: function extractExperienceSection(resumeText: string): string {
 265:   const text = resumeText.toLowerCase()
 266:   
 267:   // Find work experience section markers
 268:   const experienceMarkers = [
 269:     'work experience',
 270:     'professional experience',
 271:     'employment history',
 272:     'experience',
 273:     'work history',
 274:     'career history'
 275:   ]
 276:   
 277:   // Find education section markers to exclude
 278:   const educationMarkers = [
 279:     'education',
 280:     'academic background',
 281:     'academic history',
 282:     'degrees'
 283:   ]
 284:   
 285:   let experienceStart = -1
 286:   let experienceMarker = ''
 287:   
 288:   // Find the earliest experience marker
 289:   for (const marker of experienceMarkers) {
 290:     const index = text.indexOf(marker)
 291:     if (index !== -1 && (experienceStart === -1 || index < experienceStart)) {
 292:       experienceStart = index
 293:       experienceMarker = marker
 294:     }
 295:   }
 296:   
 297:   // If no experience section found, use entire resume (fallback)
 298:   if (experienceStart === -1) return resumeText
 299:   
 300:   // Find where experience section ends (usually at education or end of document)
 301:   let experienceEnd = resumeText.length
 302:   for (const marker of educationMarkers) {
 303:     const index = text.indexOf(marker, experienceStart + experienceMarker.length)
 304:     if (index !== -1 && index < experienceEnd) {
 305:       experienceEnd = index
 306:     }
 307:   }
 308:   
 309:   return resumeText.substring(experienceStart, experienceEnd)
 310: }
 311: 
 312: // Enhanced response wrappers (non-breaking: used by new V2 methods only)
 313: export type RequestMetadata = { 
 314:   requestId: string
 315:   timestamp: number
 316:   duration?: number
 317:   error?: string
 318:   boardsSearched?: number
 319:   resultsCount?: number
 320:   attemptedCleanups?: string[]
 321:   contactsFound?: number
 322:   withEmails?: number
 323:   agent_iterations?: number
 324:   tools_used?: string[]
 325:   reasoning?: string
 326:   confidence?: number
 327:   method?: string
 328:   sources?: number
 329: }
 330: export type EnhancedResponse<T> = { success: boolean; data: T; metadata: RequestMetadata; cached: boolean }
 331: 
 332: export interface IntelligenceRequest {
 333:   company: string
 334:   role?: string
 335:   geo?: string
 336: }
 337: 
 338: export interface IntelligenceResponse {
 339:   company: string
 340:   freshness: string
 341:   sources: Array<{ title: string; url: string }>
 342:   confidence: number
 343:   financials: Array<{ metric: string; value: string; confidence: number; source?: string }>
 344:   culture: Array<{ point: string; confidence: number; source?: string }>
 345:   salaries: Array<{ title: string; range: string; currency?: string; geo?: string; source?: string; confidence: number }>
 346:   contacts: Array<{ name: string; title: string; url?: string; source?: string; confidence: number }>
 347:   growth: Array<{ signal: string; source?: string; confidence: number }>
 348:   summary: string
 349:   description: string
 350:   size: string
 351:   revenue: string
 352:   industry: string
 353:   founded: string
 354:   headquarters: string
 355:   psychology: string
 356:   marketIntelligence: string
 357:   // CRITICAL: New comprehensive intelligence fields
 358:   recentNews?: Array<{ title: string; date: string; url: string; summary: string }>
 359:   socialMedia?: {
 360:     linkedin?: string
 361:     twitter?: string
 362:     facebook?: string
 363:     instagram?: string
 364:     youtube?: string
 365:   }
 366:   glassdoorRating?: {
 367:     overallRating?: number
 368:     ceoApproval?: number
 369:     recommendToFriend?: number
 370:     reviewCount?: number
 371:     url?: string
 372:   }
 373:   stockProfile?: {
 374:     ticker?: string
 375:     exchange?: string
 376:     currentPrice?: string
 377:     marketCap?: string
 378:     isPublic?: boolean
 379:   }
 380: }
 381: 
 382: // V2 Data structures (for job listings and contacts)
 383: export interface JobListing {
 384:   title: string
 385:   company: string
 386:   location: string
 387:   address?: string | null
 388:   url: string
 389:   source?: string
 390:   summary: string
 391:   postedDate: string
 392:   salary?: string | null
 393:   skillMatchPercent: number
 394:   skills: string[]
 395:   workType?: 'remote' | 'hybrid' | 'onsite'
 396:   experienceLevel?: 'entry' | 'mid' | 'senior' | 'executive'
 397:   contacts: {
 398:     hrEmail?: string | null
 399:     hiringManagerEmail?: string | null
 400:     generalEmail?: string | null
 401:     phone?: string | null
 402:     linkedinProfiles: string[]
 403:   }
 404:   benefits?: string[]
 405:   requirements?: string[]
 406: }
 407: 
 408: export interface HiringContact {
 409:   name: string
 410:   title: string
 411:   department: string
 412:   linkedinUrl?: string | null
 413:   email?: string | null
 414:   emailType?: 'public' | 'inferred' | 'pattern'
 415:   source: string
 416:   confidence: number
 417:   phone?: string | null
 418:   alternativeEmails?: string[]
 419:   discoveryMethod?: string
 420: }
 421: 
 422: export interface QuickSearchItem {
 423:   title: string
 424:   url: string
 425:   snippet: string
 426:   source: string
 427:   postedDate?: string
 428:   location?: string
 429:   company?: string
 430:   date?: string
 431: }
 432: 
 433: const SYSTEM = `You are a research analyst using real-time web tools.
 434: CRITICAL: Your response must be ONLY valid JSON. NO explanatory text, NO markdown, NO commentary.
 435: Rules:
 436: - Use only public sources and respect robots.txt by following links provided by Perplexity tools.
 437: - Always return ONLY structured JSON matching the requested schema.
 438: - Include 5-10 source citations with titles and URLs.
 439: - Provide confidence scores (0-1) for each data point and overall.
 440: - Mark estimates or unverified signals clearly.
 441: - NEVER add text before or after the JSON response.
 442: `
 443: 
 444: interface ComprehensiveJobResearchData {
 445:   jobAnalysis: {
 446:     matchScore: number
 447:     matchingSkills: string[]
 448:     missingSkills: string[]
 449:     skillsToHighlight: string[]
 450:     recommendations: string[]
 451:     estimatedFit: string
 452:   }
 453:   companyIntel: {
 454:     company: string
 455:     description: string
 456:     size?: string
 457:     revenue?: string
 458:     industry?: string
 459:     founded?: string
 460:     headquarters?: string
 461:     website?: string
 462:     marketPosition?: string
 463:   }
 464:   companyPsychology: {
 465:     culture: string
 466:     values: string[]
 467:     managementStyle?: string
 468:     workEnvironment?: string
 469:   }
 470:   hiringContacts: Array<{
 471:     name: string
 472:     title: string
 473:     department?: string
 474:     email?: string
 475:     linkedinUrl?: string
 476:     authority: 'decision maker' | 'recruiter' | 'manager' | 'coordinator'
 477:     confidence: number
 478:     contactMethod?: string
 479:   }>
 480:   marketIntelligence: {
 481:     competitivePosition?: string
 482:     industryTrends?: string
 483:     financialStability?: string
 484:     recentPerformance?: string
 485:   }
 486:   news: Array<{
 487:     title: string
 488:     summary: string
 489:     url: string
 490:     date?: string
 491:     source?: string
 492:     impact?: string
 493:   }>
 494:   reviews: Array<{
 495:     platform: string
 496:     rating?: number
 497:     summary: string
 498:     url: string
 499:     pros?: string[]
 500:     cons?: string[]
 501:   }>
 502:   compensation: {
 503:     salaryRange?: string
 504:     benefits?: string
 505:   }
 506:   strategicRecommendations: {
 507:     applicationStrategy: string
 508:     contactStrategy: string
 509:     interviewPrep: string[]
 510:   }
 511:   sources: string[]
 512:   confidenceLevel: number
 513: }
 514: 
 515: interface EnhancedCompanyResearchData {
 516:   companyIntelligence: {
 517:     name: string
 518:     industry?: string
 519:     founded?: string
 520:     headquarters?: string
 521:     employeeCount?: string
 522:     revenue?: string
 523:     website?: string
 524:     description?: string
 525:     marketPosition?: string
 526:     financialStability?: string
 527:     recentPerformance?: string
 528:   }
 529:   hiringContactIntelligence: {
 530:     officialChannels?: {
 531:       careersPage?: string
 532:       jobsEmail?: string
 533:       hrEmail?: string
 534:       phone?: string
 535:       address?: string
 536:     }
 537:     keyContacts?: Array<{
 538:       name: string
 539:       title: string
 540:       department?: string
 541:       linkedinUrl?: string
 542:       email?: string
 543:       authority?: string
 544:       contactMethod?: string
 545:     }>
 546:     emailFormat?: string
 547:     socialMedia?: Record<string, string>
 548:   }
 549:   companyPsychology?: {
 550:     culture?: string
 551:     values?: string[]
 552:     managementStyle?: string
 553:     workEnvironment?: string
 554:   }
 555:   reviewAnalysis?: {
 556:     glassdoor?: {
 557:       rating?: number
 558:       reviewCount?: number
 559:       ceoApproval?: string | number
 560:       recommendToFriend?: string | number
 561:       pros?: string[]
 562:       cons?: string[]
 563:     }
 564:     employeeSentiment?: string
 565:   }
 566:   aiAutomationThreat?: {
 567:     roleRisk?: string
 568:     automationProbability?: string
 569:     timeframe?: string
 570:     companyAIAdoption?: string
 571:     futureOutlook?: string
 572:     recommendations?: string[]
 573:   }
 574:   recentNews?: Array<{
 575:     headline?: string
 576:     date?: string
 577:     source?: string
 578:     url?: string
 579:     impact?: string
 580:   }>
 581:   compensation?: {
 582:     salaryRange?: string
 583:     benefits?: string
 584:   }
 585:   redFlags?: string[]
 586:   strategicRecommendations?: {
 587:     applicationStrategy?: string
 588:     contactStrategy?: string
 589:     interviewPrep?: string[]
 590:   }
 591:   sources?: string[]
 592:   confidenceLevel?: number
 593: }
 594: 
 595: export class PerplexityIntelligenceService {
 596:   /**
 597:    * CRITICAL FIX: Scrapes job URL to get full description when Perplexity returns incomplete data
 598:    * Fallback for when descriptions are too short
 599:    */
 600:   private static async scrapeJobURL(url: string): Promise<string> {
 601:     try {
 602:       const response = await fetch(url, {
 603:         headers: {
 604:           'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
 605:         },
 606:         signal: AbortSignal.timeout(10000) // 10 second timeout
 607:       })
 608:       
 609:       if (!response.ok) return ''
 610:       
 611:       const html = await response.text()
 612:       
 613:       // Try multiple common job description selectors
 614:       const patterns = [
 615:         /<div[^>]*class="[^"]*description[^"]*"[^>]*>(.*?)<\/div>/is,
 616:         /<div[^>]*id="[^"]*description[^"]*"[^>]*>(.*?)<\/div>/is,
 617:         /<section[^>]*class="[^"]*job-description[^"]*"[^>]*>(.*?)<\/section>/is,
 618:         /<div[^>]*class="[^"]*job-details[^"]*"[^>]*>(.*?)<\/div>/is
 619:       ]
 620:       
 621:       for (const pattern of patterns) {
 622:         const match = html.match(pattern)
 623:         if (match && match[1]) {
 624:           // Strip HTML tags and clean up
 625:           const cleaned = match[1]
 626:             .replace(/<script[^>]*>.*?<\/script>/gis, '')
 627:             .replace(/<style[^>]*>.*?<\/style>/gis, '')
 628:             .replace(/<[^>]+>/g, ' ')
 629:             .replace(/\s+/g, ' ')
 630:             .trim()
 631:           
 632:           if (cleaned.length > 150) {
 633:             return cleaned
 634:           }
 635:         }
 636:       }
 637:       
 638:       return ''
 639:     } catch (error) {
 640:       if (process.env.PPX_DEBUG === 'true') {
 641:         console.warn(`[SCRAPE] Failed to scrape ${url}:`, error)
 642:       }
 643:       return ''
 644:     }
 645:   }
 646: 
 647:   /**
 648:    * CRITICAL FIX: Validates job listings response from Perplexity
 649:    * Filters out incomplete, fake, or low-quality jobs
 650:    */
 651:   private static validateJobListings(jobs: JobListing[], minRequired: number): JobListing[] {
 652:     const validated = jobs.filter((job: JobListing) => {
 653:       // ‚ùå REJECT: Empty or short descriptions
 654:       if (!job.summary || job.summary.trim().length < 150) {
 655:         if (process.env.PPX_DEBUG === 'true') {
 656:           console.warn(`[VALIDATE] Rejecting ${job.title} - description too short (${job.summary?.length || 0} chars)`)
 657:         }
 658:         return false
 659:       }
 660:       
 661:       // ‚ùå REJECT: Confidential companies
 662:       const confidentialKeywords = ['confidential', 'various', 'tbd', 'multiple', 'undisclosed', 'anonymous', 'private', 'stealth', 'hidden']
 663:       const company = String(job.company || '').toLowerCase().trim()
 664:       if (confidentialKeywords.some(kw => company.includes(kw)) || company.length < 3) {
 665:         if (process.env.PPX_DEBUG === 'true') {
 666:           console.warn(`[VALIDATE] Rejecting ${job.title} - confidential company: ${job.company}`)
 667:         }
 668:         return false
 669:       }
 670:       
 671:       // ‚ùå REJECT: No valid URL
 672:       if (!job.url || !job.url.includes('http')) {
 673:         if (process.env.PPX_DEBUG === 'true') {
 674:           console.warn(`[VALIDATE] Rejecting ${job.title} - invalid URL: ${job.url}`)
 675:         }
 676:         return false
 677:       }
 678:       
 679:       // ‚úÖ ACCEPT
 680:       return true
 681:     })
 682:     
 683:     // Warn if too many filtered out
 684:     if (validated.length < minRequired * 0.5 && process.env.PPX_DEBUG === 'true') {
 685:       console.warn(`[VALIDATE] Only ${validated.length}/${minRequired} jobs passed validation (${Math.round(validated.length/minRequired*100)}%)`)
 686:     }
 687:     
 688:     return validated
 689:   }
 690: 
 691:   /**
 692:    * CRITICAL FIX: Validates hiring contacts response from Perplexity
 693:    * Filters out fake emails, personal domains, pattern-based guesses
 694:    */
 695:   private static validateHiringContacts(contacts: HiringContact[]): HiringContact[] {
 696:     const validated = contacts.filter((contact: HiringContact) => {
 697:       // ‚ùå REJECT: No email and no LinkedIn
 698:       if (!contact.email && !contact.linkedinUrl) {
 699:         if (process.env.PPX_DEBUG === 'true') {
 700:           console.warn(`[VALIDATE] Rejecting ${contact.name} - no contact method`)
 701:         }
 702:         return false
 703:       }
 704:       
 705:       // ‚ùå REJECT: Personal email domains (if email exists)
 706:       if (contact.email) {
 707:         const personalDomains = ['gmail', 'yahoo', 'hotmail', 'outlook', 'aol', 'icloud', 'protonmail']
 708:         if (personalDomains.some(d => contact.email!.toLowerCase().includes(d))) {
 709:           if (process.env.PPX_DEBUG === 'true') {
 710:             console.warn(`[VALIDATE] Rejecting ${contact.email} - personal domain`)
 711:           }
 712:           return false
 713:         }
 714:         
 715:         // ‚ùå REJECT: Template/placeholder emails
 716:         if (contact.email.includes('[') || contact.email.includes('VISIT') || contact.email.includes('example') || contact.email.includes('domain.')) {
 717:           if (process.env.PPX_DEBUG === 'true') {
 718:             console.warn(`[VALIDATE] Rejecting ${contact.email} - template email`)
 719:           }
 720:           return false
 721:         }
 722:       }
 723:       
 724:       // ‚úÖ ACCEPT
 725:       return true
 726:     })
 727:     
 728:     return validated
 729:   }
 730: 
 731:   // V2: Enhanced company research with retries and metadata
 732:   static async researchCompanyV2(input: IntelligenceRequest): Promise<EnhancedResponse<IntelligenceResponse>> {
 733:     const requestId = generateRequestId()
 734:     const started = Date.now()
 735:     const key = makeKey('ppx:research:v2', input)
 736:     const cached = getCache(key) as IntelligenceResponse | undefined
 737:     if (cached) {
 738:       return { success: true, data: cached, metadata: { requestId, timestamp: started, duration: Date.now() - started }, cached: true }
 739:     }
 740:     try {
 741:       const userPrompt = `COMPREHENSIVE RESEARCH TASK: Search for contacts, emails, website, and complete intelligence for ${input.company}${input.role ? ` (role: ${input.role})` : ''}${input.geo ? ` in ${input.geo}` : ''}.
 742: 
 743: **MANDATORY SEARCH SOURCES:**
 744: - Use Google search extensively
 745: - Search LinkedIn company page AND individual employee profiles
 746: - Search all social media platforms (Twitter, Facebook, Instagram, YouTube)
 747: - Search company website thoroughly
 748: - Search business directories (BBB, Yellow Pages, ZoomInfo, etc.)
 749: - Search news sources and press releases
 750: - Search Glassdoor for reviews and salaries
 751: - Search stock exchanges if publicly traded
 752: 
 753: **RETURN DETAILED JSON with ALL fields below:**
 754: {
 755:   "company": string (full legal name),
 756:   "description": string (detailed company overview - NOT "No description available"),
 757:   "size": string (employee count with source),
 758:   "revenue": string (annual revenue estimate with source),
 759:   "industry": string (specific industry classification),
 760:   "founded": string (year or date with source),
 761:   "headquarters": string (full address with city, province/state, postal code),
 762:   "psychology": string (company culture, values, workplace environment - from Glassdoor/employee reviews),
 763:   "marketIntelligence": string (market position, competitive landscape, growth trends - detailed analysis),
 764:   "freshness": string (ISO datetime of research),
 765:   "sources": [{"title": string, "url": string}] (minimum 8 sources, up to 20),
 766:   "confidence": number (0 to 1),
 767:   "financials": [{"metric": string, "value": string, "confidence": number, "source": string}],
 768:   "culture": [{"point": string, "confidence": number, "source": string}] (from Glassdoor/reviews),
 769:   "salaries": [{"title": string, "range": string, "currency": string, "geo": string, "source": string, "confidence": number}],
 770:   "contacts": [{"name": string, "title": string, "email": string, "url": string, "source": string, "confidence": number}] (executives, managers, recruiters from LinkedIn with emails),
 771:   "generalEmail": string (company general inbox: careers@, hr@, jobs@, info@, hello@, contact@ - MANDATORY),
 772:   "careersPage": string (company careers/jobs page URL),
 773:   "growth": [{"signal": string, "source": string, "confidence": number}],
 774:   "summary": string (comprehensive 2-3 paragraph summary),
 775:   "recentNews": [{"title": string, "date": string, "url": string, "summary": string}] (last 6 months),
 776:   "socialMedia": {"linkedin": string, "twitter": string, "facebook": string, "instagram": string, "youtube": string},
 777:   "glassdoorRating": {"overallRating": number, "ceoApproval": number, "recommendToFriend": number, "reviewCount": number, "url": string},
 778:   "stockProfile": {"ticker": string, "exchange": string, "currentPrice": string, "marketCap": string, "isPublic": boolean}
 779: }
 780: 
 781: **CRITICAL REQUIREMENTS:**
 782: 1. Search company website for About page, Contact page, Leadership/Team page
 783: 2. **MANDATORY**: Extract company general email from website footer/contact page (careers@, hr@, jobs@, info@, hello@, contact@)
 784: 3. **MANDATORY**: Find company careers/jobs page URL
 785: 4. Search "site:linkedin.com/company/${input.company}" for official company page
 786: 5. Search "site:linkedin.com ${input.company} CEO OR president OR manager" for executive contacts WITH emails
 787: 6. Search "${input.company} headquarters address phone email"
 788: 7. Search "${input.company} site:glassdoor.com" for reviews and culture insights
 789: 8. Search "${input.company} revenue employees industry" for business intelligence
 790: 9. DO NOT return "Unknown", "No description available", or "No data" - search multiple sources until you find information
 791: 10. Include REAL contact information (names, titles, emails, LinkedIn URLs) - minimum 3 contacts if company has >10 employees
 792: 11. **APP IS USELESS WITHOUT CONTACT INFO** - Always return at least generalEmail even if no specific contacts found`
 793:       const out = await withRetry(async () => {
 794:         const client = createClient()
 795:         const user = userPrompt
 796:         const res = await client.makeRequest(SYSTEM, user, { temperature: 0.2, maxTokens: 3000, model: 'sonar-pro' })
 797:         if (!res.content?.trim()) throw new Error('Empty response')
 798:         return res
 799:       })
 800:       const context = {
 801:         requestId,
 802:         prompts: { system: SYSTEM, user: userPrompt },
 803:         timestamp: started,
 804:         duration: Date.now() - started
 805:       }
 806:       const parsed = parseAIResponse<IntelligenceResponse>(out.content ?? '', { stripMarkdown: true, extractFirst: true }, context)
 807:       parsed.company = parsed.company || input.company
 808:       parsed.freshness = parsed.freshness || new Date().toISOString()
 809:       parsed.sources = Array.isArray(parsed.sources) ? parsed.sources.slice(0, 12) : []
 810:       parsed.confidence = typeof parsed.confidence === 'number' ? Math.max(0, Math.min(1, parsed.confidence)) : 0.6
 811:       if (Array.isArray(parsed.contacts)) {
 812:         parsed.contacts = parsed.contacts.map(c => ({ ...c, url: c.url }))
 813:       }
 814:       setCache(key, parsed)
 815:       return { success: true, data: parsed, metadata: { requestId, timestamp: started, duration: Date.now() - started }, cached: false }
 816:     } catch (e) {
 817:       const fb: IntelligenceResponse = {
 818:         company: input.company,
 819:         freshness: new Date().toISOString(),
 820:         sources: [],
 821:         confidence: 0.3,
 822:         financials: [],
 823:         culture: [],
 824:         salaries: [],
 825:         contacts: [],
 826:         growth: [],
 827:         summary: 'Research failed - please retry',
 828:         description: 'No description available',
 829:         size: 'Unknown',
 830:         revenue: 'Unknown',
 831:         industry: 'Unknown',
 832:         founded: 'Unknown',
 833:         headquarters: 'Unknown',
 834:         psychology: 'No insights available',
 835:         marketIntelligence: 'No market data available',
 836:         recentNews: [],
 837:         socialMedia: {},
 838:         glassdoorRating: undefined,
 839:         stockProfile: undefined
 840:       }
 841:       return { success: false, data: fb, metadata: { requestId, timestamp: started, duration: Date.now() - started, error: (e as Error).message }, cached: false }
 842:     }
 843:   }
 844:   // REMOVED: Old researchCompany - Use researchCompanyV2 instead
 845: 
 846:   static async salaryForRole(role: string, company?: string, geo?: string) {
 847:     const key = makeKey('ppx:salary', { role, company, geo })
 848:     const cached = getCache(key)
 849:     if (cached) return cached
 850:     const client = createClient()
 851:     const user = `Find current salary ranges for ${role}${company ? ` at ${company}` : ''}${geo ? ` in ${geo}` : ''}. Return JSON: items[{title,range,currency,geo,source,confidence}], summary, freshness`;
 852:     try {
 853:       const out = await client.makeRequest(SYSTEM, user, { temperature: 0.2, maxTokens: 900, model: 'sonar-pro' })
 854:       const text = (out.content || '').trim()
 855:       const context = {
 856:         requestId: generateRequestId(),
 857:         prompts: { system: SYSTEM, user },
 858:         timestamp: Date.now(),
 859:         duration: 0
 860:       }
 861:       const parsed = parseAIResponse<Record<string, unknown>>(text, { stripMarkdown: true, extractFirst: true }, context)
 862:       setCache(key, parsed)
 863:       return parsed
 864:     } catch {
 865:       return { items: [], summary: 'Unavailable', freshness: new Date().toISOString() }
 866:     }
 867:   }
 868: 
 869:   /**
 870:    * Enhanced job listings search across 25+ Canadian and global job boards
 871:    * Integrates with public-job-boards-config.ts for comprehensive coverage
 872:    */
 873:   static async jobListings(
 874:     jobTitle: string, 
 875:     location: string,
 876:     options: {
 877:       boards?: string[] // Specific boards to search (uses DISCOVERY_PRIORITY_ORDER if not specified)
 878:       limit?: number
 879:       includeCanadianOnly?: boolean
 880:     } = {}
 881:   ) {
 882:     const { boards, limit = 50, includeCanadianOnly = false } = options
 883:     const key = makeKey('ppx:jobs', { jobTitle, location, boards, limit })
 884:     const cached = getCache(key)
 885:     if (cached) return cached
 886: 
 887:     // Determine which boards to search
 888:     const targetBoards = boards || (includeCanadianOnly 
 889:       ? Object.keys(CANADIAN_JOB_BOARDS)
 890:       : DISCOVERY_PRIORITY_ORDER.slice(0, 15) // Top 15 boards
 891:     )
 892: 
 893:     // Note: targetBoards is used in the Perplexity prompt below to guide source selection
 894: 
 895:     const client = createClient()
 896:     const SYSTEM_JOBS = `You are an advanced Job Listings Aggregator with real-time web access across 25+ Canadian and global job boards.
 897: 
 898: PRIORITY CANADIAN SOURCES:
 899: - Job Bank Canada (jobbank.gc.ca) - Government jobs
 900: - AutoJobs (autojobs.com) - Canadian automotive & skilled trades
 901: - SimplyHired Canada (simplyhired.ca) - Canadian aggregator
 902: - Jobboom (jobboom.com) - Bilingual Canadian
 903: - Workopolis (workopolis.com) - Canadian
 904: - Indeed Canada (ca.indeed.com)
 905: - Jooble Canada (ca.jooble.org)
 906: - ZipRecruiter Canada (ziprecruiter.ca)
 907: - Monster Canada (monster.ca)
 908: - Glassdoor Canada (glassdoor.ca)
 909: - Dice Canada (dice.com)
 910: - Careerjet Canada (careerjet.ca)
 911: 
 912: GLOBAL SOURCES:
 913: - LinkedIn (linkedin.com/jobs)
 914: - Indeed (indeed.com)
 915: - Glassdoor (glassdoor.com)
 916: - Adzuna (adzuna.com)
 917: 
 918: ATS PLATFORMS (Canadian Tech Companies):
 919: - Greenhouse: Shopify, Hootsuite, Wealthsimple, Faire, Thinkific, Lightspeed
 920: - Lever: Slack, Shopify, Bench, Clio, Clearco, League
 921: - Workable: FreshBooks, Visier, Unbounce, Axonify
 922: - Recruitee: Paytm, Ecobee, Geotab, Auvik, Wave, KOHO
 923: - Ashby: Faire, Clearco, Maple, Borrowell, Shakepay
 924: - Breezy HR: Lumerate, Zymewire, and other Canadian startups
 925: - Communitech Job Board: communitech.ca/companies (Waterloo tech ecosystem)
 926: - RemoteRocketship: remoterocketship.com (Remote Canadian jobs)
 927: 
 928: üî• CRITICAL - FOLLOW LINKS AND EXTRACT FULL CONTENT:
 929: For EACH job found, you MUST:
 930: 1. Find the job in search results (title, company, location, URL)
 931: 2. **FOLLOW THE JOB URL** and visit the actual job posting page
 932: 3. **SCRAPE THE COMPLETE JOB DESCRIPTION** from the posting page (all paragraphs, all bullet points)
 933: 4. Extract salary, benefits, requirements, responsibilities from the posting page
 934: 5. If company name is "Confidential" in search results - **VISIT THE URL** and extract the REAL company name from the posting page
 935: 6. If description is missing - **TRY COMPANY CAREERS PAGE** (company.com/careers) or **COMPANY ATS** (company.breezy.hr, company.greenhouse.io)
 936: 
 937: CRITICAL REQUIREMENTS:
 938: 1. **ONLY REAL COMPANY NAMES** - ABSOLUTELY NO CONFIDENTIAL LISTINGS:
 939:    ‚ùå REJECT AND SKIP: "Confidential", "Various Employers", "Multiple Companies", "Undisclosed", "Private", "TBD", "N/A", "Various [Industry]", "Anonymous", "Stealth", "Hidden"
 940:    ‚ùå DO NOT INCLUDE jobs where company name is hidden or confidential
 941:    ‚úÖ ONLY INCLUDE: Jobs with real, specific company names (e.g., "Ricoh Canada", "Shopify", "TD Bank", "Lumerate", "Zymewire")
 942: 2. **VERIFY COMPANY EXISTS** - Must be a real, identifiable company
 943: 3. **SKIP INVALID LISTINGS** - If company name is missing or confidential, DO NOT include it in results
 944: 4. **EXTRACT FULL DESCRIPTIONS** - Visit each job URL and scrape complete description (minimum 200 words)
 945: 5. Search ONLY publicly accessible listings (no login required)
 946: 6. Prioritize Canadian sources for Canadian locations
 947: 7. **Extract salary** from job posting page if available
 948: 8. Deduplicate across all sources by company + title
 949: 9. Rank by: recency ‚Üí Canadian source priority ‚Üí relevance
 950: 10. Return EXACTLY ${limit} unique listings with REAL company names and FULL descriptions
 951: 
 952: OUTPUT JSON (MUST BE VALID, COMPLETE JSON):
 953: [{
 954:   "title": string (specific job title, not "Various Positions"),
 955:   "company": string (EXACT company name, not generic),
 956:   "location": string (specific city/province),
 957:   "url": string (direct job posting link),
 958:   "summary": string (200-400 words, COMPLETE job description from posting page),
 959:   "salary": string | null (extracted from posting page),
 960:   "postedDate": "YYYY-MM-DD",
 961:   "source": string (board name),
 962:   "requirements": string[] (key requirements from posting),
 963:   "benefits": string[] (benefits mentioned in posting)
 964: }]`
 965: 
 966:     const USER_JOBS = `Search for "${jobTitle}" jobs in ${location} across these prioritized sources:
 967: ${targetBoards.slice(0, 10).join(', ')}
 968: 
 969: Return ${limit} unique, recent listings in JSON format. For Canadian locations, prioritize Job Bank, Jobboom, Workopolis first.`
 970: 
 971:     const requestId = generateRequestId()
 972:     const started = Date.now()
 973:     try {
 974:       const out = await client.makeRequest(SYSTEM_JOBS, USER_JOBS, { 
 975:         temperature: 0.2, 
 976:         maxTokens: Math.min(limit * 500, 30000), // CRITICAL FIX: Increased from 300 to 500 tokens per job for full descriptions
 977:         model: 'sonar-pro' // Use research model for job search
 978:       })
 979:       
 980:       // FIXED: Check for truncation warning
 981:       if (out.content.length > 18000) {
 982:         console.warn('[JOB_LISTINGS] Response may be truncated, consider reducing limit or splitting into batches')
 983:       }
 984:       let text = (out.content || '').trim()
 985:       
 986:       // Extract JSON from response if wrapped in markdown or explanation
 987:       const jsonMatch = text.match(/\[[\s\S]*\]/)
 988:       if (jsonMatch) {
 989:         text = jsonMatch[0]
 990:       }
 991:       
 992:       // FIX: Clean up truncated JSON
 993:       // If JSON ends abruptly without closing ], try to fix it
 994:       if (!text.endsWith(']')) {
 995:         console.warn('[PERPLEXITY] JSON appears truncated, attempting to fix')
 996:         // Find last complete object
 997:         const lastCompleteObj = text.lastIndexOf('}')
 998:         if (lastCompleteObj > 0) {
 999:           text = text.substring(0, lastCompleteObj + 1) + ']'
1000:         }
1001:       }
1002:       
1003:       // FIX: Remove trailing commas before ]
1004:       text = text.replace(/,(\s*)\]/g, '$1]')
1005:       
1006:       const context = {
1007:         requestId,
1008:         prompts: { system: SYSTEM_JOBS, user: USER_JOBS },
1009:         timestamp: started,
1010:         duration: Date.now() - started
1011:       }
1012:       let parsed: unknown
1013:       try {
1014:         parsed = parseAIResponse<unknown>(text, { stripMarkdown: true, extractFirst: true }, context)
1015:       } catch (parseError: unknown) {
1016:         console.error('[PERPLEXITY] JSON parse failed, raw text:', text.substring(0, 500))
1017:         console.error('[PERPLEXITY] Parse error:', parseError)
1018:         return []
1019:       }
1020:       
1021:       const arr = Array.isArray(parsed) ? parsed.slice(0, limit) : []
1022:       
1023:       // CRITICAL FIX: Filter out confidential companies (NO FAKE/INFERRED DATA)
1024:       const filtered = arr.filter((job: unknown) => {
1025:         const jobObj = job as Record<string, unknown>
1026:         const companyRaw = String(jobObj.company || '')
1027:         const company = companyRaw.toLowerCase().trim()
1028:         
1029:         const isConfidential = 
1030:           company.includes('confidential') ||
1031:           company.includes('anonymous') ||
1032:           company.includes('undisclosed') ||
1033:           company.includes('various') ||
1034:           company.includes('multiple') ||
1035:           company.includes('private') ||
1036:           company.includes('stealth') ||
1037:           company.includes('hidden') ||
1038:           company.includes('tbd') ||
1039:           company.includes('n/a') ||
1040:           company === '' ||
1041:           company.length < 3
1042:         
1043:         if (isConfidential) {
1044:           return false
1045:         }
1046:         return true
1047:       })
1048:       
1049:       // Filtered confidential postings
1050:       
1051:       // Enhance with board metadata
1052:       const enhanced = filtered.map((job: unknown) => {
1053:         const jobObj = job as Record<string, unknown>
1054:         return {
1055:           ...jobObj,
1056:           metadata: {
1057:             searchedBoards: targetBoards.length,
1058:             canadianPriority: includeCanadianOnly,
1059:             extractedAt: new Date().toISOString(),
1060:             confidentialFiltered: arr.length - filtered.length
1061:           }
1062:         }
1063:       })
1064:       
1065:       // FIXED: Only cache if we have good success rate (at least 80%)
1066:       const successRate = enhanced.length / limit
1067:       if (enhanced.length > 0 && successRate >= 0.8) {
1068:         setCache(key, enhanced)
1069:         // Cached jobs
1070:       } else if (enhanced.length > 0) {
1071:         // Skipping cache - low success rate
1072:       }
1073:       return enhanced
1074:     } catch (error) {
1075:       console.error('[PERPLEXITY] Job listings failed:', error)
1076:       return []
1077:     }
1078:   }
1079: 
1080:   // Fast SEARCH API for raw listings from specific domains (outside of template strings)
1081:   static async jobQuickSearch(query: string, domains: string[] = [], maxResults: number = 20, recency: 'day'|'week'|'month'|'year' = 'month'): Promise<QuickSearchItem[]> {
1082:     const key = makeKey('ppx:search', { query, domains, maxResults, recency })
1083:     const cached = getCache(key) as QuickSearchItem[] | undefined
1084:     if (cached) return cached
1085:     try {
1086:       const resp = await fetch('https://api.perplexity.ai/search', {
1087:         method: 'POST',
1088:         headers: {
1089:           'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY || ''}`,
1090:           'Content-Type': 'application/json'
1091:         },
1092:         body: JSON.stringify({
1093:           query,
1094:           max_results: Math.max(5, Math.min(25, maxResults)),
1095:           ...(domains.length ? { search_domain_filter: domains } : {}),
1096:           search_recency_filter: recency
1097:         })
1098:       })
1099:       if (!resp.ok) throw new Error('ppx search failed')
1100:       const data = await resp.json() as unknown
1101:       const asRecord = data as Record<string, unknown>
1102:       const arr = (Array.isArray(asRecord?.results) ? (asRecord.results as unknown[]) : (Array.isArray(data as unknown[]) ? (data as unknown[]) : []))
1103:       const mapped: QuickSearchItem[] = arr.map((raw: unknown) => {
1104:         const it = (raw || {}) as Record<string, unknown>
1105:         const title = typeof it.title === 'string' ? it.title : (typeof it.snippet === 'string' ? String(it.snippet) : '')
1106:         const url = typeof it.url === 'string' ? it.url : (typeof it.link === 'string' ? String(it.link) : '')
1107:         const snippet = typeof it.snippet === 'string' ? String(it.snippet) : (typeof it.summary === 'string' ? String(it.summary) : '')
1108:         const source = typeof it.domain === 'string' ? String(it.domain) : (typeof it.source === 'string' ? String(it.source) : '')
1109:         const publishedTime = it.published_time
1110:         const dateField = it.date
1111:         const published = (typeof publishedTime === 'string' ? publishedTime : (typeof dateField === 'string' ? dateField : undefined))
1112:         return { title, url, snippet, source, postedDate: published }
1113:       })
1114:       setCache(key, mapped)
1115:       return mapped
1116:     } catch {
1117:       return []
1118:     }
1119:   }
1120: 
1121:   // REMOVED: jobMarketAnalysis wrapper - Use jobMarketAnalysisV2 directly
1122:   /**
1123:    * V2: Enhanced job market analysis with options and ranking
1124:    * Now integrated with 25+ Canadian and global job boards
1125:    */
1126:   static async jobMarketAnalysisV2(
1127:     location: string, 
1128:     resumeText: string, 
1129:     options: { 
1130:       roleHint?: string
1131:       workType?: 'remote'|'hybrid'|'onsite'|'any'
1132:       salaryMin?: number
1133:       experienceLevel?: 'entry'|'mid'|'senior'|'executive'
1134:       maxResults?: number
1135:       boards?: string[] // Specify which boards to prioritize
1136:     } = {}
1137:   ): Promise<EnhancedResponse<JobListing[]>> {
1138:     const requestId = generateRequestId()
1139:     const started = Date.now()
1140:     const key = makeKey('ppx:jobmarket:v2', { location, resume: resumeText.slice(0,1000), options })
1141:     const cached = getCache(key) as JobListing[] | undefined
1142:     if (cached) return { success: true, data: cached, metadata: { requestId, timestamp: started, duration: Date.now() - started }, cached: true }
1143: 
1144:     // Determine if location is Canadian for prioritization
1145:     const isCanadian = /canada|canadian|toronto|vancouver|montreal|calgary|ottawa|edmonton|quebec|winnipeg|halifax/i.test(location)
1146:     const targetBoards = options.boards || (isCanadian 
1147:       ? DISCOVERY_PRIORITY_ORDER.filter(b => CANADIAN_JOB_BOARDS[b]).concat(['linkedin', 'indeed', 'glassdoor'])
1148:       : DISCOVERY_PRIORITY_ORDER.slice(0, 15)
1149:     )
1150: 
1151:     try {
1152:       const out = await withRetry(async () => {
1153:         const client = createClient()
1154:         const prompt = `Find ${options.maxResults || 25} relevant job opportunities in ${location} matching this profile.
1155: 
1156: RESUME:
1157: ${resumeText}
1158: 
1159: FILTERS:
1160: - Role: ${options.roleHint || '(infer from resume)'}
1161: - Work Type: ${options.workType || 'any'}
1162: - Experience: ${options.experienceLevel || 'any'}
1163: - Min Salary: ${options.salaryMin ? ('$' + options.salaryMin + '+') : 'any'}
1164: 
1165: PRIORITY JOB BOARDS (use site: search for each):
1166: ${targetBoards.slice(0, 12).map((board, i) => {
1167:   const config = CANADIAN_JOB_BOARDS[board] || MAJOR_JOB_BOARDS[board] || OPEN_API_BOARDS[board] || ATS_PLATFORMS[board]
1168:   const baseUrl = config?.scrapingConfig?.baseUrl || ''
1169:   const domain = baseUrl ? baseUrl.replace(/https?:\/\//, '').replace(/\/$/, '') : board
1170:   return `${i + 1}. site:${domain} "${options.roleHint || 'jobs'}" "${location}"`
1171: }).join('\n')}
1172: 
1173: ${isCanadian ? `
1174: CANADIAN ATS PLATFORMS - Check these tech companies:
1175: - Greenhouse: Shopify, Hootsuite, Wealthsimple, Faire, Thinkific, Lightspeed, Jobber
1176: - Lever: Slack, Bench, Clio, Clearco, League, ApplyBoard, Ritual
1177: - Workable: FreshBooks, Visier, Unbounce, Axonify, TouchBistro
1178: - Recruitee: Ecobee, Geotab, Auvik, Wave, KOHO, SkipTheDishes
1179: - Ashby: Faire, Clearco, Maple, Borrowell, Shakepay, Wealthsimple
1180: ` : ''}
1181: 
1182: REQUIREMENTS:
1183: 1. **CRITICAL**: Use real-time web search to find ACTUAL job postings from MULTIPLE boards
1184: 2. **PRIORITIZE LINKEDIN**: Search "site:linkedin.com/jobs ${options.roleHint || 'jobs'} ${location}" FIRST and get at least 15-20 LinkedIn jobs
1185: 3. Search other boards: "site:indeed.${isCanadian ? 'ca' : 'com'}", "site:glassdoor.${isCanadian ? 'ca' : 'com'}", etc.
1186: 4. Extract: title, company, location, URL (MUST be actual job posting URL), summary (at least 100 chars), posted date
1187: 5. **MANDATORY**: Return AT LEAST 30-40 jobs total. LinkedIn should be 40-50% of results.
1188: 6. **IMPORTANT**: Include jobs even if some fields are missing (use null for missing data)
1189: 7. Match resume skills to job requirements (estimate 0-100%)
1190: 8. If company is "Confidential", try to find real name from posting
1191: 9. **LINKEDIN URLS**: Must be format "https://www.linkedin.com/jobs/view/[job-id]" or "https://linkedin.com/jobs/collections/recommended/?currentJobId=[id]"
1192: 
1193: OUTPUT STRICT JSON ARRAY (no markdown, no wrapper object):
1194: [{
1195:   "title": "Job Title",
1196:   "company": "Company Name",
1197:   "location": "${location}",
1198:   "url": "https://...",
1199:   "source": "indeed",
1200:   "summary": "Brief description",
1201:   "postedDate": "2025-10-24",
1202:   "salary": "$50,000-$70,000" or null,
1203:   "skillMatchPercent": 75,
1204:   "skills": ["skill1", "skill2"],
1205:   "workType": "remote" or "hybrid" or "onsite",
1206:   "experienceLevel": "mid"
1207: }]
1208: 
1209: **CRITICAL**: Return the JSON array directly. Do NOT wrap in markdown. Return AT LEAST 25 jobs.`
1210: 
1211:         const res = await client.makeRequest(SYSTEM, prompt, { 
1212:           temperature: 0.2, // Slightly higher for more variety
1213:           maxTokens: 20000, // Increased to allow more jobs
1214:           model: 'sonar' // Use faster model for job search
1215:         })
1216:         if (!res.content?.trim()) throw new Error('Empty job analysis')
1217:         
1218:         console.log('[JOB_SEARCH_V2] Perplexity response received:', {
1219:           contentLength: res.content.length,
1220:           preview: res.content.slice(0, 500)
1221:         })
1222:         
1223:         return res
1224:       })
1225: 
1226:       console.log('[JOB_SEARCH_V2] Parsing response...')
1227:       let parsed: JobListing[] = []
1228:       
1229:       try {
1230:         let rawContent = out.content.trim()
1231:         console.log('[JOB_SEARCH_V2] Raw content preview:', rawContent.slice(0, 200))
1232:         
1233:         // CRITICAL FIX: Strip markdown code blocks
1234:         rawContent = rawContent.replace(/^```json\s*/i, '').replace(/```\s*$/i, '')
1235:         
1236:         // Try to extract JSON array if wrapped in object
1237:         const jsonMatch = rawContent.match(/\[[\s\S]*\]/)
1238:         if (jsonMatch) {
1239:           rawContent = jsonMatch[0]
1240:         }
1241:         
1242:         parsed = JSON.parse(rawContent) as JobListing[]
1243:         
1244:         console.log('[JOB_SEARCH_V2] Parsed jobs:', {
1245:           isArray: Array.isArray(parsed),
1246:           count: Array.isArray(parsed) ? parsed.length : 0,
1247:           firstJob: parsed[0] ? { title: parsed[0].title, company: parsed[0].company } : null
1248:         })
1249:       } catch (parseError) {
1250:         console.error('[JOB_SEARCH_V2] JSON parse error:', {
1251:           error: (parseError as Error).message,
1252:           contentPreview: out.content.slice(0, 500)
1253:         })
1254:         // Return empty array on parse error
1255:         parsed = []
1256:       }
1257:       
1258:       parsed = Array.isArray(parsed) ? parsed.slice(0, options.maxResults || 25) : []
1259:       
1260:       if (parsed.length === 0) {
1261:         console.warn('[JOB_SEARCH_V2] ‚ö†Ô∏è WARNING: Perplexity returned 0 jobs. This might indicate:')
1262:         console.warn('  1. No jobs found for this search')
1263:         console.warn('  2. Perplexity did not perform web search')
1264:         console.warn('  3. Response format is incorrect')
1265:         console.warn('  Content received:', out.content.slice(0, 1000))
1266:       }
1267:       
1268:       // CRITICAL FIX: Enrich jobs with short descriptions by scraping URLs
1269:       const enriched = await Promise.all(
1270:         parsed.map(async (job) => {
1271:           if (job.summary && job.summary.length < 150 && job.url) {
1272:             if (process.env.PPX_DEBUG === 'true') {
1273:               console.log(`[ENRICH] Scraping ${job.url} for full description...`)
1274:             }
1275:             const fullDescription = await this.scrapeJobURL(job.url)
1276:             if (fullDescription) {
1277:               return { ...job, summary: fullDescription }
1278:             }
1279:           }
1280:           return job
1281:         })
1282:       )
1283:       
1284:       // CRITICAL FIX: Validate job listings after enrichment
1285:       parsed = this.validateJobListings(enriched, options.maxResults || 25)
1286:       
1287:       // Enhance and normalize
1288:       parsed = parsed.map(j => ({
1289:         ...j,
1290:         skills: normalizeSkills(j.skills || []),
1291:         skillMatchPercent: Math.max(0, Math.min(100, j.skillMatchPercent || 0)),
1292:         workType: j.workType || 'onsite',
1293:         experienceLevel: j.experienceLevel || 'mid',
1294:         source: j.source || (typeof j.url === 'string' ? (new URL(j.url)).hostname.replace(/^www\./,'') : undefined),
1295:         benefits: j.benefits || [],
1296:         requirements: j.requirements || [],
1297:         metadata: {
1298:           searchedBoards: targetBoards.length,
1299:           isCanadianSearch: isCanadian,
1300:           extractedAt: new Date().toISOString()
1301:         }
1302:       }))
1303: 
1304:       // Sort by match quality, then recency
1305:       parsed.sort((a,b)=>{
1306:         if (Math.abs(a.skillMatchPercent - b.skillMatchPercent) > 5) {
1307:           return b.skillMatchPercent - a.skillMatchPercent
1308:         }
1309:         return new Date(b.postedDate).getTime() - new Date(a.postedDate).getTime()
1310:       })
1311: 
1312:       setCache(key, parsed)
1313:       return { 
1314:         success: true, 
1315:         data: parsed,
1316:         metadata: { 
1317:           requestId, 
1318:           timestamp: started, 
1319:           duration: Date.now() - started,
1320:           boardsSearched: targetBoards.length,
1321:           resultsCount: parsed.length
1322:         }, 
1323:         cached: false 
1324:       }
1325:     } catch (e) {
1326:       console.error('[JOB_SEARCH_ERROR] Job search failed:', {
1327:         error: (e as Error).message,
1328:         stack: (e as Error).stack,
1329:         location,
1330:         roleHint: options.roleHint,
1331:         boards: targetBoards.slice(0, 5)
1332:       })
1333:       
1334:       return { 
1335:         success: false, 
1336:         data: [], 
1337:         metadata: { 
1338:           requestId, 
1339:           timestamp: started, 
1340:           duration: Date.now() - started, 
1341:           error: (e as Error).message 
1342:         }, 
1343:         cached: false 
1344:       }
1345:     }
1346:   }
1347: 
1348:   // V2: Enhanced hiring contacts with email enrichment and discovery
1349:   static async hiringContactsV2(companyName: string): Promise<EnhancedResponse<HiringContact[]>> {
1350:     const requestId = generateRequestId()
1351:     const started = Date.now()
1352:     const key = makeKey('ppx:contacts:v2', { companyName })
1353:     const cached = getCache(key) as HiringContact[] | undefined
1354:     if (cached) return { success: true, data: cached, metadata: { requestId, timestamp: started, duration: Date.now() - started }, cached: true }
1355:     try {
1356:       const out = await withRetry(async () => {
1357:         const client = createClient()
1358:         
1359:         // PERPLEXITY AUDIT FIX: Use optimal configuration
1360:         const { getPerplexityConfig } = await import('./config/perplexity-configs')
1361:         const config = getPerplexityConfig('hiringContacts')
1362:         
1363:         // ULTRA-AGGRESSIVE: Multi-platform exhaustive contact scraping
1364:         const prompt = `Find ALL public hiring contacts for ${companyName} using exhaustive web and social media research.
1365: 
1366: MANDATORY SEARCH LOCATIONS (check ALL of these):
1367: 
1368: üåê OFFICIAL WEBSITE (VISIT AND SCRAPE):
1369: 1. **VISIT** ${companyName} official website /contact page - EXTRACT all emails
1370: 2. **VISIT** ${companyName} official website /careers page - EXTRACT contact info
1371: 3. **VISIT** ${companyName} official website /about page - EXTRACT team emails
1372: 4. **VISIT** ${companyName} official website /team page - EXTRACT individual emails
1373: 5. **VISIT** Website footer - EXTRACT contact emails
1374: 6. Look for: careers@, hr@, jobs@, recruiting@, talent@, info@, contact@, hello@
1375: 
1376: üîç GOOGLE SEARCHES (FOLLOW TOP 3 RESULTS):
1377: - "${companyName} HR email" - **VISIT top results and EXTRACT emails**
1378: - "${companyName} careers contact" - **VISIT and EXTRACT**
1379: - "${companyName} recruiter email" - **VISIT and EXTRACT**
1380: - "${companyName} talent acquisition contact" - **VISIT and EXTRACT**
1381: - "${companyName} hiring manager" - **VISIT and EXTRACT**
1382: 
1383: üîó LINKEDIN (VISIT PROFILES):
1384: - Search: site:linkedin.com/in/ "${companyName}" recruiter
1385: - Search: site:linkedin.com/in/ "${companyName}" HR
1386: - Search: site:linkedin.com/in/ "${companyName}" talent acquisition
1387: - **VISIT** Company LinkedIn page: linkedin.com/company/${companyName.toLowerCase().replace(/\s+/g, '-')}
1388: - **VISIT** individual LinkedIn profiles of HR employees
1389: - Extract REAL names, titles, and profile URLs
1390: 
1391: üê¶ TWITTER/X (VISIT PAGES):
1392: - Search: site:twitter.com "${companyName}" careers
1393: - **VISIT** Company Twitter bio for contact info
1394: 
1395: üìò FACEBOOK (VISIT PAGES):
1396: - Search: site:facebook.com "${companyName}" jobs
1397: - **VISIT** Company Facebook page About section
1398: 
1399: üì∑ INSTAGRAM (VISIT BIO):
1400: - **VISIT** Company Instagram bio for contact email
1401: 
1402: üíº JOB BOARDS (VISIT POSTINGS):
1403: - Search: site:indeed.com "${companyName}" contact
1404: - Search: site:glassdoor.com "${companyName}" contact
1405: - **VISIT** Job postings and EXTRACT direct contact info
1406: 
1407: üìß CONTACTOUT / HUNTER.IO:
1408: - Search: site:contactout.com "${companyName}"
1409: - **VISIT** any ContactOut pages and EXTRACT verified emails
1410: 
1411: EXTRACT ONLY VERIFIED PUBLIC INFORMATION:
1412: ‚úÖ Email addresses you SEE on websites (careers@, hr@, jobs@, recruiting@, talent@)
1413: ‚úÖ Direct employee emails found on LinkedIn/website (firstname.lastname@domain)
1414: ‚úÖ Phone numbers for HR/recruiting
1415: ‚úÖ LinkedIn profile URLs of recruiters/HR with REAL names
1416: ‚úÖ Company careers page URL
1417: 
1418: STRICT RULES:
1419: üö´ Do NOT infer or generate any email addresses
1420: üö´ Do NOT guess email patterns
1421: üö´ ONLY return information you can SEE on public pages
1422: üö´ Do NOT include personal emails (gmail, yahoo, hotmail)
1423: üö´ Do NOT make up names or contacts
1424: 
1425: RETURN FORMAT (JSON array):
1426: [
1427:   {
1428:     "name": "Sarah Johnson",
1429:     "title": "Senior Recruiter",
1430:     "email": "sarah.johnson@company.com",
1431:     "phone": "+1-888-742-6417",
1432:     "linkedinUrl": "https://linkedin.com/in/sarahjohnson",
1433:     "source": "LinkedIn profile",
1434:     "platform": "LinkedIn"
1435:   },
1436:   {
1437:     "name": "HR Department",
1438:     "title": "Human Resources",
1439:     "email": "careers@company.com",
1440:     "source": "Company website",
1441:     "platform": "Website"
1442:   }
1443: ]
1444: 
1445: IF ZERO VERIFIED CONTACTS FOUND, return empty array: []
1446: 
1447: IMPORTANT: Search ALL platforms listed above. Return ONLY verified contacts you actually found.`
1448: 
1449:         // PERPLEXITY AUDIT FIX: Use optimal token limits + sonar-pro for research
1450:         return client.makeRequest(SYSTEM, prompt, { 
1451:           temperature: config.temperature, 
1452:           maxTokens: config.maxTokens,
1453:           model: 'sonar-pro' // Use research model for multi-source search
1454:         })
1455:       })
1456:       
1457:       // CRITICAL DEBUG: Log raw Perplexity output (Perplexity recommendation)
1458:       if (process.env.PPX_DEBUG === 'true') {
1459:         console.log('[PERPLEXITY RAW]', {
1460:           method: 'hiringContactsV2',
1461:           company: companyName,
1462:           contentLength: out.content.length,
1463:           contentPreview: out.content.slice(0, 500)
1464:         })
1465:       }
1466:       
1467:       // Parse and clean Perplexity response - ENTERPRISE-GRADE JSON EXTRACTION
1468:       let cleanedContent = out.content.trim()
1469:       
1470:       // Step 1: Remove markdown code blocks
1471:       cleanedContent = cleanedContent.replace(/^```(?:json)?\s*/gm, '').replace(/```\s*$/gm, '')
1472:       
1473:       // Step 2: Extract JSON array from any surrounding text
1474:       const jsonMatch = cleanedContent.match(/\[[\s\S]*?\]/);
1475:       if (jsonMatch) {
1476:         cleanedContent = jsonMatch[0]
1477:       } else {
1478:         // Step 3: If no array found, check for explanatory text with JSON after it
1479:         const afterTextMatch = cleanedContent.match(/(?:Here|I found|Below|Results?)[\s\S]*?(\[[\s\S]*?\])/i);
1480:         if (afterTextMatch) {
1481:           cleanedContent = afterTextMatch[1]
1482:         } else {
1483:           console.warn('[HIRING_CONTACTS] No JSON array found in response, returning empty array')
1484:           return { success: false, data: [], metadata: { requestId, timestamp: started, duration: Date.now() - started, error: 'No JSON array in response' }, cached: false }
1485:         }
1486:       }
1487:       
1488:       // PERPLEXITY AUDIT FIX: Use enterprise-grade JSON extraction
1489:       const { extractEnterpriseJSON } = await import('./utils/enterprise-json-extractor')
1490:       const extractionResult = extractEnterpriseJSON(cleanedContent)
1491:       
1492:       if (!extractionResult.success) {
1493:         console.error('[HIRING_CONTACTS] Enterprise JSON extraction failed:', extractionResult.error)
1494:         console.error('[HIRING_CONTACTS] Attempted cleanups:', extractionResult.attemptedCleanups)
1495:         console.error('[HIRING_CONTACTS] Raw content preview:', out.content.slice(0, 500))
1496:         return { 
1497:           success: false, 
1498:           data: [], 
1499:           metadata: { 
1500:             requestId, 
1501:             timestamp: started, 
1502:             duration: Date.now() - started, 
1503:             error: `Enterprise JSON extraction failed: ${extractionResult.error}`,
1504:             attemptedCleanups: extractionResult.attemptedCleanups
1505:           }, 
1506:           cached: false 
1507:         }
1508:       }
1509:       
1510:       // CRITICAL FIX: ALWAYS ensure we have an array (never undefined/null)
1511:       let parsed: HiringContact[] = []
1512:       
1513:       if (Array.isArray(extractionResult.data)) {
1514:         parsed = extractionResult.data.slice(0, 8)
1515:       } else if (extractionResult.data && typeof extractionResult.data === 'object') {
1516:         // Handle case where AI returns single object instead of array
1517:         parsed = [extractionResult.data]
1518:       }
1519:       
1520:       // Enterprise extraction succeeded
1521:       
1522:       // CRITICAL: Validate and filter contacts - reject fake/personal emails
1523:       const personalDomains = ['gmail.com', 'yahoo.com', 'hotmail.com', 'outlook.com', 'aol.com', 'icloud.com', 'protonmail.com']
1524:       parsed = parsed.filter(contact => {
1525:         // Must have at least one contact method
1526:         if (!contact.email && !contact.phone && !contact.linkedinUrl) {
1527:           console.warn(`[HIRING_CONTACTS] Rejected contact with no contact method: ${contact.name}`)
1528:           return false
1529:         }
1530:         
1531:         // Reject inferred/template emails
1532:         if (contact.email?.includes('[') || 
1533:             contact.email?.includes('example.') || 
1534:             contact.email?.includes('domain.') ||
1535:             contact.email?.includes('VISIT_WEBSITE')) {
1536:           console.warn(`[HIRING_CONTACTS] Rejected template email: ${contact.email}`)
1537:           return false
1538:         }
1539:         
1540:         // Reject personal emails
1541:         if (contact.email && personalDomains.some(d => contact.email!.toLowerCase().endsWith(d))) {
1542:           console.warn(`[HIRING_CONTACTS] Rejected personal email: ${contact.email}`)
1543:           return false
1544:         }
1545:         
1546:         // Reject LinkedIn profiles without proper URL
1547:         if (contact.linkedinUrl && !contact.linkedinUrl.includes('linkedin.com/')) {
1548:           console.warn(`[HIRING_CONTACTS] Rejected invalid LinkedIn URL: ${contact.linkedinUrl}`)
1549:           return false
1550:         }
1551:         
1552:         return true
1553:       })
1554:       
1555:       // Validation complete
1556:       
1557:       // Enhance each contact with metadata
1558:       parsed = parsed.map(c => {
1559:         const domain = `${companyName.toLowerCase().replace(/\s+/g,'').replace(/[^a-z0-9]/g,'')}.com`
1560:         const inferred = c.name ? inferEmails(c.name, domain) : []
1561:         
1562:         return { 
1563:           ...c, 
1564:           confidence: Math.max(0, Math.min(1, c.confidence || 0.5)), 
1565:           alternativeEmails: c.alternativeEmails || inferred, 
1566:           emailType: (c.email ? c.emailType : 'pattern') as 'public'|'inferred'|'pattern',
1567:           discoveryMethod: c.discoveryMethod || (c.email ? 'Direct lookup' : 'Pattern inference')
1568:         }
1569:       })
1570:       
1571:       // Final result prepared
1572:       
1573:       // CRITICAL FIX: Validate contacts before returning
1574:       const validated = this.validateHiringContacts(parsed)
1575:       
1576:       // CRITICAL FIX: NO INFERRED EMAILS - return empty if none verified
1577:       // User should visit company website or use LinkedIn instead of contacting fake emails
1578:       const finalContacts = validated
1579:       
1580:       // Cache the result (even if empty)
1581:       setCache(key, finalContacts)
1582:       
1583:       return { 
1584:         success: validated.length > 0, 
1585:         data: finalContacts, 
1586:         metadata: { 
1587:           requestId, 
1588:           timestamp: started, 
1589:           duration: Date.now() - started,
1590:           contactsFound: finalContacts.length,
1591:           withEmails: finalContacts.filter(c => c.email).length,
1592:           error: validated.length === 0 
1593:             ? `No verified hiring contacts found for ${companyName}. Visit company website or use LinkedIn InMail.` 
1594:             : undefined
1595:         }, 
1596:         cached: false 
1597:       }
1598:     } catch (e) {
1599:       console.error('[HIRING_CONTACTS] Error:', e)
1600:       return { success: false, data: [], metadata: { requestId, timestamp: started, duration: Date.now() - started, error: (e as Error).message }, cached: false }
1601:     }
1602:   }
1603: 
1604:   // ... (rest of the code remains the same)
1605: 
1606:   // Extract normalized keywords and location from resume (STRICT JSON)
1607:   static async extractResumeSignals(
1608:     resumeText: string,
1609:     maxKeywords: number = 50
1610:   ): Promise<{ keywords: string[]; location?: string; locations?: string[]; personalInfo?: { name?: string; email?: string; phone?: string } }> {
1611:     const key = makeKey('ppx:resume:signals:v3', { t: resumeText.slice(0, 3000), maxKeywords })
1612:     const cached = getCache(key) as { keywords: string[]; location?: string; locations?: string[] } | undefined
1613:     if (cached) return cached
1614: 
1615:     try {
1616:       const client = createClient()
1617:       
1618:       // ENTERPRISE PROMPT - WEIGHTED KEYWORD EXTRACTION WITH TIME-BASED RELEVANCE
1619:       const prompt = `CRITICAL TASK: Extract weighted keywords, location, and personal info from this resume.
1620: 
1621: RESUME TEXT:
1622: ${resumeText}
1623: 
1624: KEYWORD EXTRACTION WITH TIME-BASED WEIGHTING:
1625: 1. Extract ALL relevant skills, technologies, and competencies (up to 50)
1626: 2. WEIGHT keywords based on:
1627:    - Years of experience using that skill (more years = higher priority)
1628:    - Recency (recent roles = higher weight than old roles or education)
1629:    - Frequency of mention across work experience
1630: 3. ORDER keywords by weighted relevance (most important first)
1631: 4. Skills from work experience should be weighted HIGHER than skills from education only
1632: 5. Calculate weight as: (years using skill / total career years) * recency_multiplier
1633: 
1634: LOCATION EXTRACTION RULES:
1635: 1. Find ANY city/province/state mentioned (email header, address, work experience)
1636: 2. Look for patterns like "City, PROVINCE" or "City, STATE"
1637: 3. Check contact information section first
1638: 4. If multiple locations, use the FIRST one found (likely primary)
1639: 5. Return EXACTLY as found (e.g., "Edmonton, AB" not "Edmonton, Alberta")
1640: 
1641: PERSONAL INFORMATION EXTRACTION:
1642: 1. Extract full name (usually at the top of resume)
1643: 2. Extract email address (look for @ symbol)
1644: 3. Extract phone number (look for phone patterns)
1645: 4. If not found, return null for that field
1646: 
1647: RETURN STRICT JSON (no explanation, no markdown):
1648: {
1649:   "keywords": ["Most Important Skill", "Second Most Important", "...", "50th skill"],
1650:   "location": "City, PROVINCE",
1651:   "personalInfo": {
1652:     "name": "Full Name",
1653:     "email": "email@example.com",
1654:     "phone": "555-1234"
1655:   }
1656: }
1657: 
1658: IMPORTANT: 
1659: - Order keywords by weighted importance (years of experience + recency)
1660: - If NO location found after thorough search, return "location": null (do NOT guess or default)
1661: - If personal info not found, return null for those fields`
1662: 
1663:       // Processing resume signals
1664: 
1665:       const response = await client.makeRequest(
1666:         'You extract keywords and locations from resumes. Return only JSON.',
1667:         prompt,
1668:         { temperature: 0.2, maxTokens: 2000, model: 'sonar-pro' } // CRITICAL FIX: Increased from 800 to handle 50 keywords
1669:       )
1670: 
1671:       if (process.env.PPX_DEBUG === 'true') {
1672:         console.log('[SIGNALS] Raw response:', response.content?.slice(0, 400))
1673:       }
1674: 
1675:       // ENTERPRISE FIX: Strip markdown code blocks that Perplexity sometimes adds
1676:       let cleanedContent = response.content.trim()
1677:       
1678:       // Remove markdown code fences (```json ... ``` or ``` ... ```)
1679:       cleanedContent = cleanedContent.replace(/^```(?:json)?\s*/gm, '').replace(/```\s*$/gm, '')
1680:       
1681:       // Extract JSON array/object if wrapped in explanatory text
1682:       const jsonMatch = cleanedContent.match(/(\{[\s\S]*\}|\[[\s\S]*\])/);
1683:       if (jsonMatch) {
1684:         cleanedContent = jsonMatch[0]
1685:       }
1686: 
1687:       const parsed = JSON.parse(cleanedContent) as { keywords: string[]; location?: string; locations?: string[]; personalInfo?: { name?: string; email?: string; phone?: string } }
1688:       
1689:       if (process.env.PPX_DEBUG === 'true') {
1690:         console.log('[SIGNALS] Parsed:', {
1691:           keywordCount: parsed.keywords?.length,
1692:           location: parsed.location,
1693:           hasLocations: !!parsed.locations,
1694:           personalInfo: parsed.personalInfo
1695:         })
1696:       }
1697: 
1698:       setCache(key, parsed)
1699:       return parsed
1700:     } catch (error) {
1701:       console.error('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
1702:       console.error('[EXTRACT SIGNALS] ‚ùå PERPLEXITY EXTRACTION FAILED')
1703:       console.error('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
1704:       console.error('[EXTRACT SIGNALS] Error:', (error as Error).message)
1705:       console.error('[EXTRACT SIGNALS] Resume text length:', resumeText.length, 'chars')
1706:       console.error('[EXTRACT SIGNALS] First 300 chars of resume:')
1707:       console.error(resumeText.substring(0, 300))
1708:       console.error('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê')
1709:       
1710:       // CRITICAL: Don't return fake data - throw error so upload route can handle it
1711:       throw new Error(`Failed to extract resume signals: ${(error as Error).message}. Resume may be missing contact information or is corrupted.`)
1712:     }
1713:   }
1714: 
1715:   // ... (rest of the code remains the same)
1716: 
1717:   /**
1718:    * ONE-SHOT COMPREHENSIVE RESEARCH
1719:    * Replaces multiple API calls with a single comprehensive prompt
1720:    * Returns: Job Analysis + Company Research + Hiring Contacts + News + Reviews
1721:    * 
1722:    * @param params - Job and resume details
1723:    * @returns Complete research data for all Career Finder pages
1724:    */
1725:   static async comprehensiveJobResearch(params: {
1726:     jobTitle: string
1727:     company: string
1728:     jobDescription: string
1729:     location?: string
1730:     resumeText: string
1731:     resumeSkills?: string[]
1732:   }): Promise<EnhancedResponse<ComprehensiveJobResearchData | null>> {
1733:     const requestId = generateRequestId()
1734:     const started = Date.now()
1735: 
1736:     try {
1737:       const client = createClient()
1738: 
1739:       const prompt = `COMPREHENSIVE JOB APPLICATION RESEARCH
1740: 
1741: - Position: ${params.jobTitle}
1742: - Company: ${params.company}
1743: - Location: ${params.location || 'Not specified'}
1744: - Description: ${params.jobDescription.slice(0, 1000)}
1745: 
1746: CANDIDATE SKILLS: ${params.resumeSkills ? params.resumeSkills.slice(0, 20).join(', ') : 'Extract from resume below'}
1747: 
1748: RESUME TEXT (First 2000 chars):
1749: ${params.resumeText.slice(0, 2000)}
1750: 
1751: ---
1752: 
1753: YOUR MISSION: Conduct a comprehensive research report covering ALL of the following sections. This is a ONE-TIME research call, so be thorough and detailed. Include clickable URLs wherever possible.
1754: 
1755: OUTPUT FORMAT (Valid JSON ONLY):
1756: \`\`\`json
1757: {
1758:   "jobAnalysis": {
1759:     "matchScore": 85,
1760:     "matchingSkills": ["skill1", "skill2"],
1761:     "missingSkills": ["skill3", "skill4"],
1762:     "skillsToHighlight": ["top skill to emphasize"],
1763:     "recommendations": ["specific action 1", "specific action 2"],
1764:     "estimatedFit": "Excellent|Good|Moderate|Poor"
1765:   },
1766:   "companyIntel": {
1767:     "company": "${params.company}",
1768:     "description": "detailed company overview (minimum 200 chars)",
1769:     "size": "employee count or range",
1770:     "revenue": "annual revenue if public",
1771:     "industry": "primary industry",
1772:     "founded": "year",
1773:     "headquarters": "city, state/country",
1774:     "website": "https://company.com",
1775:     "marketPosition": "market leader|challenger|niche player",
1776:     "generalEmail": "ONLY include if found on company website or LinkedIn - DO NOT GUESS. Leave empty if not found.",
1777:     "careersPage": "https://company.com/careers"
1778:   },
1779:   "companyPsychology": {
1780:     "culture": "detailed culture description based on reviews and public info",
1781:     "values": ["value1", "value2", "value3"],
1782:     "managementStyle": "hierarchical|flat|hybrid",
1783:     "workEnvironment": "remote-friendly|hybrid|office-centric"
1784:   },
1785:   "hiringContacts": [
1786:     {
1787:       "name": "Real Person Name - ONLY if found on LinkedIn or company website",
1788:       "title": "Talent Acquisition Manager",
1789:       "department": "Human Resources",
1790:       "email": "ONLY include if verified from LinkedIn or company website - DO NOT GUESS. Leave empty if not found.",
1791:       "linkedinUrl": "https://linkedin.com/in/person - ONLY if found",
1792:       "authority": "decision maker",
1793:       "confidence": 0.9
1794:     }
1795:   ],
1796:   "CRITICAL_INSTRUCTION": "DO NOT GUESS EMAILS. Only include emails that are explicitly found on the company website, LinkedIn profiles, or other verified sources. If no email is found, leave the field empty or set to null. NEVER construct emails like info@company.com or careers@company.com unless they are explicitly listed on official sources.",
1797:   "marketIntelligence": {
1798:     "competitivePosition": "how company compares to competitors",
1799:     "industryTrends": "relevant industry trends affecting this role",
1800:     "financialStability": "financial health assessment",
1801:     "recentPerformance": "last 12 months highlights"
1802:   },
1803:   "news": [
1804:     {
1805:       "title": "Recent news headline",
1806:       "summary": "Brief summary of the article",
1807:       "url": "https://newsource.com/article",
1808:       "date": "2024-01-15",
1809:       "source": "TechCrunch",
1810:       "impact": "positive|neutral|negative for employment"
1811:     }
1812:   ],
1813:   "reviews": [
1814:     {
1815:       "platform": "Glassdoor",
1816:       "rating": 4.2,
1817:       "summary": "Overall employee sentiment summary",
1818:       "url": "https://glassdoor.com/company-reviews",
1819:       "pros": ["pro1", "pro2"],
1820:       "cons": ["con1", "con2"]
1821:     }
1822:   ],
1823:   "compensation": {
1824:     "salaryRange": "$XX,000 - $YY,000 for ${params.jobTitle}",
1825:     "benefits": "typical benefits package"
1826:   },
1827:   "strategicRecommendations": {
1828:     "applicationStrategy": "specific advice on how to apply",
1829:     "contactStrategy": "who to contact first and how",
1830:     "interviewPrep": ["prepare for X", "research Y", "practice Z"]
1831:   },
1832:   "sources": ["https://source1.com", "https://source2.com", "https://source3.com"],
1833:   "confidenceLevel": 0.85
1834: }
1835: \`\`\`
1836: 
1837: CRITICAL REQUIREMENTS:
1838: 1. Job Analysis: Compare resume skills to job requirements, calculate match score
1839: 2. Company Intel: Search company website, LinkedIn, Crunchbase, Wikipedia for REAL data
1840:    - MUST find general company email (careers@, hr@, jobs@, info@, contact@)
1841:    - Check company website contact page, footer, careers page
1842:    - If no email found, generate likely addresses based on domain
1843: 3. Hiring Contacts: **CRITICAL - MUST FIND CONTACTS**
1844:    - Search LinkedIn, Twitter, Facebook, Instagram, company website
1845:    - Minimum 2-3 REAL hiring contacts if company has 10+ employees
1846:    - Include verified LinkedIn URLs and emails where possible
1847:    - DO NOT return fake/placeholder names
1848:    - **MANDATORY FALLBACK**: If no hiring contacts found, extract company general inbox:
1849:      * Check: careers@, hr@, jobs@, info@, hello@, contact@, support@
1850:      * Return as: {"name":"General Inbox","title":"Company Contact","email":"found@company.com"}
1851:    - NEVER return empty contacts array - app is useless without contact info
1852: 4. News: Find 2-5 recent news articles about the company with clickable URLs
1853: 5. Reviews: Search Glassdoor, Indeed, Comparably for employee reviews with clickable URLs
1854: 6. Market Intelligence: Research industry trends, competitive landscape
1855: 7. Strategic Recommendations: Provide actionable, company-specific advice
1856: 
1857: IMPORTANT:
1858: - Return ONLY valid JSON (no markdown, no explanations)
1859: - All URLs must be real and clickable
1860: - If data not found after searching, use "Not available" but ALWAYS try multiple sources first
1861: - Focus on actionable intelligence, not generic advice`
1862: 
1863:       const out = await withRetry(async () => {
1864:         return client.makeRequest(
1865:           'You are an elite corporate intelligence analyst providing comprehensive job application research. Return detailed JSON with all requested fields.',
1866:           prompt,
1867:           {
1868:             temperature: 0.2,
1869:             maxTokens: 8000,
1870:             model: 'sonar-pro'
1871:           }
1872:         )
1873:       })
1874: 
1875:       if (process.env.PPX_DEBUG === 'true') {
1876:         console.log('[COMPREHENSIVE_RESEARCH] Raw response length:', out.content.length)
1877:       }
1878: 
1879:       // Parse response
1880:       let cleanedContent = out.content.trim()
1881:       
1882:       // Remove markdown code blocks
1883:       cleanedContent = cleanedContent.replace(/^```(?:json)?\s*/gm, '').replace(/```\s*$/gm, '')
1884:       
1885:       // Extract JSON object
1886:       const jsonMatch = cleanedContent.match(/\{[\s\S]*\}/)
1887:       if (jsonMatch) {
1888:         cleanedContent = jsonMatch[0]
1889:       }
1890: 
1891:       const parsed = JSON.parse(cleanedContent) as Partial<ComprehensiveJobResearchData>
1892: 
1893:       // Construct with fallbacks
1894:       const data: ComprehensiveJobResearchData = {
1895:         jobAnalysis: {
1896:           matchScore: parsed.jobAnalysis?.matchScore ?? 0,
1897:           matchingSkills: parsed.jobAnalysis?.matchingSkills ?? [],
1898:           missingSkills: parsed.jobAnalysis?.missingSkills ?? [],
1899:           skillsToHighlight: parsed.jobAnalysis?.skillsToHighlight ?? [],
1900:           recommendations: parsed.jobAnalysis?.recommendations ?? [],
1901:           estimatedFit: parsed.jobAnalysis?.estimatedFit ?? 'Unknown'
1902:         },
1903:         companyIntel: {
1904:           company: parsed.companyIntel?.company ?? params.company,
1905:           description: parsed.companyIntel?.description ?? 'No description available',
1906:           size: parsed.companyIntel?.size ?? 'Unknown',
1907:           revenue: parsed.companyIntel?.revenue,
1908:           industry: parsed.companyIntel?.industry ?? 'Unknown',
1909:           founded: parsed.companyIntel?.founded,
1910:           headquarters: parsed.companyIntel?.headquarters,
1911:           website: parsed.companyIntel?.website,
1912:           marketPosition: parsed.companyIntel?.marketPosition
1913:         },
1914:         companyPsychology: {
1915:           culture: parsed.companyPsychology?.culture ?? 'No information available',
1916:           values: parsed.companyPsychology?.values ?? [],
1917:           managementStyle: parsed.companyPsychology?.managementStyle,
1918:           workEnvironment: parsed.companyPsychology?.workEnvironment
1919:         },
1920:         hiringContacts: Array.isArray(parsed.hiringContacts)
1921:           ? parsed.hiringContacts
1922:               .map(contact => ({
1923:                 name: contact.name,
1924:                 title: contact.title,
1925:                 department: contact.department,
1926:                 email: contact.email,
1927:                 linkedinUrl: contact.linkedinUrl,
1928:                 authority: contact.authority ?? 'manager',
1929:                 confidence: contact.confidence ?? 0,
1930:                 contactMethod: contact.contactMethod
1931:               }))
1932:               .filter(contact => !!contact?.name && contact?.title)
1933:           : [],
1934:         marketIntelligence: {
1935:           competitivePosition: parsed.marketIntelligence?.competitivePosition,
1936:           industryTrends: parsed.marketIntelligence?.industryTrends,
1937:           financialStability: parsed.marketIntelligence?.financialStability,
1938:           recentPerformance: parsed.marketIntelligence?.recentPerformance
1939:         },
1940:         news: Array.isArray(parsed.news)
1941:           ? parsed.news
1942:               .map(item => (item?.title && item?.summary && item?.url
1943:                 ? {
1944:                     title: item.title,
1945:                     summary: item.summary,
1946:                     url: item.url,
1947:                     date: item.date,
1948:                     source: item.source,
1949:                     impact: item.impact
1950:                   }
1951:                 : undefined))
1952:               .filter((item): item is NonNullable<typeof item> => !!item)
1953:           : [],
1954:         reviews: Array.isArray(parsed.reviews)
1955:           ? parsed.reviews
1956:               .map(item => (item?.platform && item?.summary && item?.url
1957:                 ? {
1958:                     platform: item.platform,
1959:                     rating: item.rating,
1960:                     summary: item.summary,
1961:                     url: item.url,
1962:                     pros: item.pros,
1963:                     cons: item.cons
1964:                   }
1965:                 : undefined))
1966:               .filter((item): item is NonNullable<typeof item> => !!item)
1967:           : [],
1968:         compensation: parsed.compensation ?? {},
1969:         strategicRecommendations: {
1970:           applicationStrategy: parsed.strategicRecommendations?.applicationStrategy ?? 'Apply through company website',
1971:           contactStrategy: parsed.strategicRecommendations?.contactStrategy ?? 'Reach out to HR via LinkedIn',
1972:           interviewPrep: parsed.strategicRecommendations?.interviewPrep ?? []
1973:         },
1974:         sources: Array.isArray(parsed.sources)
1975:           ? parsed.sources.filter((source): source is string => typeof source === 'string')
1976:           : [],
1977:         confidenceLevel: parsed.confidenceLevel ?? 0.5
1978:       }
1979: 
1980:       if (process.env.PPX_DEBUG === 'true') {
1981:         console.log('[COMPREHENSIVE_RESEARCH] Complete -', 
1982:           'matchScore:', data.jobAnalysis.matchScore, 
1983:           'contacts:', data.hiringContacts.length, 
1984:           'news:', data.news.length, 
1985:           'reviews:', data.reviews.length, 
1986:           'confidence:', data.confidenceLevel
1987:         )
1988:       }
1989: 
1990:       return {
1991:         success: true,
1992:         data,
1993:         metadata: { requestId, timestamp: started, duration: Date.now() - started },
1994:         cached: false
1995:       }
1996:     } catch (error) {
1997:       console.error('[COMPREHENSIVE_RESEARCH] Error:', error)
1998:       return {
1999:         success: false,
2000:         data: null,
2001:         metadata: { 
2002:           requestId, 
2003:           timestamp: started, 
2004:           duration: Date.now() - started,
2005:           error: (error as Error).message 
2006:         },
2007:         cached: false
2008:       }
2009:     }
2010:   }
2011: 
2012:   // Resume Optimizer: Generate tailored resume variants
2013:   static async generateResumeVariants(params: {
2014:     resumeText: string
2015:     jobTitle: string
2016:     jobRequirements: string[]
2017:     companyInsights: { culture: string; values: string[]; industry: string }
2018:     template?: string
2019:   }): Promise<EnhancedResponse<{
2020:     variantA: string
2021:     variantB: string
2022:     recommendations: string[]
2023:   }>> {
2024:     const requestId = generateRequestId()
2025:     const started = Date.now()
2026:     const cacheKey = makeKey('resume-variants', params)
2027:     
2028:     const cached = getCache(cacheKey)
2029:     if (cached) {
2030:       return {
2031:         success: true,
2032:         data: cached as { variantA: string; variantB: string; recommendations: string[] },
2033:         metadata: { requestId, timestamp: started, duration: 0 },
2034:         cached: true
2035:       }
2036:     }
2037: 
2038:     try {
2039:       const client = createClient()
2040:       const systemPrompt = 'You are a professional resume optimization expert. Return only valid JSON with properly formatted resume text.'
2041:       
2042:       // Build template-specific instructions
2043:       const templateInstructions = {
2044:         modern: 'Use a contemporary style with visual hierarchy. Emphasize innovation and forward-thinking achievements.',
2045:         professional: 'Use traditional, formal language. Focus on stability, reliability, and proven track record.',
2046:         creative: 'Use dynamic language and unique phrasing. Highlight creativity, innovation, and out-of-the-box thinking.',
2047:         tech: 'Use technical terminology and emphasize projects, technologies, and technical achievements.',
2048:         minimal: 'Use simple, direct language. Focus on facts and quantifiable results. Maximum ATS compatibility.',
2049:         executive: 'Use leadership language. Emphasize strategic impact, team leadership, and business results.'
2050:       }
2051:       
2052:       const templateStyle = templateInstructions[params.template as keyof typeof templateInstructions] || templateInstructions.modern
2053:       
2054:       const userPrompt = `Analyze this resume and create TWO tailored variants for the target role using the ${params.template} template style.
2055: 
2056: **Resume:**
2057: ${params.resumeText}
2058: 
2059: **Target Role:** ${params.jobTitle}
2060: 
2061: **Key Requirements:**
2062: ${params.jobRequirements.map((req, i) => `${i + 1}. ${req}`).join('\n')}
2063: 
2064: **Company Culture:** ${params.companyInsights.culture}
2065: **Company Values:** ${params.companyInsights.values.join(', ')}
2066: **Industry:** ${params.companyInsights.industry}
2067: 
2068: **Template Style (${params.template}):** ${templateStyle}
2069: 
2070: Generate TWO resume variants:
2071: 1. **Variant A (Achievement-Focused):** Emphasize quantifiable achievements and metrics. ${templateStyle}
2072: 2. **Variant B (Skills-Focused):** Highlight technical skills and competencies. ${templateStyle}
2073: 
2074: CRITICAL FORMATTING REQUIREMENTS:
2075: - Use proper line breaks (\\n\\n for sections, \\n for lines)
2076: - DO NOT include name, email, phone, or address in the resume body
2077: - Personal contact info will be added separately by the template
2078: - Start directly with PROFESSIONAL SUMMARY or first section
2079: - Use clear section headers (PROFESSIONAL SUMMARY, EXPERIENCE, EDUCATION, SKILLS)
2080: - Format each job entry with: Title\\nCompany | Location | Dates\\n‚Ä¢ Achievement 1\\n‚Ä¢ Achievement 2
2081: - Keep bullet points aligned with ‚Ä¢ symbol
2082: - Ensure proper spacing between sections
2083: - NO markdown formatting (no **, no #, no _)
2084: - Plain text only with line breaks
2085: - INCLUDE ALL job history from original resume
2086: 
2087: CRITICAL - PERSONAL INFO:
2088: - DO NOT include the person's name anywhere in the resume body
2089: - DO NOT include email address in the resume body
2090: - DO NOT include phone number in the resume body
2091: - DO NOT include physical address in the resume body
2092: - These will be added by the template header automatically
2093: - Start the resume body with the PROFESSIONAL SUMMARY section
2094: 
2095: For each variant, rewrite the resume to:
2096: - Match keywords from job requirements
2097: - Align with company culture and values
2098: - Use industry-specific terminology appropriate for ${params.template} template
2099: - Optimize for ATS (Applicant Tracking Systems)
2100: - Keep formatting clean and professional
2101: - Apply ${params.template} template style throughout
2102: - NEVER duplicate personal contact information
2103: 
2104: Also provide 3-5 strategic recommendations for improving the resume.
2105: 
2106: Return ONLY valid JSON:
2107: {
2108:   "variantA": "Full resume text WITHOUT personal info (starts with PROFESSIONAL SUMMARY)...",
2109:   "variantB": "Full resume text WITHOUT personal info (starts with PROFESSIONAL SUMMARY)...",
2110:   "recommendations": ["Recommendation 1", "Recommendation 2", ...]
2111: }`
2112: 
2113:       const response = await withRetry(
2114:         () => client.makeRequest(systemPrompt, userPrompt, { temperature: 0.2, maxTokens: 4000, model: 'sonar-pro' }),
2115:         MAX_RETRY_ATTEMPTS
2116:       )
2117: 
2118:       const parsed = parseAIResponse<{
2119:         variantA: string
2120:         variantB: string
2121:         recommendations: string[]
2122:       }>(response.content)
2123: 
2124:       const data = {
2125:         variantA: parsed.variantA || params.resumeText,
2126:         variantB: parsed.variantB || params.resumeText,
2127:         recommendations: Array.isArray(parsed.recommendations) ? parsed.recommendations : []
2128:       }
2129: 
2130:       setCache(cacheKey, data)
2131: 
2132:       return {
2133:         success: true,
2134:         data,
2135:         metadata: { requestId, timestamp: started, duration: Date.now() - started },
2136:         cached: false
2137:       }
2138:     } catch (error) {
2139:       console.error('[RESUME_VARIANTS] Error:', error)
2140:       return {
2141:         success: false,
2142:         data: {
2143:           variantA: params.resumeText,
2144:           variantB: params.resumeText,
2145:           recommendations: []
2146:         },
2147:         metadata: { 
2148:           requestId, 
2149:           timestamp: started, 
2150:           duration: Date.now() - started,
2151:           error: (error as Error).message 
2152:         },
2153:         cached: false
2154:       }
2155:     }
2156:   }
2157: 
2158:   // Cover Letter Generator: Create personalized cover letters using templates
2159:   static async generateCoverLetters(params: {
2160:     jobTitle: string
2161:     company: string
2162:     jobRequirements: string[]
2163:     resumeText: string
2164:     companyInsights: {
2165:       culture: string
2166:       values: string[]
2167:       recentNews: Array<{ title: string; summary: string }>
2168:     }
2169:     hiringManager?: { name: string; title: string }
2170:     userName?: string
2171:     templateId?: string
2172:   }): Promise<EnhancedResponse<{
2173:     variantA: string
2174:     variantB: string
2175:     personalization: string[]
2176:   }>> {
2177:     const requestId = generateRequestId()
2178:     const started = Date.now()
2179:     const cacheKey = makeKey('cover-letters', params)
2180:     
2181:     const cached = getCache(cacheKey)
2182:     if (cached) {
2183:       return {
2184:         success: true,
2185:         data: cached as { variantA: string; variantB: string; personalization: string[] },
2186:         metadata: { requestId, timestamp: started, duration: 0 },
2187:         cached: true
2188:       }
2189:     }
2190: 
2191:     try {
2192:       // CRITICAL FIX: Calculate years of experience to prevent hallucinations
2193:       const yearsExperience = calculateYearsFromResume(params.resumeText)
2194:       if (process.env.PPX_DEBUG === 'true') {
2195:         console.log('[COVER_LETTERS] Calculated experience:', yearsExperience, 'years')
2196:       }
2197: 
2198:       // Get templates - use professional and modern as defaults
2199:       const templateA = getCoverLetterTemplateById(params.templateId || 'professional')
2200:       const templateB = getCoverLetterTemplateById('modern')
2201: 
2202:       const client = createClient()
2203:       const systemPrompt = `You are an expert cover letter writer. Use the provided templates as structure guides and fill them with personalized content from the candidate's resume.
2204: 
2205: CRITICAL EXPERIENCE CONSTRAINT:
2206: - Candidate has EXACTLY ${yearsExperience} years of total work experience
2207: - DO NOT say "decades", "38 years", or any number higher than ${yearsExperience}
2208: - If ${yearsExperience} < 10, say "several years" or "${yearsExperience} years"
2209: - If ${yearsExperience} >= 10 && ${yearsExperience} < 20, say "${yearsExperience} years" or "over a decade"
2210: - If ${yearsExperience} >= 20, say "${yearsExperience} years" or "two decades"
2211: - NEVER invent or exaggerate experience duration
2212: - Use ONLY the experience data provided in the resume
2213: 
2214: Return only valid JSON.`
2215: 
2216:       const userPrompt = `Create TWO personalized cover letter variants using these templates as guides:
2217: 
2218: **TEMPLATE A (${templateA.name}):**
2219: ${templateA.template}
2220: 
2221: **TEMPLATE B (${templateB.name}):**
2222: ${templateB.template}
2223: 
2224: **Job Details:**
2225: - Job Title: ${params.jobTitle}
2226: - Company: ${params.company}
2227: - Hiring Manager: ${params.hiringManager?.name || 'Hiring Manager'}
2228: - Applicant: ${params.userName || '[Your Name]'}
2229: 
2230: **Key Requirements:**
2231: ${params.jobRequirements.map((req, i) => `${i + 1}. ${req}`).join('\n')}
2232: 
2233: **Resume Content (${yearsExperience} years experience):**
2234: ${params.resumeText.slice(0, 1500)}
2235: 
2236: **Company Research:**
2237: - Culture: ${params.companyInsights.culture}
2238: - Values: ${params.companyInsights.values.join(', ')}
2239: - Recent News: ${params.companyInsights.recentNews.map(n => n.title).join(', ')}
2240: 
2241: **Instructions:**
2242: 1. Fill in ALL placeholders in the templates with actual data
2243: 2. Replace [X years] with "${yearsExperience} years" (EXACT number)
2244: 3. Use real achievements from resume with metrics
2245: 4. Reference specific company news/values
2246: 5. Keep the template structure but personalize content
2247: 6. Variant A: Use Template A structure
2248: 7. Variant B: Use Template B structure
2249: 
2250: CRITICAL RULES:
2251: - Experience: EXACTLY ${yearsExperience} years (no more, no less)
2252: - NO generic phrases like "proven track record" without specifics
2253: - NO casual language like "Here's what most people don't realize"
2254: - ALL achievements must come from the actual resume
2255: - Keep professional and mature tone
2256: 
2257: Return ONLY valid JSON:
2258: {
2259:   "variantA": "Full cover letter text using Template A structure...",
2260:   "variantB": "Full cover letter text using Template B structure...",
2261:   "personalization": ["Tip 1", "Tip 2", "Tip 3"]
2262: }`
2263: 
2264:       const response = await withRetry(
2265:         () => client.makeRequest(systemPrompt, userPrompt, { temperature: 0.3, maxTokens: 4000, model: 'sonar-pro' }),
2266:         MAX_RETRY_ATTEMPTS
2267:       )
2268: 
2269:       const parsed = parseAIResponse<{
2270:         variantA: string
2271:         variantB: string
2272:         personalization: string[]
2273:       }>(response.content)
2274: 
2275:       const data = {
2276:         variantA: parsed.variantA || 'Cover letter generation failed',
2277:         variantB: parsed.variantB || 'Cover letter generation failed',
2278:         personalization: Array.isArray(parsed.personalization) ? parsed.personalization : []
2279:       }
2280: 
2281:       setCache(cacheKey, data)
2282: 
2283:       return {
2284:         success: true,
2285:         data,
2286:         metadata: { requestId, timestamp: started, duration: Date.now() - started },
2287:         cached: false
2288:       }
2289:     } catch (error) {
2290:       console.error('[COVER_LETTERS] Error:', error)
2291:       return {
2292:         success: false,
2293:         data: {
2294:           variantA: 'Cover letter generation failed',
2295:           variantB: 'Cover letter generation failed',
2296:           personalization: []
2297:         },
2298:         metadata: { 
2299:           requestId, 
2300:           timestamp: started, 
2301:           duration: Date.now() - started,
2302:           error: (error as Error).message 
2303:         },
2304:         cached: false
2305:       }
2306:     }
2307:   }
2308: 
2309:   // Email Outreach Generator: Create personalized email templates
2310:   static async generateEmailOutreach(params: {
2311:     hiringContact: { name: string; title: string; email?: string }
2312:     jobTitle: string
2313:     company: string
2314:     resumeHighlights: string[]
2315:   }): Promise<EnhancedResponse<{
2316:     subjects: string[]
2317:     templates: Array<{ type: 'formal' | 'conversational'; body: string }>
2318:     mailtoLink: string
2319:   }>> {
2320:     const requestId = generateRequestId()
2321:     const started = Date.now()
2322:     const cacheKey = makeKey('email-outreach', params)
2323:     
2324:     const cached = getCache(cacheKey)
2325:     if (cached) {
2326:       return {
2327:         success: true,
2328:         data: cached as { subjects: string[]; templates: Array<{ type: 'formal' | 'conversational'; body: string }>; mailtoLink: string },
2329:         metadata: { requestId, timestamp: started, duration: 0 },
2330:         cached: true
2331:       }
2332:     }
2333: 
2334:     try {
2335:       const client = createClient()
2336:       const systemPrompt = 'You are an expert at professional networking and cold email outreach. Return only valid JSON.'
2337:       const userPrompt = `Create personalized email outreach templates for contacting a hiring manager.
2338: 
2339: **Hiring Contact:** ${params.hiringContact.name}, ${params.hiringContact.title}
2340: **Job Title:** ${params.jobTitle}
2341: **Company:** ${params.company}
2342: 
2343: **Resume Highlights:**
2344: ${params.resumeHighlights.map((h, i) => `${i + 1}. ${h}`).join('\n')}
2345: 
2346: Generate:
2347: 1. **3 email subject lines** (varied approaches: direct, curious, value-focused)
2348: 2. **2 email templates:**
2349:    - Formal: Professional, respectful tone
2350:    - Conversational: Friendly, engaging tone
2351: 
2352: Each template should:
2353: - Be concise (150-200 words)
2354: - Reference the hiring manager by name
2355: - Show genuine interest in the role/company
2356: - Highlight 1-2 relevant achievements
2357: - Include a clear call-to-action
2358: - Be personalized, not generic
2359: 
2360: Return ONLY valid JSON:
2361: {
2362:   "subjects": ["Subject 1", "Subject 2", "Subject 3"],
2363:   "templates": [
2364:     { "type": "formal", "body": "Email body..." },
2365:     { "type": "conversational", "body": "Email body..." }
2366:   ]
2367: }`
2368: 
2369:       const response = await withRetry(
2370:         () => client.makeRequest(systemPrompt, userPrompt, { temperature: 0.4, maxTokens: 3000, model: 'sonar-pro' }),
2371:         MAX_RETRY_ATTEMPTS
2372:       )
2373: 
2374:       const parsed = parseAIResponse<{
2375:         subjects: string[]
2376:         templates: Array<{ type: 'formal' | 'conversational'; body: string }>
2377:       }>(response.content)
2378: 
2379:       const mailtoLink = params.hiringContact.email 
2380:         ? `mailto:${params.hiringContact.email}?subject=${encodeURIComponent(parsed.subjects?.[0] || 'Inquiry about ' + params.jobTitle)}`
2381:         : ''
2382: 
2383:       const data = {
2384:         subjects: Array.isArray(parsed.subjects) ? parsed.subjects : [],
2385:         templates: Array.isArray(parsed.templates) ? parsed.templates : [],
2386:         mailtoLink
2387:       }
2388: 
2389:       setCache(cacheKey, data)
2390: 
2391:       return {
2392:         success: true,
2393:         data,
2394:         metadata: { requestId, timestamp: started, duration: Date.now() - started },
2395:         cached: false
2396:       }
2397:     } catch (error) {
2398:       console.error('[EMAIL_OUTREACH] Error:', error)
2399:       return {
2400:         success: false,
2401:         data: {
2402:           subjects: [],
2403:           templates: [],
2404:           mailtoLink: ''
2405:         },
2406:         metadata: { 
2407:           requestId, 
2408:           timestamp: started, 
2409:           duration: Date.now() - started,
2410:           error: (error as Error).message 
2411:         },
2412:         cached: false
2413:       }
2414:     }
2415:   }
2416: 
2417:   /**
2418:    * AGENT-POWERED: Job search with 95%+ reliability
2419:    * Uses NEW orchestrator-based agent system with Perplexity web_search + Cheerio fallback
2420:    * Searches 15+ job boards in parallel
2421:    */
2422:   static async jobListingsWithAgent(
2423:     jobTitle: string,
2424:     location: string,
2425:     options?: { maxResults?: number; workType?: 'remote'|'hybrid'|'onsite'|'any' }
2426:   ): Promise<EnhancedResponse<JobListing[]>> {
2427:     const started = Date.now()
2428:     const requestId = generateRequestId()
2429: 
2430:     console.log('ü§ñ [INTELLIGENCE] Starting NEW agent-powered job search...')
2431:     console.log(`üìã [INTELLIGENCE] Job: "${jobTitle}" in "${location}"`)
2432:     console.log(`üéØ [INTELLIGENCE] Max results: ${options?.maxResults || 30}`)
2433: 
2434:     try {
2435:       const { AgentOrchestrator } = await import('./agents/agent-orchestrator')
2436:       
2437:       const orchestrator = new AgentOrchestrator()
2438: 
2439:       const task = {
2440:         id: requestId,
2441:         type: 'job_search' as const,
2442:         input: { 
2443:           jobTitle, 
2444:           location, 
2445:           maxResults: options?.maxResults || 30,
2446:           workType: options?.workType
2447:         },
2448:         priority: 1 as const
2449:       }
2450: 
2451:       const result = await orchestrator.executeTask(task)
2452: 
2453:       if (!result.success || !result.data || result.data.length === 0) {
2454:         console.warn('‚ö†Ô∏è [INTELLIGENCE] Agent found no jobs, using fallback method')
2455:         return await this.jobMarketAnalysisV2(location, '', {
2456:           roleHint: jobTitle,
2457:           maxResults: options?.maxResults,
2458:           workType: options?.workType
2459:         })
2460:       }
2461: 
2462:       console.log(`‚úÖ [INTELLIGENCE] Agent found ${result.data.length} jobs`)
2463:       console.log(`üìä [INTELLIGENCE] Confidence: ${result.confidence}, Method: ${result.method}`)
2464: 
2465:       return {
2466:         success: true,
2467:         data: result.data,
2468:         metadata: {
2469:           requestId,
2470:           timestamp: started,
2471:           duration: result.duration,
2472:           reasoning: result.reasoning,
2473:           confidence: result.confidence,
2474:           method: result.method,
2475:           sources: result.sources.length
2476:         },
2477:         cached: false
2478:       }
2479:     } catch (error) {
2480:       console.error('‚ùå [INTELLIGENCE] Agent system failed:', error)
2481:       console.log('üîÑ [INTELLIGENCE] Falling back to standard method...')
2482:       
2483:       return await this.jobMarketAnalysisV2(location, '', {
2484:         roleHint: jobTitle,
2485:         maxResults: options?.maxResults,
2486:         workType: options?.workType
2487:       })
2488:     }
2489:   }
2490: 
2491:   /**
2492:    * AGENT-POWERED: Hiring contacts with 95%+ reliability
2493:    * Uses NEW orchestrator-based agent system with Perplexity + Hunter.io verification
2494:    * Returns empty array if no verified contacts (NO GUESSING)
2495:    */
2496:   static async hiringContactsWithAgent(
2497:     companyName: string,
2498:     companyDomain?: string
2499:   ): Promise<EnhancedResponse<HiringContact[]>> {
2500:     const started = Date.now()
2501:     const requestId = generateRequestId()
2502: 
2503:     console.log('ü§ñ [INTELLIGENCE] Starting NEW agent-powered contact research...')
2504:     console.log(`üè¢ [INTELLIGENCE] Company: "${companyName}"`)
2505:     console.log(`üåê [INTELLIGENCE] Domain: ${companyDomain || 'auto-detect'}`)
2506: 
2507:     try {
2508:       const { AgentOrchestrator } = await import('./agents/agent-orchestrator')
2509:       
2510:       const orchestrator = new AgentOrchestrator()
2511: 
2512:       const task = {
2513:         id: requestId,
2514:         type: 'contact_research' as const,
2515:         input: { 
2516:           companyName,
2517:           companyDomain
2518:         },
2519:         priority: 1 as const
2520:       }
2521: 
2522:       const result = await orchestrator.executeTask(task)
2523: 
2524:       if (!result.success || !result.data || result.data.length === 0) {
2525:         console.warn('‚ö†Ô∏è [INTELLIGENCE] No verified contacts found')
2526:         return {
2527:           success: false,
2528:           data: [],
2529:           metadata: {
2530:             requestId,
2531:             timestamp: started,
2532:             duration: result.duration,
2533:             error: `No verified hiring contacts found for ${companyName}. Visit company website or use LinkedIn InMail.`,
2534:             reasoning: result.reasoning
2535:           },
2536:           cached: false
2537:         }
2538:       }
2539: 
2540:       console.log(`‚úÖ [INTELLIGENCE] Found ${result.data.length} verified contacts`)
2541:       console.log(`üìä [INTELLIGENCE] Confidence: ${result.confidence}`)
2542: 
2543:       return {
2544:         success: true,
2545:         data: result.data,
2546:         metadata: {
2547:           requestId,
2548:           timestamp: started,
2549:           duration: result.duration,
2550:           reasoning: result.reasoning,
2551:           confidence: result.confidence,
2552:           method: result.method,
2553:           sources: result.sources.length
2554:         },
2555:         cached: false
2556:       }
2557:     } catch (error) {
2558:       console.error('‚ùå [INTELLIGENCE] Contact agent system failed:', error)
2559:       console.log('üîÑ [INTELLIGENCE] Falling back to standard method...')
2560:       return await this.hiringContactsV2(companyName)
2561:     }
2562:   }
2563: 
2564:   /**
2565:    * Clear cache entries (admin utility)
2566:    * @param prefix - Optional prefix to clear specific cache entries
2567:    * @returns Number of entries cleared
2568:    */
2569:   static clearCache(prefix?: string): number {
2570:     if (!prefix) {
2571:       const size = cache.size
2572:       cache.clear()
2573:       return size
2574:     }
2575:     
2576:     let cleared = 0
2577:     for (const key of cache.keys()) {
2578:       if (key.startsWith(prefix)) {
2579:         cache.delete(key)
2580:         cleared++
2581:       }
2582:     }
2583:     return cleared
2584:   }
2585: 
2586:   /**
2587:    * Get cache statistics (admin utility)
2588:    * @returns Cache stats including size, hit counts, and breakdown by prefix
2589:    */
2590:   static getCacheStats(): {
2591:     totalEntries: number
2592:     totalHits: number
2593:     breakdown: Record<string, { count: number; hits: number }>
2594:   } {
2595:     const breakdown: Record<string, { count: number; hits: number }> = {}
2596:     let totalHits = 0
2597: 
2598:     for (const [key, record] of cache.entries()) {
2599:       const prefix = key.split(':')[0] || 'unknown'
2600:       if (!breakdown[prefix]) {
2601:         breakdown[prefix] = { count: 0, hits: 0 }
2602:       }
2603:       breakdown[prefix].count++
2604:       breakdown[prefix].hits += record.metadata.hitCount
2605:       totalHits += record.metadata.hitCount
2606:     }
2607: 
2608:     return {
2609:       totalEntries: cache.size,
2610:       totalHits,
2611:       breakdown
2612:     }
2613:   }
2614: 
2615:   /**
2616:    * Custom query to Perplexity API (flexible utility)
2617:    * @param options - Query options including prompts and parameters
2618:    * @returns API response content
2619:    */
2620:   static async customQuery(options: {
2621:     systemPrompt: string
2622:     userPrompt: string
2623:     temperature?: number
2624:     maxTokens?: number
2625:     model?: 'sonar' | 'sonar-pro'
2626:   }): Promise<{ content: string }> {
2627:     const client = createClient()
2628:     const response = await client.makeRequest(
2629:       options.systemPrompt,
2630:       options.userPrompt,
2631:       {
2632:         temperature: options.temperature || 0.2,
2633:         maxTokens: options.maxTokens || 4000,
2634:         model: options.model || 'sonar-pro'
2635:       }
2636:     )
2637:     return { content: response.content }
2638:   }
2639: 
2640:   /**
2641:    * Get recommended job boards based on location
2642:    * @param location - User's location (e.g., "Toronto", "Canada", "USA")
2643:    * @returns Array of recommended job board names
2644:    */
2645:   static getRecommendedBoards(location: string): string[] {
2646:     const lowerLocation = location.toLowerCase()
2647:     const isCanadian = lowerLocation.includes('canada') || 
2648:                        lowerLocation.includes('toronto') || 
2649:                        lowerLocation.includes('vancouver') || 
2650:                        lowerLocation.includes('montreal') ||
2651:                        lowerLocation.includes('calgary') ||
2652:                        lowerLocation.includes('ottawa')
2653: 
2654:     if (isCanadian) {
2655:       return [
2656:         'Indeed Canada',
2657:         'Workopolis',
2658:         'Job Bank (Canada)',
2659:         'LinkedIn',
2660:         'Glassdoor',
2661:         'Monster Canada',
2662:         'CareerBuilder Canada',
2663:         'Eluta.ca',
2664:         'CharityVillage (Non-profit)',
2665:         'TechTO (Tech jobs)'
2666:       ]
2667:     }
2668: 
2669:     // Default US/International boards
2670:     return [
2671:       'Indeed',
2672:       'LinkedIn',
2673:       'Glassdoor',
2674:       'Monster',
2675:       'CareerBuilder',
2676:       'ZipRecruiter',
2677:       'SimplyHired',
2678:       'Dice (Tech)',
2679:       'AngelList (Startups)',
2680:       'RemoteOK (Remote)'
2681:     ]
2682:   }
2683: 
2684:   /**
2685:    * Get list of available job boards
2686:    * @returns Array of job board objects with name and URL
2687:    */
2688:   static getAvailableJobBoards(): Array<{ name: string; url: string; region: string }> {
2689:     return [
2690:       { name: 'Indeed', url: 'https://www.indeed.com', region: 'Global' },
2691:       { name: 'LinkedIn', url: 'https://www.linkedin.com/jobs', region: 'Global' },
2692:       { name: 'Glassdoor', url: 'https://www.glassdoor.com', region: 'Global' },
2693:       { name: 'Monster', url: 'https://www.monster.com', region: 'Global' },
2694:       { name: 'CareerBuilder', url: 'https://www.careerbuilder.com', region: 'US' },
2695:       { name: 'ZipRecruiter', url: 'https://www.ziprecruiter.com', region: 'US' },
2696:       { name: 'SimplyHired', url: 'https://www.simplyhired.com', region: 'US' },
2697:       { name: 'Dice', url: 'https://www.dice.com', region: 'US (Tech)' },
2698:       { name: 'Indeed Canada', url: 'https://ca.indeed.com', region: 'Canada' },
2699:       { name: 'Workopolis', url: 'https://www.workopolis.com', region: 'Canada' },
2700:       { name: 'Job Bank', url: 'https://www.jobbank.gc.ca', region: 'Canada' },
2701:       { name: 'Eluta', url: 'https://www.eluta.ca', region: 'Canada' },
2702:       { name: 'AngelList', url: 'https://angel.co/jobs', region: 'Startups' },
2703:       { name: 'RemoteOK', url: 'https://remoteok.com', region: 'Remote' },
2704:       { name: 'We Work Remotely', url: 'https://weworkremotely.com', region: 'Remote' }
2705:     ]
2706:   }
2707: 
2708:   /**
2709:    * Extract career timeline from resume
2710:    * @param resumeText - Resume text content
2711:    * @returns Career timeline with industries and experience
2712:    */
2713:   static async extractCareerTimeline(resumeText: string): Promise<{
2714:     industries: Array<{ name: string; percentage: number; years: number }>
2715:     totalYears: number
2716:     primaryIndustry: string
2717:   }> {
2718:     const client = createClient()
2719:     const prompt = `Analyze this resume and extract the career timeline:
2720: 
2721: ${resumeText.slice(0, 3000)}
2722: 
2723: Return ONLY valid JSON with this structure:
2724: {
2725:   "industries": [
2726:     { "name": "Industry Name", "percentage": 40, "years": 5 },
2727:     { "name": "Another Industry", "percentage": 30, "years": 3 }
2728:   ],
2729:   "totalYears": 8,
2730:   "primaryIndustry": "Most relevant industry"
2731: }
2732: 
2733: Rules:
2734: - List all industries worked in
2735: - Calculate percentage of time in each
2736: - Count years of experience per industry
2737: - Identify primary/dominant industry`
2738: 
2739:     const response = await client.makeRequest(
2740:       'You are a career analyst. Extract career timeline data. Return ONLY valid JSON.',
2741:       prompt,
2742:       { temperature: 0.2, maxTokens: 1000, model: 'sonar-pro' }
2743:     )
2744: 
2745:     try {
2746:       const parsed = parseAIResponse<{
2747:         industries: Array<{ name: string; percentage: number; years: number }>
2748:         totalYears: number
2749:         primaryIndustry: string
2750:       }>(response.content)
2751: 
2752:       return {
2753:         industries: parsed.industries || [],
2754:         totalYears: parsed.totalYears || 0,
2755:         primaryIndustry: parsed.primaryIndustry || (parsed.industries?.[0]?.name || 'Unknown')
2756:       }
2757:     } catch {
2758:       // Fallback if parsing fails
2759:       return {
2760:         industries: [{ name: 'General', percentage: 100, years: 0 }],
2761:         totalYears: 0,
2762:         primaryIndustry: 'General'
2763:       }
2764:     }
2765:   }
2766: 
2767:   /**
2768:    * Enhanced company research with comprehensive data
2769:    * @param params - Company name, job title, location
2770:    * @returns Enhanced company research data
2771:    */
2772:   static async enhancedCompanyResearch(params: {
2773:     companyName: string
2774:     jobTitle?: string
2775:     location?: string
2776:   }): Promise<EnhancedResponse<IntelligenceResponse>> {
2777:     // Use existing researchCompanyV2 as the base
2778:     return await this.researchCompanyV2({
2779:       company: params.companyName,
2780:       role: params.jobTitle,
2781:       geo: params.location
2782:     })
2783:   }
2784: }
</file>

</files>
